{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N3KVvRYZDED5",
    "outputId": "0600aadb-5401-4543-a333-8dfb80957494"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jr-T9XJ-BWdm"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AAqN4QaTsHdT"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "YCoj9TuusHfv",
    "outputId": "bf7a41a3-3a8e-4391-cc8d-fcc6b6d65bcf"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-67df0db0-d8ed-46c1-bc86-5d84452c78a0\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>491</th>\n",
       "      <th>492</th>\n",
       "      <th>493</th>\n",
       "      <th>494</th>\n",
       "      <th>495</th>\n",
       "      <th>496</th>\n",
       "      <th>497</th>\n",
       "      <th>498</th>\n",
       "      <th>499</th>\n",
       "      <th>500</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.797172</td>\n",
       "      <td>-0.664392</td>\n",
       "      <td>-0.373015</td>\n",
       "      <td>0.040815</td>\n",
       "      <td>0.526936</td>\n",
       "      <td>0.984288</td>\n",
       "      <td>1.353120</td>\n",
       "      <td>1.578108</td>\n",
       "      <td>1.659251</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.362068</td>\n",
       "      <td>0.092083</td>\n",
       "      <td>-0.081268</td>\n",
       "      <td>-0.212573</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.664392</td>\n",
       "      <td>-1.073796</td>\n",
       "      <td>-1.564343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.804855</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.373474</td>\n",
       "      <td>0.038343</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.740860</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.395357</td>\n",
       "      <td>-1.570192</td>\n",
       "      <td>...</td>\n",
       "      <td>0.386403</td>\n",
       "      <td>0.049213</td>\n",
       "      <td>-0.258138</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.683647</td>\n",
       "      <td>-0.773817</td>\n",
       "      <td>-0.785255</td>\n",
       "      <td>-0.714885</td>\n",
       "      <td>-0.560443</td>\n",
       "      <td>-0.319086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.727985</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.499124</td>\n",
       "      <td>-1.068629</td>\n",
       "      <td>-1.578351</td>\n",
       "      <td>-1.990534</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2.503403</td>\n",
       "      <td>-2.585211</td>\n",
       "      <td>...</td>\n",
       "      <td>0.394463</td>\n",
       "      <td>0.463685</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.517174</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.476270</td>\n",
       "      <td>0.438513</td>\n",
       "      <td>0.394463</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.255391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.234439</td>\n",
       "      <td>-0.502157</td>\n",
       "      <td>-0.732488</td>\n",
       "      <td>-0.946128</td>\n",
       "      <td>-1.139739</td>\n",
       "      <td>-1.323336</td>\n",
       "      <td>-1.490243</td>\n",
       "      <td>-1.607077</td>\n",
       "      <td>-1.620430</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.952804</td>\n",
       "      <td>-0.929437</td>\n",
       "      <td>-0.922761</td>\n",
       "      <td>-0.929437</td>\n",
       "      <td>-0.909409</td>\n",
       "      <td>-0.835970</td>\n",
       "      <td>-0.695768</td>\n",
       "      <td>-0.478790</td>\n",
       "      <td>-0.188707</td>\n",
       "      <td>0.119736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.062285</td>\n",
       "      <td>0.235829</td>\n",
       "      <td>0.710396</td>\n",
       "      <td>1.239969</td>\n",
       "      <td>1.649823</td>\n",
       "      <td>1.876321</td>\n",
       "      <td>1.865535</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.776188</td>\n",
       "      <td>0.725496</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.731967</td>\n",
       "      <td>0.808545</td>\n",
       "      <td>0.839823</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.437520</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.602213</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 501 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-67df0db0-d8ed-46c1-bc86-5d84452c78a0')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-67df0db0-d8ed-46c1-bc86-5d84452c78a0 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-67df0db0-d8ed-46c1-bc86-5d84452c78a0');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "   0         1         2         3         4         5         6         7    \\\n",
       "0 -1.0 -0.797172 -0.664392 -0.373015  0.040815  0.526936  0.984288  1.353120   \n",
       "1  1.0  0.804855       NaN  0.373474  0.038343       NaN -0.740860       NaN   \n",
       "2 -1.0  0.727985       NaN -0.499124 -1.068629 -1.578351 -1.990534       NaN   \n",
       "3 -1.0 -0.234439 -0.502157 -0.732488 -0.946128 -1.139739 -1.323336 -1.490243   \n",
       "4 -1.0       NaN -0.062285  0.235829  0.710396  1.239969  1.649823  1.876321   \n",
       "\n",
       "        8         9    ...       491       492       493       494       495  \\\n",
       "0  1.578108  1.659251  ...       NaN       NaN  0.362068  0.092083 -0.081268   \n",
       "1 -1.395357 -1.570192  ...  0.386403  0.049213 -0.258138       NaN -0.683647   \n",
       "2 -2.503403 -2.585211  ...  0.394463  0.463685       NaN  0.517174       NaN   \n",
       "3 -1.607077 -1.620430  ... -0.952804 -0.929437 -0.922761 -0.929437 -0.909409   \n",
       "4  1.865535       NaN  ...  0.776188  0.725496       NaN  0.731967  0.808545   \n",
       "\n",
       "        496       497       498       499       500  \n",
       "0 -0.212573       NaN -0.664392 -1.073796 -1.564343  \n",
       "1 -0.773817 -0.785255 -0.714885 -0.560443 -0.319086  \n",
       "2  0.476270  0.438513  0.394463       NaN  0.255391  \n",
       "3 -0.835970 -0.695768 -0.478790 -0.188707  0.119736  \n",
       "4  0.839823       NaN  0.437520       NaN -0.602213  \n",
       "\n",
       "[5 rows x 501 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_nan = pd.read_csv('/content/drive/MyDrive/train_nan.csv', header=None)\n",
    "df_train_nan.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 236
    },
    "id": "VVUQzglL1S74",
    "outputId": "ada79731-5b89-42ff-c835-6b3476798d2f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-66997328-0ce3-4297-91a1-1363f92ea223\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>491</th>\n",
       "      <th>492</th>\n",
       "      <th>493</th>\n",
       "      <th>494</th>\n",
       "      <th>495</th>\n",
       "      <th>496</th>\n",
       "      <th>497</th>\n",
       "      <th>498</th>\n",
       "      <th>499</th>\n",
       "      <th>500</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 501 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-66997328-0ce3-4297-91a1-1363f92ea223')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-66997328-0ce3-4297-91a1-1363f92ea223 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-66997328-0ce3-4297-91a1-1363f92ea223');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "     0      1      2      3      4      5      6      7      8      9    ...  \\\n",
       "0  False  False  False  False  False  False  False  False  False  False  ...   \n",
       "1  False  False   True  False  False   True  False   True  False  False  ...   \n",
       "2  False  False   True  False  False  False  False   True  False  False  ...   \n",
       "3  False  False  False  False  False  False  False  False  False  False  ...   \n",
       "4  False   True  False  False  False  False  False  False  False   True  ...   \n",
       "\n",
       "     491    492    493    494    495    496    497    498    499    500  \n",
       "0   True   True  False  False  False  False   True  False  False  False  \n",
       "1  False  False  False   True  False  False  False  False  False  False  \n",
       "2  False  False   True  False   True  False  False  False   True  False  \n",
       "3  False  False  False  False  False  False  False  False  False  False  \n",
       "4  False  False   True  False  False  False   True  False   True  False  \n",
       "\n",
       "[5 rows x 501 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_nan_mask = df_train_nan.isna()\n",
    "df_train_nan_mask.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QHIzv5DV1S-m",
    "outputId": "a5b6103e-1fd2-4e7c-bda7-40525547cdff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False False False False False False False False False False False False\n",
      " False False False  True  True False False  True False False False  True\n",
      " False False False  True False False False False False False False False\n",
      "  True False  True False False False False False False False False False\n",
      " False False False False False False False False  True False False False\n",
      "  True False False  True False  True  True False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False  True False False False False False False False\n",
      " False False False False False False False  True False False  True False\n",
      "  True False False False False False False False False False False  True\n",
      " False False False False  True False False False False False False False\n",
      " False  True False False False False False False False False False False\n",
      " False False False False False False False False  True False  True False\n",
      " False False False False False  True False False False  True False False\n",
      " False False False False False False False False False False False  True\n",
      " False False False False False False False False False False False False\n",
      " False False False False False  True False False False  True False False\n",
      "  True  True False False False False False False False  True False  True\n",
      " False False False  True False False False False False False False False\n",
      " False False False  True False  True False False False  True False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False  True False\n",
      " False False False False  True False False  True False False False False\n",
      " False False False False False  True False False False  True False False\n",
      " False  True False False False False  True  True False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False  True False False\n",
      " False False False  True False  True  True False  True False False False\n",
      " False False False False False False False False False False False False\n",
      " False False  True False False False False False  True False  True False\n",
      " False False False False False False False  True False False False  True\n",
      " False False False False False False False False False False False  True\n",
      " False False False False  True False False False  True  True False False\n",
      " False False False False False False False False  True False False False\n",
      " False False False False False False  True False False False False False\n",
      "  True False False  True False  True  True False False False  True False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False  True False False False False False False  True False  True\n",
      "  True False False False False  True False False False]\n"
     ]
    }
   ],
   "source": [
    "df_train_nan_mask = df_train_nan_mask.to_numpy()\n",
    "print(df_train_nan_mask[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EB2YuRhr153u",
    "outputId": "2a33368d-7024-4dfd-a44d-b5719de6af2b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 1.\n",
      " 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1.\n",
      " 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 1. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 1. 0. 0. 0. 1. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "df_train_nan_mask = df_train_nan_mask*1.0\n",
    "print(df_train_nan_mask[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Hflz4LBf2JO5",
    "outputId": "4f06f0a3-6cb4-4228-824b-4cf0550775ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3601, 500)\n"
     ]
    }
   ],
   "source": [
    "df_train_nan_mask = df_train_nan_mask[:, 1:]\n",
    "print(df_train_nan_mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rqanNmjt2JRI"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "UJbvTPP-aFz4",
    "outputId": "58ab5ebd-db02-4b8a-9b66-206720a7b9b2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-c66893c8-7bb3-45cb-a8d2-641ea0e7f79d\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>491</th>\n",
       "      <th>492</th>\n",
       "      <th>493</th>\n",
       "      <th>494</th>\n",
       "      <th>495</th>\n",
       "      <th>496</th>\n",
       "      <th>497</th>\n",
       "      <th>498</th>\n",
       "      <th>499</th>\n",
       "      <th>500</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.797172</td>\n",
       "      <td>-0.664392</td>\n",
       "      <td>-0.373015</td>\n",
       "      <td>0.040815</td>\n",
       "      <td>0.526936</td>\n",
       "      <td>0.984288</td>\n",
       "      <td>1.353120</td>\n",
       "      <td>1.578108</td>\n",
       "      <td>1.659251</td>\n",
       "      <td>...</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>0.362068</td>\n",
       "      <td>0.092083</td>\n",
       "      <td>-0.081268</td>\n",
       "      <td>-0.212573</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>-0.664392</td>\n",
       "      <td>-1.073796</td>\n",
       "      <td>-1.564343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.804855</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>0.373474</td>\n",
       "      <td>0.038343</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>-0.740860</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>-1.395357</td>\n",
       "      <td>-1.570192</td>\n",
       "      <td>...</td>\n",
       "      <td>0.386403</td>\n",
       "      <td>0.049213</td>\n",
       "      <td>-0.258138</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>-0.683647</td>\n",
       "      <td>-0.773817</td>\n",
       "      <td>-0.785255</td>\n",
       "      <td>-0.714885</td>\n",
       "      <td>-0.560443</td>\n",
       "      <td>-0.319086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.727985</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>-0.499124</td>\n",
       "      <td>-1.068629</td>\n",
       "      <td>-1.578351</td>\n",
       "      <td>-1.990534</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>-2.503403</td>\n",
       "      <td>-2.585211</td>\n",
       "      <td>...</td>\n",
       "      <td>0.394463</td>\n",
       "      <td>0.463685</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>0.517174</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>0.476270</td>\n",
       "      <td>0.438513</td>\n",
       "      <td>0.394463</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>0.255391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.234439</td>\n",
       "      <td>-0.502157</td>\n",
       "      <td>-0.732488</td>\n",
       "      <td>-0.946128</td>\n",
       "      <td>-1.139739</td>\n",
       "      <td>-1.323336</td>\n",
       "      <td>-1.490243</td>\n",
       "      <td>-1.607077</td>\n",
       "      <td>-1.620430</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.952804</td>\n",
       "      <td>-0.929437</td>\n",
       "      <td>-0.922761</td>\n",
       "      <td>-0.929437</td>\n",
       "      <td>-0.909409</td>\n",
       "      <td>-0.835970</td>\n",
       "      <td>-0.695768</td>\n",
       "      <td>-0.478790</td>\n",
       "      <td>-0.188707</td>\n",
       "      <td>0.119736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>-0.062285</td>\n",
       "      <td>0.235829</td>\n",
       "      <td>0.710396</td>\n",
       "      <td>1.239969</td>\n",
       "      <td>1.649823</td>\n",
       "      <td>1.876321</td>\n",
       "      <td>1.865535</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.776188</td>\n",
       "      <td>0.725496</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>0.731967</td>\n",
       "      <td>0.808545</td>\n",
       "      <td>0.839823</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>0.437520</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>-0.602213</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 501 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c66893c8-7bb3-45cb-a8d2-641ea0e7f79d')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-c66893c8-7bb3-45cb-a8d2-641ea0e7f79d button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-c66893c8-7bb3-45cb-a8d2-641ea0e7f79d');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "   0            1            2         3         4            5         6    \\\n",
       "0 -1.0    -0.797172    -0.664392 -0.373015  0.040815     0.526936  0.984288   \n",
       "1  1.0     0.804855  1000.000000  0.373474  0.038343  1000.000000 -0.740860   \n",
       "2 -1.0     0.727985  1000.000000 -0.499124 -1.068629    -1.578351 -1.990534   \n",
       "3 -1.0    -0.234439    -0.502157 -0.732488 -0.946128    -1.139739 -1.323336   \n",
       "4 -1.0  1000.000000    -0.062285  0.235829  0.710396     1.239969  1.649823   \n",
       "\n",
       "           7         8            9    ...          491          492  \\\n",
       "0     1.353120  1.578108     1.659251  ...  1000.000000  1000.000000   \n",
       "1  1000.000000 -1.395357    -1.570192  ...     0.386403     0.049213   \n",
       "2  1000.000000 -2.503403    -2.585211  ...     0.394463     0.463685   \n",
       "3    -1.490243 -1.607077    -1.620430  ...    -0.952804    -0.929437   \n",
       "4     1.876321  1.865535  1000.000000  ...     0.776188     0.725496   \n",
       "\n",
       "           493          494          495       496          497       498  \\\n",
       "0     0.362068     0.092083    -0.081268 -0.212573  1000.000000 -0.664392   \n",
       "1    -0.258138  1000.000000    -0.683647 -0.773817    -0.785255 -0.714885   \n",
       "2  1000.000000     0.517174  1000.000000  0.476270     0.438513  0.394463   \n",
       "3    -0.922761    -0.929437    -0.909409 -0.835970    -0.695768 -0.478790   \n",
       "4  1000.000000     0.731967     0.808545  0.839823  1000.000000  0.437520   \n",
       "\n",
       "           499       500  \n",
       "0    -1.073796 -1.564343  \n",
       "1    -0.560443 -0.319086  \n",
       "2  1000.000000  0.255391  \n",
       "3    -0.188707  0.119736  \n",
       "4  1000.000000 -0.602213  \n",
       "\n",
       "[5 rows x 501 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_nan = df_train_nan.fillna(1000)\n",
    "df_train_nan.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZedM7aGJsHso"
   },
   "outputs": [],
   "source": [
    "df_train_nan = df_train_nan.to_numpy()\n",
    "x_train_nan = df_train_nan[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wrXWii6-snJ6",
    "outputId": "6eab027b-06c8-415f-c6b0-a8838ffe5419"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3601, 500, 1)\n"
     ]
    }
   ],
   "source": [
    "x_train_nan = x_train_nan.reshape((x_train_nan.shape[0], x_train_nan.shape[1], 1))\n",
    "print(x_train_nan.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6fDxzj74Y9Jz",
    "outputId": "15d0b766-eb8a-4223-885b-9c8660774e10"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3601, 500, 1)\n"
     ]
    }
   ],
   "source": [
    "df_train_nan_mask = df_train_nan_mask.reshape((df_train_nan_mask.shape[0], df_train_nan_mask.shape[1], 1))\n",
    "print(df_train_nan_mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Lifs4hyH2vhG",
    "outputId": "5d812763-3455-444e-a40b-a13209d56e18"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3601, 500, 2)\n"
     ]
    }
   ],
   "source": [
    "x_train_input = np.concatenate([x_train_nan, df_train_nan_mask], axis=2)\n",
    "print(x_train_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SndZjE5X2vjq",
    "outputId": "e21595bd-0893-4493-9e13-30b09f1776a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-7.9717168e-01 -6.6439208e-01 -3.7301463e-01  4.0815121e-02\n",
      "  5.2693599e-01  9.8428794e-01  1.3531202e+00  1.5781078e+00\n",
      "  1.6592509e+00  1.6408093e+00  1.5522896e+00  1.4379516e+00\n",
      "  1.2793537e+00  1.0691193e+00  1.0000000e+03  1.0000000e+03\n",
      " -3.0072351e-01 -9.3732792e-01  1.0000000e+03 -1.9516165e+00\n",
      " -2.1360326e+00 -2.0401363e+00  1.0000000e+03 -1.2619003e+00\n",
      " -8.0454833e-01 -4.6153436e-01  1.0000000e+03 -2.5130000e-01\n",
      " -3.0183001e-01 -3.1326381e-01 -2.0445830e-01  6.7002208e-02\n",
      "  4.7161115e-01  9.3265143e-01  1.3531202e+00  1.0000000e+03\n",
      "  1.7588356e+00  1.0000000e+03  1.4822114e+00  1.1797690e+00\n",
      "  8.2569008e-01  4.4948122e-01  7.2534692e-02 -2.9703519e-01\n",
      " -6.4595047e-01 -9.7421115e-01 -1.2508353e+00 -1.4094332e+00\n",
      " -1.4278748e+00 -1.3024718e+00]\n"
     ]
    }
   ],
   "source": [
    "print(x_train_input[0, :50, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uoAjiDx83dnh",
    "outputId": "a2ed626f-e34a-4375-9765-f3abff70fbe6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 1. 0.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(x_train_input[0, :50, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UuAUfl2x3dpx"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-d50cnAhtTDU"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g12wOnFxTH2o",
    "outputId": "e726d308-40cd-46f4-de09-b1c287bd8b78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3601, 500, 1)\n"
     ]
    }
   ],
   "source": [
    "def readucr(filename):\n",
    "    data = np.loadtxt(filename, delimiter=\"\\t\")\n",
    "    y = data[:, 0]\n",
    "    x = data[:, 1:]\n",
    "    return x, y.astype(int)\n",
    "\n",
    "x_train_target, _ = readucr(\"/content/drive/MyDrive/FordA_TRAIN.tsv\")\n",
    "x_train_target = x_train_target.reshape((x_train_target.shape[0], x_train_target.shape[1], 1))\n",
    "print(x_train_target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O-SHn8THTH5D"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7NJBEYcxTH7a",
    "outputId": "2b16acfb-e541-4194-b98d-bdfcaa645cdf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-7.9717168e-01 -6.6439208e-01 -3.7301463e-01  4.0815121e-02\n",
      "  5.2693599e-01  9.8428794e-01  1.3531202e+00  1.5781078e+00\n",
      "  1.6592509e+00  1.6408093e+00  1.5522896e+00  1.4379516e+00\n",
      "  1.2793537e+00  1.0691193e+00  1.0000000e+03  1.0000000e+03\n",
      " -3.0072351e-01 -9.3732792e-01  1.0000000e+03 -1.9516165e+00\n",
      " -2.1360326e+00 -2.0401363e+00  1.0000000e+03 -1.2619003e+00\n",
      " -8.0454833e-01 -4.6153436e-01  1.0000000e+03 -2.5130000e-01\n",
      " -3.0183001e-01 -3.1326381e-01 -2.0445830e-01  6.7002208e-02\n",
      "  4.7161115e-01  9.3265143e-01  1.3531202e+00  1.0000000e+03\n",
      "  1.7588356e+00  1.0000000e+03  1.4822114e+00  1.1797690e+00\n",
      "  8.2569008e-01  4.4948122e-01  7.2534692e-02 -2.9703519e-01\n",
      " -6.4595047e-01 -9.7421115e-01 -1.2508353e+00 -1.4094332e+00\n",
      " -1.4278748e+00 -1.3024718e+00]\n"
     ]
    }
   ],
   "source": [
    "print(x_train_input[0,:50,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GvTZRo5XTH9g",
    "outputId": "ff0ebffc-0ae8-47b2-9030-9d3e26555691"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.79717168 -0.66439208 -0.37301463  0.04081512  0.52693599  0.98428794\n",
      "  1.3531202   1.5781078   1.6592509   1.6408093   1.5522896   1.4379516\n",
      "  1.2793537   1.0691193   0.744547    0.27760541 -0.30072351 -0.93732792\n",
      " -1.5200828  -1.9516165  -2.1360326  -2.0401363  -1.7229406  -1.2619003\n",
      " -0.80454833 -0.46153436 -0.27822475 -0.2513     -0.30183001 -0.31326381\n",
      " -0.2044583   0.06700221  0.47161115  0.93265143  1.3531202   1.6444976\n",
      "  1.7588356   1.6961341   1.4822114   1.179769    0.82569008  0.44948122\n",
      "  0.07253469 -0.29703519 -0.64595047 -0.97421115 -1.2508353  -1.4094332\n",
      " -1.4278748  -1.3024718 ]\n"
     ]
    }
   ],
   "source": [
    "print(x_train_target[0,:50,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XBSEdiWkTH_3"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3JRGml5lsnSa"
   },
   "outputs": [],
   "source": [
    "train_ds = tf.data.Dataset.from_tensor_slices((x_train_input, x_train_target)).batch(32)\n",
    "train_ds = train_ds.cache().prefetch(buffer_size=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kwJOqf4GBBkP",
    "outputId": "a7d9f9a4-ee2e-4e6b-d4bb-5b48a6a4ab14"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 500, 2)\n",
      "(32, 500, 1)\n"
     ]
    }
   ],
   "source": [
    "for x_nan, x_target in train_ds:\n",
    "  print(x_nan.shape)\n",
    "  print(x_target.shape)\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QdRSyNiiU6uY"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jJAKtxtjZdXg"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FIKvYsplBWdu"
   },
   "source": [
    "## Build a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dASnMDEnBWdu",
    "outputId": "8b0d53af-3748-40cf-cc8c-d95c448da6fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_8 (InputLayer)           [(None, 500, 2)]     0           []                               \n",
      "                                                                                                  \n",
      " conv1d_24 (Conv1D)             (None, 500, 64)      448         ['input_8[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_18 (BatchN  (None, 500, 64)     256         ['conv1d_24[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_6 (ReLU)                 (None, 500, 64)      0           ['batch_normalization_18[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_25 (Conv1D)             (None, 500, 64)      12352       ['re_lu_6[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_19 (BatchN  (None, 500, 64)     256         ['conv1d_25[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " p_re_lu_12 (PReLU)             (None, 500, 64)      32000       ['batch_normalization_19[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_26 (Conv1D)             (None, 500, 64)      12352       ['p_re_lu_12[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_20 (BatchN  (None, 500, 64)     256         ['conv1d_26[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " p_re_lu_13 (PReLU)             (None, 500, 64)      32000       ['batch_normalization_20[0][0]'] \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_15 (S  (None, 500)         0           ['input_8[0][0]']                \n",
      " licingOpLambda)                                                                                  \n",
      "                                                                                                  \n",
      " conv1d_27 (Conv1D)             (None, 500, 1)       193         ['p_re_lu_13[0][0]']             \n",
      "                                                                                                  \n",
      " tf.cast_5 (TFOpLambda)         (None, 500)          0           ['tf.__operators__.getitem_15[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " flatten_2 (Flatten)            (None, 500)          0           ['conv1d_27[0][0]']              \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_14 (S  (None, 500)         0           ['input_8[0][0]']                \n",
      " licingOpLambda)                                                                                  \n",
      "                                                                                                  \n",
      " tf.where_6 (TFOpLambda)        (None, 500)          0           ['tf.cast_5[0][0]',              \n",
      "                                                                  'flatten_2[0][0]',              \n",
      "                                                                  'tf.__operators__.getitem_14[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 90,113\n",
      "Trainable params: 89,729\n",
      "Non-trainable params: 384\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_layer = keras.layers.Input((500, 2))\n",
    "\n",
    "origin = input_layer[:,:,0]\n",
    "condition = tf.cast(input_layer[:,:,1], dtype=tf.bool)\n",
    "\n",
    "x = keras.layers.Conv1D(filters=64, kernel_size=3, padding=\"same\")(input_layer)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.ReLU()(x)\n",
    "\n",
    "x = keras.layers.Conv1D(filters=64, kernel_size=3, padding=\"same\")(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.PReLU()(x)\n",
    "\n",
    "x = keras.layers.Conv1D(filters=64, kernel_size=3, padding=\"same\")(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.PReLU()(x)\n",
    "\n",
    "x = keras.layers.Conv1D(filters=1, kernel_size=3, padding=\"same\")(x)\n",
    "x = keras.layers.Flatten()(x)\n",
    "\n",
    "x = tf.where(condition, x, origin)\n",
    "\n",
    "model_fill = keras.models.Model(inputs=input_layer, outputs=x)\n",
    "model_fill.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tYVmk2QSBWdu"
   },
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "muPLmcaVBWdv",
    "outputId": "5f04de79-b38f-427d-a552-4a0f15dbdb6f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "113/113 [==============================] - 7s 9ms/step - loss: 0.1625 - mse: 0.1625 - lr: 0.0010\n",
      "Epoch 2/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.1479 - mse: 0.1479 - lr: 0.0010\n",
      "Epoch 3/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.1365 - mse: 0.1365 - lr: 0.0010\n",
      "Epoch 4/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0990 - mse: 0.0990 - lr: 0.0010\n",
      "Epoch 5/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0692 - mse: 0.0692 - lr: 0.0010\n",
      "Epoch 6/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0529 - mse: 0.0529 - lr: 0.0010\n",
      "Epoch 7/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0428 - mse: 0.0428 - lr: 0.0010\n",
      "Epoch 8/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0409 - mse: 0.0409 - lr: 0.0010\n",
      "Epoch 9/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 0.0330 - mse: 0.0330 - lr: 0.0010\n",
      "Epoch 10/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0333 - mse: 0.0333 - lr: 0.0010\n",
      "Epoch 11/500\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0309 - mse: 0.0309 - lr: 0.0010\n",
      "Epoch 12/500\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 0.0340 - mse: 0.0340 - lr: 0.0010\n",
      "Epoch 13/500\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 0.0271 - mse: 0.0271 - lr: 0.0010\n",
      "Epoch 14/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0241 - mse: 0.0241 - lr: 0.0010\n",
      "Epoch 15/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 0.0266 - mse: 0.0266 - lr: 0.0010\n",
      "Epoch 16/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0238 - mse: 0.0238 - lr: 0.0010\n",
      "Epoch 17/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0219 - mse: 0.0219 - lr: 0.0010\n",
      "Epoch 18/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0224 - mse: 0.0224 - lr: 0.0010\n",
      "Epoch 19/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0194 - mse: 0.0194 - lr: 0.0010\n",
      "Epoch 20/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0200 - mse: 0.0200 - lr: 0.0010\n",
      "Epoch 21/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0183 - mse: 0.0183 - lr: 0.0010\n",
      "Epoch 22/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0192 - mse: 0.0192 - lr: 0.0010\n",
      "Epoch 23/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0173 - mse: 0.0173 - lr: 0.0010\n",
      "Epoch 24/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0166 - mse: 0.0166 - lr: 0.0010\n",
      "Epoch 25/500\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0169 - mse: 0.0169 - lr: 0.0010\n",
      "Epoch 26/500\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0176 - mse: 0.0176 - lr: 0.0010\n",
      "Epoch 27/500\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0147 - mse: 0.0147 - lr: 0.0010\n",
      "Epoch 28/500\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0153 - mse: 0.0153 - lr: 0.0010\n",
      "Epoch 29/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0171 - mse: 0.0171 - lr: 0.0010\n",
      "Epoch 30/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0154 - mse: 0.0154 - lr: 0.0010\n",
      "Epoch 31/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0142 - mse: 0.0142 - lr: 0.0010\n",
      "Epoch 32/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0136 - mse: 0.0136 - lr: 0.0010\n",
      "Epoch 33/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 0.0127 - mse: 0.0127 - lr: 0.0010\n",
      "Epoch 34/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0136 - mse: 0.0136 - lr: 0.0010\n",
      "Epoch 35/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0140 - mse: 0.0140 - lr: 0.0010\n",
      "Epoch 36/500\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0115 - mse: 0.0115 - lr: 0.0010\n",
      "Epoch 37/500\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 0.0115 - mse: 0.0115 - lr: 0.0010\n",
      "Epoch 38/500\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 0.0115 - mse: 0.0115 - lr: 0.0010\n",
      "Epoch 39/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0105 - mse: 0.0105 - lr: 0.0010\n",
      "Epoch 40/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0111 - mse: 0.0111 - lr: 0.0010\n",
      "Epoch 41/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0117 - mse: 0.0117 - lr: 0.0010\n",
      "Epoch 42/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0105 - mse: 0.0105 - lr: 0.0010\n",
      "Epoch 43/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0102 - mse: 0.0102 - lr: 0.0010\n",
      "Epoch 44/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0104 - mse: 0.0104 - lr: 0.0010\n",
      "Epoch 45/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0110 - mse: 0.0110 - lr: 0.0010\n",
      "Epoch 46/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 0.0094 - mse: 0.0094 - lr: 0.0010\n",
      "Epoch 47/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0095 - mse: 0.0095 - lr: 0.0010\n",
      "Epoch 48/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0092 - mse: 0.0092 - lr: 0.0010\n",
      "Epoch 49/500\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0088 - mse: 0.0088 - lr: 0.0010\n",
      "Epoch 50/500\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 0.0095 - mse: 0.0095 - lr: 0.0010\n",
      "Epoch 51/500\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0095 - mse: 0.0095 - lr: 0.0010\n",
      "Epoch 52/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0088 - mse: 0.0088 - lr: 0.0010\n",
      "Epoch 53/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0091 - mse: 0.0091 - lr: 0.0010\n",
      "Epoch 54/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0081 - mse: 0.0081 - lr: 0.0010\n",
      "Epoch 55/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0081 - mse: 0.0081 - lr: 0.0010\n",
      "Epoch 56/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0072 - mse: 0.0072 - lr: 0.0010\n",
      "Epoch 57/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0070 - mse: 0.0070 - lr: 0.0010\n",
      "Epoch 58/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0083 - mse: 0.0083 - lr: 0.0010\n",
      "Epoch 59/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0075 - mse: 0.0075 - lr: 0.0010\n",
      "Epoch 60/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0072 - mse: 0.0072 - lr: 0.0010\n",
      "Epoch 61/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0077 - mse: 0.0077 - lr: 0.0010\n",
      "Epoch 62/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0087 - mse: 0.0087 - lr: 0.0010\n",
      "Epoch 63/500\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0071 - mse: 0.0071 - lr: 0.0010\n",
      "Epoch 64/500\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0086 - mse: 0.0086 - lr: 0.0010\n",
      "Epoch 65/500\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 0.0076 - mse: 0.0076 - lr: 0.0010\n",
      "Epoch 66/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0082 - mse: 0.0082 - lr: 0.0010\n",
      "Epoch 67/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0080 - mse: 0.0080 - lr: 0.0010\n",
      "Epoch 68/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0088 - mse: 0.0088 - lr: 0.0010\n",
      "Epoch 69/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 0.0079 - mse: 0.0079 - lr: 0.0010\n",
      "Epoch 70/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0077 - mse: 0.0077 - lr: 0.0010\n",
      "Epoch 71/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0099 - mse: 0.0099 - lr: 0.0010\n",
      "Epoch 72/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0069 - mse: 0.0069 - lr: 0.0010\n",
      "Epoch 73/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0071 - mse: 0.0071 - lr: 0.0010\n",
      "Epoch 74/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0079 - mse: 0.0079 - lr: 0.0010\n",
      "Epoch 75/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0082 - mse: 0.0082 - lr: 0.0010\n",
      "Epoch 76/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0068 - mse: 0.0068 - lr: 0.0010\n",
      "Epoch 77/500\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 0.0074 - mse: 0.0074 - lr: 0.0010\n",
      "Epoch 78/500\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0060 - mse: 0.0060 - lr: 0.0010\n",
      "Epoch 79/500\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 0.0064 - mse: 0.0064 - lr: 0.0010\n",
      "Epoch 80/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0071 - mse: 0.0071 - lr: 0.0010\n",
      "Epoch 81/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0070 - mse: 0.0070 - lr: 0.0010\n",
      "Epoch 82/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0072 - mse: 0.0072 - lr: 0.0010\n",
      "Epoch 83/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0097 - mse: 0.0097 - lr: 0.0010\n",
      "Epoch 84/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0095 - mse: 0.0095 - lr: 0.0010\n",
      "Epoch 85/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0070 - mse: 0.0070 - lr: 0.0010\n",
      "Epoch 86/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0071 - mse: 0.0071 - lr: 0.0010\n",
      "Epoch 87/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0062 - mse: 0.0062 - lr: 0.0010\n",
      "Epoch 88/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0059 - mse: 0.0059 - lr: 0.0010\n",
      "Epoch 89/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0059 - mse: 0.0059 - lr: 0.0010\n",
      "Epoch 90/500\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 0.0055 - mse: 0.0055 - lr: 0.0010\n",
      "Epoch 91/500\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 0.0056 - mse: 0.0056 - lr: 0.0010\n",
      "Epoch 92/500\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0052 - mse: 0.0052 - lr: 0.0010\n",
      "Epoch 93/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0050 - mse: 0.0050 - lr: 0.0010\n",
      "Epoch 94/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0050 - mse: 0.0050 - lr: 0.0010\n",
      "Epoch 95/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0045 - mse: 0.0045 - lr: 0.0010\n",
      "Epoch 96/500\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0047 - mse: 0.0047 - lr: 0.0010\n",
      "Epoch 97/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0059 - mse: 0.0059 - lr: 0.0010\n",
      "Epoch 98/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0050 - mse: 0.0050 - lr: 0.0010\n",
      "Epoch 99/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0050 - mse: 0.0050 - lr: 0.0010\n",
      "Epoch 100/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0047 - mse: 0.0047 - lr: 0.0010\n",
      "Epoch 101/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 0.0050 - mse: 0.0050 - lr: 0.0010\n",
      "Epoch 102/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0053 - mse: 0.0053 - lr: 0.0010\n",
      "Epoch 103/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0060 - mse: 0.0060 - lr: 0.0010\n",
      "Epoch 104/500\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 0.0069 - mse: 0.0069 - lr: 0.0010\n",
      "Epoch 105/500\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0075 - mse: 0.0075 - lr: 0.0010\n",
      "Epoch 106/500\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 0.0071 - mse: 0.0071 - lr: 0.0010\n",
      "Epoch 107/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0073 - mse: 0.0073 - lr: 0.0010\n",
      "Epoch 108/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0106 - mse: 0.0106 - lr: 0.0010\n",
      "Epoch 109/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0079 - mse: 0.0079 - lr: 0.0010\n",
      "Epoch 110/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0073 - mse: 0.0073 - lr: 0.0010\n",
      "Epoch 111/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0059 - mse: 0.0059 - lr: 0.0010\n",
      "Epoch 112/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0057 - mse: 0.0057 - lr: 0.0010\n",
      "Epoch 113/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0054 - mse: 0.0054 - lr: 0.0010\n",
      "Epoch 114/500\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0050 - mse: 0.0050 - lr: 0.0010\n",
      "Epoch 115/500\n",
      "113/113 [==============================] - 2s 13ms/step - loss: 0.0048 - mse: 0.0048 - lr: 0.0010\n",
      "Epoch 116/500\n",
      "113/113 [==============================] - 2s 18ms/step - loss: 0.0039 - mse: 0.0039 - lr: 5.0000e-04\n",
      "Epoch 117/500\n",
      "113/113 [==============================] - 2s 15ms/step - loss: 0.0038 - mse: 0.0038 - lr: 5.0000e-04\n",
      "Epoch 118/500\n",
      "113/113 [==============================] - 1s 13ms/step - loss: 0.0036 - mse: 0.0036 - lr: 5.0000e-04\n",
      "Epoch 119/500\n",
      "113/113 [==============================] - 2s 16ms/step - loss: 0.0035 - mse: 0.0035 - lr: 5.0000e-04\n",
      "Epoch 120/500\n",
      "113/113 [==============================] - 2s 13ms/step - loss: 0.0034 - mse: 0.0034 - lr: 5.0000e-04\n",
      "Epoch 121/500\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0033 - mse: 0.0033 - lr: 5.0000e-04\n",
      "Epoch 122/500\n",
      "113/113 [==============================] - 2s 16ms/step - loss: 0.0032 - mse: 0.0032 - lr: 5.0000e-04\n",
      "Epoch 123/500\n",
      "113/113 [==============================] - 2s 17ms/step - loss: 0.0031 - mse: 0.0031 - lr: 5.0000e-04\n",
      "Epoch 124/500\n",
      "113/113 [==============================] - 2s 17ms/step - loss: 0.0031 - mse: 0.0031 - lr: 5.0000e-04\n",
      "Epoch 125/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0030 - mse: 0.0030 - lr: 5.0000e-04\n",
      "Epoch 126/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0030 - mse: 0.0030 - lr: 5.0000e-04\n",
      "Epoch 127/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0029 - mse: 0.0029 - lr: 5.0000e-04\n",
      "Epoch 128/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0029 - mse: 0.0029 - lr: 5.0000e-04\n",
      "Epoch 129/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0029 - mse: 0.0029 - lr: 5.0000e-04\n",
      "Epoch 130/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0028 - mse: 0.0028 - lr: 5.0000e-04\n",
      "Epoch 131/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0028 - mse: 0.0028 - lr: 5.0000e-04\n",
      "Epoch 132/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0027 - mse: 0.0027 - lr: 5.0000e-04\n",
      "Epoch 133/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0027 - mse: 0.0027 - lr: 5.0000e-04\n",
      "Epoch 134/500\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 0.0027 - mse: 0.0027 - lr: 5.0000e-04\n",
      "Epoch 135/500\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 0.0026 - mse: 0.0026 - lr: 5.0000e-04\n",
      "Epoch 136/500\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 0.0026 - mse: 0.0026 - lr: 5.0000e-04\n",
      "Epoch 137/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0026 - mse: 0.0026 - lr: 5.0000e-04\n",
      "Epoch 138/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0025 - mse: 0.0025 - lr: 5.0000e-04\n",
      "Epoch 139/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0025 - mse: 0.0025 - lr: 5.0000e-04\n",
      "Epoch 140/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0026 - mse: 0.0026 - lr: 5.0000e-04\n",
      "Epoch 141/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0026 - mse: 0.0026 - lr: 5.0000e-04\n",
      "Epoch 142/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0026 - mse: 0.0026 - lr: 5.0000e-04\n",
      "Epoch 143/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0031 - mse: 0.0031 - lr: 5.0000e-04\n",
      "Epoch 144/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0026 - mse: 0.0026 - lr: 5.0000e-04\n",
      "Epoch 145/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0025 - mse: 0.0025 - lr: 5.0000e-04\n",
      "Epoch 146/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0028 - mse: 0.0028 - lr: 5.0000e-04\n",
      "Epoch 147/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0025 - mse: 0.0025 - lr: 5.0000e-04\n",
      "Epoch 148/500\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 0.0024 - mse: 0.0024 - lr: 5.0000e-04\n",
      "Epoch 149/500\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 0.0024 - mse: 0.0024 - lr: 5.0000e-04\n",
      "Epoch 150/500\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 0.0024 - mse: 0.0024 - lr: 5.0000e-04\n",
      "Epoch 151/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0025 - mse: 0.0025 - lr: 5.0000e-04\n",
      "Epoch 152/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0025 - mse: 0.0025 - lr: 5.0000e-04\n",
      "Epoch 153/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0026 - mse: 0.0026 - lr: 5.0000e-04\n",
      "Epoch 154/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0030 - mse: 0.0030 - lr: 5.0000e-04\n",
      "Epoch 155/500\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0027 - mse: 0.0027 - lr: 5.0000e-04\n",
      "Epoch 156/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0025 - mse: 0.0025 - lr: 5.0000e-04\n",
      "Epoch 157/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0024 - mse: 0.0024 - lr: 5.0000e-04\n",
      "Epoch 158/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0024 - mse: 0.0024 - lr: 5.0000e-04\n",
      "Epoch 159/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0022 - mse: 0.0022 - lr: 5.0000e-04\n",
      "Epoch 160/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0021 - mse: 0.0021 - lr: 5.0000e-04\n",
      "Epoch 161/500\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 0.0020 - mse: 0.0020 - lr: 5.0000e-04\n",
      "Epoch 162/500\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 0.0020 - mse: 0.0020 - lr: 5.0000e-04\n",
      "Epoch 163/500\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 0.0019 - mse: 0.0019 - lr: 5.0000e-04\n",
      "Epoch 164/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0019 - mse: 0.0019 - lr: 5.0000e-04\n",
      "Epoch 165/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0019 - mse: 0.0019 - lr: 5.0000e-04\n",
      "Epoch 166/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0019 - mse: 0.0019 - lr: 5.0000e-04\n",
      "Epoch 167/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0018 - mse: 0.0018 - lr: 5.0000e-04\n",
      "Epoch 168/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0018 - mse: 0.0018 - lr: 5.0000e-04\n",
      "Epoch 169/500\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0019 - mse: 0.0019 - lr: 5.0000e-04\n",
      "Epoch 170/500\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0018 - mse: 0.0018 - lr: 5.0000e-04\n",
      "Epoch 171/500\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0017 - mse: 0.0017 - lr: 5.0000e-04\n",
      "Epoch 172/500\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0017 - mse: 0.0017 - lr: 5.0000e-04\n",
      "Epoch 173/500\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0018 - mse: 0.0018 - lr: 5.0000e-04\n",
      "Epoch 174/500\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 0.0020 - mse: 0.0020 - lr: 5.0000e-04\n",
      "Epoch 175/500\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 0.0035 - mse: 0.0035 - lr: 5.0000e-04\n",
      "Epoch 176/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0036 - mse: 0.0036 - lr: 5.0000e-04\n",
      "Epoch 177/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0032 - mse: 0.0032 - lr: 5.0000e-04\n",
      "Epoch 178/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0032 - mse: 0.0032 - lr: 5.0000e-04\n",
      "Epoch 179/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0027 - mse: 0.0027 - lr: 5.0000e-04\n",
      "Epoch 180/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0029 - mse: 0.0029 - lr: 5.0000e-04\n",
      "Epoch 181/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0025 - mse: 0.0025 - lr: 5.0000e-04\n",
      "Epoch 182/500\n",
      "113/113 [==============================] - 1s 13ms/step - loss: 0.0028 - mse: 0.0028 - lr: 5.0000e-04\n",
      "Epoch 183/500\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0029 - mse: 0.0029 - lr: 5.0000e-04\n",
      "Epoch 184/500\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0028 - mse: 0.0028 - lr: 5.0000e-04\n",
      "Epoch 185/500\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 0.0030 - mse: 0.0030 - lr: 5.0000e-04\n",
      "Epoch 186/500\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 0.0024 - mse: 0.0024 - lr: 5.0000e-04\n",
      "Epoch 187/500\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 0.0025 - mse: 0.0025 - lr: 5.0000e-04\n",
      "Epoch 188/500\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0021 - mse: 0.0021 - lr: 2.5000e-04\n",
      "Epoch 189/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0020 - mse: 0.0020 - lr: 2.5000e-04\n",
      "Epoch 190/500\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 0.0020 - mse: 0.0020 - lr: 2.5000e-04\n",
      "Epoch 191/500\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0019 - mse: 0.0019 - lr: 2.5000e-04\n",
      "Epoch 192/500\n",
      "113/113 [==============================] - 2s 14ms/step - loss: 0.0019 - mse: 0.0019 - lr: 2.5000e-04\n",
      "Epoch 193/500\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0019 - mse: 0.0019 - lr: 2.5000e-04\n",
      "Epoch 194/500\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 0.0018 - mse: 0.0018 - lr: 2.5000e-04\n",
      "Epoch 195/500\n",
      "113/113 [==============================] - 2s 14ms/step - loss: 0.0018 - mse: 0.0018 - lr: 2.5000e-04\n",
      "Epoch 196/500\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0018 - mse: 0.0018 - lr: 2.5000e-04\n",
      "Epoch 197/500\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 0.0017 - mse: 0.0017 - lr: 2.5000e-04\n",
      "Epoch 198/500\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0017 - mse: 0.0017 - lr: 2.5000e-04\n",
      "Epoch 199/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0017 - mse: 0.0017 - lr: 2.5000e-04\n",
      "Epoch 200/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0017 - mse: 0.0017 - lr: 2.5000e-04\n",
      "Epoch 201/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0016 - mse: 0.0016 - lr: 2.5000e-04\n",
      "Epoch 202/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0016 - mse: 0.0016 - lr: 2.5000e-04\n",
      "Epoch 203/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0016 - mse: 0.0016 - lr: 2.5000e-04\n",
      "Epoch 204/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0015 - mse: 0.0015 - lr: 2.5000e-04\n",
      "Epoch 205/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0015 - mse: 0.0015 - lr: 2.5000e-04\n",
      "Epoch 206/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0015 - mse: 0.0015 - lr: 2.5000e-04\n",
      "Epoch 207/500\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0015 - mse: 0.0015 - lr: 2.5000e-04\n",
      "Epoch 208/500\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 0.0014 - mse: 0.0014 - lr: 2.5000e-04\n",
      "Epoch 209/500\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0014 - mse: 0.0014 - lr: 2.5000e-04\n",
      "Epoch 210/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0014 - mse: 0.0014 - lr: 2.5000e-04\n",
      "Epoch 211/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0014 - mse: 0.0014 - lr: 2.5000e-04\n",
      "Epoch 212/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0013 - mse: 0.0013 - lr: 2.5000e-04\n",
      "Epoch 213/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0013 - mse: 0.0013 - lr: 2.5000e-04\n",
      "Epoch 214/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0013 - mse: 0.0013 - lr: 2.5000e-04\n",
      "Epoch 215/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0013 - mse: 0.0013 - lr: 2.5000e-04\n",
      "Epoch 216/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0013 - mse: 0.0013 - lr: 2.5000e-04\n",
      "Epoch 217/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0012 - mse: 0.0012 - lr: 2.5000e-04\n",
      "Epoch 218/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0012 - mse: 0.0012 - lr: 2.5000e-04\n",
      "Epoch 219/500\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0012 - mse: 0.0012 - lr: 2.5000e-04\n",
      "Epoch 220/500\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 0.0012 - mse: 0.0012 - lr: 2.5000e-04\n",
      "Epoch 221/500\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 0.0012 - mse: 0.0012 - lr: 2.5000e-04\n",
      "Epoch 222/500\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0012 - mse: 0.0012 - lr: 2.5000e-04\n",
      "Epoch 223/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0012 - mse: 0.0012 - lr: 2.5000e-04\n",
      "Epoch 224/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0011 - mse: 0.0011 - lr: 2.5000e-04\n",
      "Epoch 225/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0011 - mse: 0.0011 - lr: 2.5000e-04\n",
      "Epoch 226/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0011 - mse: 0.0011 - lr: 2.5000e-04\n",
      "Epoch 227/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0011 - mse: 0.0011 - lr: 2.5000e-04\n",
      "Epoch 228/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0011 - mse: 0.0011 - lr: 2.5000e-04\n",
      "Epoch 229/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0011 - mse: 0.0011 - lr: 2.5000e-04\n",
      "Epoch 230/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0011 - mse: 0.0011 - lr: 2.5000e-04\n",
      "Epoch 231/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0011 - mse: 0.0011 - lr: 2.5000e-04\n",
      "Epoch 232/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0010 - mse: 0.0010 - lr: 2.5000e-04\n",
      "Epoch 233/500\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 0.0010 - mse: 0.0010 - lr: 2.5000e-04\n",
      "Epoch 234/500\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 0.0010 - mse: 0.0010 - lr: 2.5000e-04\n",
      "Epoch 235/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0010 - mse: 0.0010 - lr: 2.5000e-04\n",
      "Epoch 236/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0010 - mse: 0.0010 - lr: 2.5000e-04\n",
      "Epoch 237/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 9.9349e-04 - mse: 9.9349e-04 - lr: 2.5000e-04\n",
      "Epoch 238/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 9.8456e-04 - mse: 9.8456e-04 - lr: 2.5000e-04\n",
      "Epoch 239/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 9.7535e-04 - mse: 9.7535e-04 - lr: 2.5000e-04\n",
      "Epoch 240/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 9.7210e-04 - mse: 9.7210e-04 - lr: 2.5000e-04\n",
      "Epoch 241/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 9.6287e-04 - mse: 9.6287e-04 - lr: 2.5000e-04\n",
      "Epoch 242/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 9.5679e-04 - mse: 9.5679e-04 - lr: 2.5000e-04\n",
      "Epoch 243/500\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 9.4928e-04 - mse: 9.4928e-04 - lr: 2.5000e-04\n",
      "Epoch 244/500\n",
      "113/113 [==============================] - 2s 14ms/step - loss: 9.4070e-04 - mse: 9.4070e-04 - lr: 2.5000e-04\n",
      "Epoch 245/500\n",
      "113/113 [==============================] - 2s 21ms/step - loss: 9.3206e-04 - mse: 9.3206e-04 - lr: 2.5000e-04\n",
      "Epoch 246/500\n",
      "113/113 [==============================] - 2s 15ms/step - loss: 9.2455e-04 - mse: 9.2455e-04 - lr: 2.5000e-04\n",
      "Epoch 247/500\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 9.2283e-04 - mse: 9.2283e-04 - lr: 2.5000e-04\n",
      "Epoch 248/500\n",
      "113/113 [==============================] - 2s 13ms/step - loss: 9.2378e-04 - mse: 9.2378e-04 - lr: 2.5000e-04\n",
      "Epoch 249/500\n",
      "113/113 [==============================] - 2s 16ms/step - loss: 9.3526e-04 - mse: 9.3526e-04 - lr: 2.5000e-04\n",
      "Epoch 250/500\n",
      "113/113 [==============================] - 2s 16ms/step - loss: 9.7578e-04 - mse: 9.7578e-04 - lr: 2.5000e-04\n",
      "Epoch 251/500\n",
      "113/113 [==============================] - 2s 14ms/step - loss: 0.0010 - mse: 0.0010 - lr: 2.5000e-04\n",
      "Epoch 252/500\n",
      "113/113 [==============================] - 2s 17ms/step - loss: 0.0010 - mse: 0.0010 - lr: 2.5000e-04\n",
      "Epoch 253/500\n",
      "113/113 [==============================] - 2s 15ms/step - loss: 0.0011 - mse: 0.0011 - lr: 2.5000e-04\n",
      "Epoch 254/500\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 9.9344e-04 - mse: 9.9344e-04 - lr: 2.5000e-04\n",
      "Epoch 255/500\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 9.7511e-04 - mse: 9.7511e-04 - lr: 2.5000e-04\n",
      "Epoch 256/500\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 9.4679e-04 - mse: 9.4679e-04 - lr: 2.5000e-04\n",
      "Epoch 257/500\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 9.4329e-04 - mse: 9.4329e-04 - lr: 2.5000e-04\n",
      "Epoch 258/500\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 9.4357e-04 - mse: 9.4357e-04 - lr: 2.5000e-04\n",
      "Epoch 259/500\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 9.5086e-04 - mse: 9.5086e-04 - lr: 2.5000e-04\n",
      "Epoch 260/500\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 9.7771e-04 - mse: 9.7771e-04 - lr: 2.5000e-04\n",
      "Epoch 261/500\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0010 - mse: 0.0010 - lr: 2.5000e-04\n",
      "Epoch 262/500\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 0.0011 - mse: 0.0011 - lr: 2.5000e-04\n",
      "Epoch 263/500\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 0.0011 - mse: 0.0011 - lr: 2.5000e-04\n",
      "Epoch 264/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0011 - mse: 0.0011 - lr: 2.5000e-04\n",
      "Epoch 265/500\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0012 - mse: 0.0012 - lr: 1.2500e-04\n",
      "Epoch 266/500\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0012 - mse: 0.0012 - lr: 1.2500e-04\n",
      "Epoch 267/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0011 - mse: 0.0011 - lr: 1.2500e-04\n",
      "Epoch 268/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0010 - mse: 0.0010 - lr: 1.2500e-04\n",
      "Epoch 269/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0010 - mse: 0.0010 - lr: 1.2500e-04\n",
      "Epoch 270/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0010 - mse: 0.0010 - lr: 1.2500e-04\n",
      "Epoch 271/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 9.9904e-04 - mse: 9.9904e-04 - lr: 1.2500e-04\n",
      "Epoch 272/500\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 9.9124e-04 - mse: 9.9124e-04 - lr: 1.2500e-04\n",
      "Epoch 273/500\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 9.8315e-04 - mse: 9.8315e-04 - lr: 1.2500e-04\n",
      "Epoch 274/500\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 9.7602e-04 - mse: 9.7602e-04 - lr: 1.2500e-04\n",
      "Epoch 275/500\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 9.6581e-04 - mse: 9.6581e-04 - lr: 1.2500e-04\n",
      "Epoch 276/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 9.5727e-04 - mse: 9.5727e-04 - lr: 1.2500e-04\n",
      "Epoch 277/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 9.4845e-04 - mse: 9.4845e-04 - lr: 1.2500e-04\n",
      "Epoch 278/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 9.4071e-04 - mse: 9.4071e-04 - lr: 1.2500e-04\n",
      "Epoch 279/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 9.3400e-04 - mse: 9.3400e-04 - lr: 1.2500e-04\n",
      "Epoch 280/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 9.2822e-04 - mse: 9.2822e-04 - lr: 1.2500e-04\n",
      "Epoch 281/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 9.2353e-04 - mse: 9.2353e-04 - lr: 1.2500e-04\n",
      "Epoch 282/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 9.1900e-04 - mse: 9.1900e-04 - lr: 1.2500e-04\n",
      "Epoch 283/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 9.1638e-04 - mse: 9.1638e-04 - lr: 1.2500e-04\n",
      "Epoch 284/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 9.1347e-04 - mse: 9.1347e-04 - lr: 1.2500e-04\n",
      "Epoch 285/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 9.3191e-04 - mse: 9.3191e-04 - lr: 1.0000e-04\n",
      "Epoch 286/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 9.3285e-04 - mse: 9.3285e-04 - lr: 1.0000e-04\n",
      "Epoch 287/500\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 9.2244e-04 - mse: 9.2244e-04 - lr: 1.0000e-04\n",
      "Epoch 288/500\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 9.0493e-04 - mse: 9.0493e-04 - lr: 1.0000e-04\n",
      "Epoch 289/500\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 8.8630e-04 - mse: 8.8630e-04 - lr: 1.0000e-04\n",
      "Epoch 290/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 8.6954e-04 - mse: 8.6954e-04 - lr: 1.0000e-04\n",
      "Epoch 291/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 8.5420e-04 - mse: 8.5420e-04 - lr: 1.0000e-04\n",
      "Epoch 292/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 8.4094e-04 - mse: 8.4094e-04 - lr: 1.0000e-04\n",
      "Epoch 293/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 8.3013e-04 - mse: 8.3013e-04 - lr: 1.0000e-04\n",
      "Epoch 294/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 8.2036e-04 - mse: 8.2036e-04 - lr: 1.0000e-04\n",
      "Epoch 295/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 8.1156e-04 - mse: 8.1156e-04 - lr: 1.0000e-04\n",
      "Epoch 296/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 8.0339e-04 - mse: 8.0339e-04 - lr: 1.0000e-04\n",
      "Epoch 297/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 7.9611e-04 - mse: 7.9611e-04 - lr: 1.0000e-04\n",
      "Epoch 298/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 7.8919e-04 - mse: 7.8919e-04 - lr: 1.0000e-04\n",
      "Epoch 299/500\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 7.8314e-04 - mse: 7.8314e-04 - lr: 1.0000e-04\n",
      "Epoch 300/500\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 7.7730e-04 - mse: 7.7730e-04 - lr: 1.0000e-04\n",
      "Epoch 301/500\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 7.7179e-04 - mse: 7.7179e-04 - lr: 1.0000e-04\n",
      "Epoch 302/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 7.6711e-04 - mse: 7.6711e-04 - lr: 1.0000e-04\n",
      "Epoch 303/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 7.6269e-04 - mse: 7.6269e-04 - lr: 1.0000e-04\n",
      "Epoch 304/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 7.5911e-04 - mse: 7.5911e-04 - lr: 1.0000e-04\n",
      "Epoch 305/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 7.5564e-04 - mse: 7.5564e-04 - lr: 1.0000e-04\n",
      "Epoch 306/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 7.5210e-04 - mse: 7.5210e-04 - lr: 1.0000e-04\n",
      "Epoch 307/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 7.4938e-04 - mse: 7.4938e-04 - lr: 1.0000e-04\n",
      "Epoch 308/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 7.4647e-04 - mse: 7.4647e-04 - lr: 1.0000e-04\n",
      "Epoch 309/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 7.4385e-04 - mse: 7.4385e-04 - lr: 1.0000e-04\n",
      "Epoch 310/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 7.4190e-04 - mse: 7.4190e-04 - lr: 1.0000e-04\n",
      "Epoch 311/500\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 7.3934e-04 - mse: 7.3934e-04 - lr: 1.0000e-04\n",
      "Epoch 312/500\n",
      "113/113 [==============================] - 2s 14ms/step - loss: 7.3718e-04 - mse: 7.3718e-04 - lr: 1.0000e-04\n",
      "Epoch 313/500\n",
      "113/113 [==============================] - 2s 17ms/step - loss: 7.3489e-04 - mse: 7.3489e-04 - lr: 1.0000e-04\n",
      "Epoch 314/500\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 7.3340e-04 - mse: 7.3340e-04 - lr: 1.0000e-04\n",
      "Epoch 315/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 7.3180e-04 - mse: 7.3180e-04 - lr: 1.0000e-04\n",
      "Epoch 316/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 7.3071e-04 - mse: 7.3071e-04 - lr: 1.0000e-04\n",
      "Epoch 317/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 7.2901e-04 - mse: 7.2901e-04 - lr: 1.0000e-04\n",
      "Epoch 318/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 7.2839e-04 - mse: 7.2839e-04 - lr: 1.0000e-04\n",
      "Epoch 319/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 7.2758e-04 - mse: 7.2758e-04 - lr: 1.0000e-04\n",
      "Epoch 320/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 7.2662e-04 - mse: 7.2662e-04 - lr: 1.0000e-04\n",
      "Epoch 321/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 7.2579e-04 - mse: 7.2579e-04 - lr: 1.0000e-04\n",
      "Epoch 322/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 7.2558e-04 - mse: 7.2558e-04 - lr: 1.0000e-04\n",
      "Epoch 323/500\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 7.2492e-04 - mse: 7.2492e-04 - lr: 1.0000e-04\n",
      "Epoch 324/500\n",
      "113/113 [==============================] - 2s 15ms/step - loss: 7.2432e-04 - mse: 7.2432e-04 - lr: 1.0000e-04\n",
      "Epoch 325/500\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 7.2404e-04 - mse: 7.2404e-04 - lr: 1.0000e-04\n",
      "Epoch 326/500\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 7.2412e-04 - mse: 7.2412e-04 - lr: 1.0000e-04\n",
      "Epoch 327/500\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 7.2391e-04 - mse: 7.2391e-04 - lr: 1.0000e-04\n",
      "Epoch 328/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 7.2394e-04 - mse: 7.2394e-04 - lr: 1.0000e-04\n",
      "Epoch 329/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 7.2388e-04 - mse: 7.2388e-04 - lr: 1.0000e-04\n",
      "Epoch 330/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 7.2294e-04 - mse: 7.2294e-04 - lr: 1.0000e-04\n",
      "Epoch 331/500\n",
      "113/113 [==============================] - 2s 14ms/step - loss: 7.2283e-04 - mse: 7.2283e-04 - lr: 1.0000e-04\n",
      "Epoch 332/500\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 7.2241e-04 - mse: 7.2241e-04 - lr: 1.0000e-04\n",
      "Epoch 333/500\n",
      "113/113 [==============================] - 2s 17ms/step - loss: 7.2114e-04 - mse: 7.2114e-04 - lr: 1.0000e-04\n",
      "Epoch 334/500\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 7.1974e-04 - mse: 7.1974e-04 - lr: 1.0000e-04\n",
      "Epoch 335/500\n",
      "113/113 [==============================] - 2s 16ms/step - loss: 7.1796e-04 - mse: 7.1796e-04 - lr: 1.0000e-04\n",
      "Epoch 336/500\n",
      "113/113 [==============================] - 2s 14ms/step - loss: 7.1659e-04 - mse: 7.1659e-04 - lr: 1.0000e-04\n",
      "Epoch 337/500\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 7.1425e-04 - mse: 7.1425e-04 - lr: 1.0000e-04\n",
      "Epoch 338/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 7.1237e-04 - mse: 7.1237e-04 - lr: 1.0000e-04\n",
      "Epoch 339/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 7.0991e-04 - mse: 7.0991e-04 - lr: 1.0000e-04\n",
      "Epoch 340/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 7.0712e-04 - mse: 7.0712e-04 - lr: 1.0000e-04\n",
      "Epoch 341/500\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 7.0476e-04 - mse: 7.0476e-04 - lr: 1.0000e-04\n",
      "Epoch 342/500\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 7.0123e-04 - mse: 7.0123e-04 - lr: 1.0000e-04\n",
      "Epoch 343/500\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 6.9863e-04 - mse: 6.9863e-04 - lr: 1.0000e-04\n",
      "Epoch 344/500\n",
      "113/113 [==============================] - 2s 16ms/step - loss: 6.9539e-04 - mse: 6.9539e-04 - lr: 1.0000e-04\n",
      "Epoch 345/500\n",
      "113/113 [==============================] - 2s 15ms/step - loss: 6.9234e-04 - mse: 6.9234e-04 - lr: 1.0000e-04\n",
      "Epoch 346/500\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 6.8939e-04 - mse: 6.8939e-04 - lr: 1.0000e-04\n",
      "Epoch 347/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 6.8713e-04 - mse: 6.8713e-04 - lr: 1.0000e-04\n",
      "Epoch 348/500\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 6.8426e-04 - mse: 6.8426e-04 - lr: 1.0000e-04\n",
      "Epoch 349/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 6.8163e-04 - mse: 6.8163e-04 - lr: 1.0000e-04\n",
      "Epoch 350/500\n",
      "113/113 [==============================] - 1s 13ms/step - loss: 6.7897e-04 - mse: 6.7897e-04 - lr: 1.0000e-04\n",
      "Epoch 351/500\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 6.7637e-04 - mse: 6.7637e-04 - lr: 1.0000e-04\n",
      "Epoch 352/500\n",
      "113/113 [==============================] - 2s 15ms/step - loss: 6.7376e-04 - mse: 6.7376e-04 - lr: 1.0000e-04\n",
      "Epoch 353/500\n",
      "113/113 [==============================] - 2s 17ms/step - loss: 6.7129e-04 - mse: 6.7129e-04 - lr: 1.0000e-04\n",
      "Epoch 354/500\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 6.6851e-04 - mse: 6.6851e-04 - lr: 1.0000e-04\n",
      "Epoch 355/500\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 6.6535e-04 - mse: 6.6535e-04 - lr: 1.0000e-04\n",
      "Epoch 356/500\n",
      "113/113 [==============================] - 1s 13ms/step - loss: 6.6212e-04 - mse: 6.6212e-04 - lr: 1.0000e-04\n",
      "Epoch 357/500\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 6.5977e-04 - mse: 6.5977e-04 - lr: 1.0000e-04\n",
      "Epoch 358/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 6.5709e-04 - mse: 6.5709e-04 - lr: 1.0000e-04\n",
      "Epoch 359/500\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 6.5436e-04 - mse: 6.5436e-04 - lr: 1.0000e-04\n",
      "Epoch 360/500\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 6.5171e-04 - mse: 6.5171e-04 - lr: 1.0000e-04\n",
      "Epoch 361/500\n",
      "113/113 [==============================] - 2s 16ms/step - loss: 6.4877e-04 - mse: 6.4877e-04 - lr: 1.0000e-04\n",
      "Epoch 362/500\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 6.4663e-04 - mse: 6.4663e-04 - lr: 1.0000e-04\n",
      "Epoch 363/500\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 6.4387e-04 - mse: 6.4387e-04 - lr: 1.0000e-04\n",
      "Epoch 364/500\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 6.4170e-04 - mse: 6.4170e-04 - lr: 1.0000e-04\n",
      "Epoch 365/500\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 6.3976e-04 - mse: 6.3976e-04 - lr: 1.0000e-04\n",
      "Epoch 366/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 6.3756e-04 - mse: 6.3756e-04 - lr: 1.0000e-04\n",
      "Epoch 367/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 6.3611e-04 - mse: 6.3611e-04 - lr: 1.0000e-04\n",
      "Epoch 368/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 6.3411e-04 - mse: 6.3411e-04 - lr: 1.0000e-04\n",
      "Epoch 369/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 6.3237e-04 - mse: 6.3237e-04 - lr: 1.0000e-04\n",
      "Epoch 370/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 6.3003e-04 - mse: 6.3003e-04 - lr: 1.0000e-04\n",
      "Epoch 371/500\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 6.2722e-04 - mse: 6.2722e-04 - lr: 1.0000e-04\n",
      "Epoch 372/500\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 6.2409e-04 - mse: 6.2409e-04 - lr: 1.0000e-04\n",
      "Epoch 373/500\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 6.2067e-04 - mse: 6.2067e-04 - lr: 1.0000e-04\n",
      "Epoch 374/500\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 6.1650e-04 - mse: 6.1650e-04 - lr: 1.0000e-04\n",
      "Epoch 375/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 6.1271e-04 - mse: 6.1271e-04 - lr: 1.0000e-04\n",
      "Epoch 376/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 6.0835e-04 - mse: 6.0835e-04 - lr: 1.0000e-04\n",
      "Epoch 377/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 6.0447e-04 - mse: 6.0447e-04 - lr: 1.0000e-04\n",
      "Epoch 378/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 6.0014e-04 - mse: 6.0014e-04 - lr: 1.0000e-04\n",
      "Epoch 379/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 5.9582e-04 - mse: 5.9582e-04 - lr: 1.0000e-04\n",
      "Epoch 380/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 5.9182e-04 - mse: 5.9182e-04 - lr: 1.0000e-04\n",
      "Epoch 381/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 5.8853e-04 - mse: 5.8853e-04 - lr: 1.0000e-04\n",
      "Epoch 382/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 5.8435e-04 - mse: 5.8435e-04 - lr: 1.0000e-04\n",
      "Epoch 383/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 5.8127e-04 - mse: 5.8127e-04 - lr: 1.0000e-04\n",
      "Epoch 384/500\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 5.7814e-04 - mse: 5.7814e-04 - lr: 1.0000e-04\n",
      "Epoch 385/500\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 5.7543e-04 - mse: 5.7543e-04 - lr: 1.0000e-04\n",
      "Epoch 386/500\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 5.7284e-04 - mse: 5.7284e-04 - lr: 1.0000e-04\n",
      "Epoch 387/500\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 5.6986e-04 - mse: 5.6986e-04 - lr: 1.0000e-04\n",
      "Epoch 388/500\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 5.6723e-04 - mse: 5.6723e-04 - lr: 1.0000e-04\n",
      "Epoch 389/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 5.6492e-04 - mse: 5.6492e-04 - lr: 1.0000e-04\n",
      "Epoch 390/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 5.6198e-04 - mse: 5.6198e-04 - lr: 1.0000e-04\n",
      "Epoch 391/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 5.5984e-04 - mse: 5.5984e-04 - lr: 1.0000e-04\n",
      "Epoch 392/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 5.5796e-04 - mse: 5.5796e-04 - lr: 1.0000e-04\n",
      "Epoch 393/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 5.5563e-04 - mse: 5.5563e-04 - lr: 1.0000e-04\n",
      "Epoch 394/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 5.5361e-04 - mse: 5.5361e-04 - lr: 1.0000e-04\n",
      "Epoch 395/500\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 5.5167e-04 - mse: 5.5167e-04 - lr: 1.0000e-04\n",
      "Epoch 396/500\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 5.4951e-04 - mse: 5.4951e-04 - lr: 1.0000e-04\n",
      "Epoch 397/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 5.4799e-04 - mse: 5.4799e-04 - lr: 1.0000e-04\n",
      "Epoch 398/500\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 5.4617e-04 - mse: 5.4617e-04 - lr: 1.0000e-04\n",
      "Epoch 399/500\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 5.4416e-04 - mse: 5.4416e-04 - lr: 1.0000e-04\n",
      "Epoch 400/500\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 5.4267e-04 - mse: 5.4267e-04 - lr: 1.0000e-04\n",
      "Epoch 401/500\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 5.4071e-04 - mse: 5.4071e-04 - lr: 1.0000e-04\n",
      "Epoch 402/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 5.3942e-04 - mse: 5.3942e-04 - lr: 1.0000e-04\n",
      "Epoch 403/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 5.3767e-04 - mse: 5.3767e-04 - lr: 1.0000e-04\n",
      "Epoch 404/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 5.3608e-04 - mse: 5.3608e-04 - lr: 1.0000e-04\n",
      "Epoch 405/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 5.3424e-04 - mse: 5.3424e-04 - lr: 1.0000e-04\n",
      "Epoch 406/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 5.3254e-04 - mse: 5.3254e-04 - lr: 1.0000e-04\n",
      "Epoch 407/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 5.3090e-04 - mse: 5.3090e-04 - lr: 1.0000e-04\n",
      "Epoch 408/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 5.2930e-04 - mse: 5.2930e-04 - lr: 1.0000e-04\n",
      "Epoch 409/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 5.2756e-04 - mse: 5.2756e-04 - lr: 1.0000e-04\n",
      "Epoch 410/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 5.2593e-04 - mse: 5.2593e-04 - lr: 1.0000e-04\n",
      "Epoch 411/500\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 5.2492e-04 - mse: 5.2492e-04 - lr: 1.0000e-04\n",
      "Epoch 412/500\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 5.2359e-04 - mse: 5.2359e-04 - lr: 1.0000e-04\n",
      "Epoch 413/500\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 5.2228e-04 - mse: 5.2228e-04 - lr: 1.0000e-04\n",
      "Epoch 414/500\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 5.2122e-04 - mse: 5.2122e-04 - lr: 1.0000e-04\n",
      "Epoch 415/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 5.1982e-04 - mse: 5.1982e-04 - lr: 1.0000e-04\n",
      "Epoch 416/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 5.1876e-04 - mse: 5.1876e-04 - lr: 1.0000e-04\n",
      "Epoch 417/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 5.1749e-04 - mse: 5.1749e-04 - lr: 1.0000e-04\n",
      "Epoch 418/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 5.1688e-04 - mse: 5.1688e-04 - lr: 1.0000e-04\n",
      "Epoch 419/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 5.1532e-04 - mse: 5.1532e-04 - lr: 1.0000e-04\n",
      "Epoch 420/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 5.1397e-04 - mse: 5.1397e-04 - lr: 1.0000e-04\n",
      "Epoch 421/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 5.1342e-04 - mse: 5.1342e-04 - lr: 1.0000e-04\n",
      "Epoch 422/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 5.1215e-04 - mse: 5.1215e-04 - lr: 1.0000e-04\n",
      "Epoch 423/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 5.1076e-04 - mse: 5.1076e-04 - lr: 1.0000e-04\n",
      "Epoch 424/500\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 5.0994e-04 - mse: 5.0994e-04 - lr: 1.0000e-04\n",
      "Epoch 425/500\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 5.0884e-04 - mse: 5.0884e-04 - lr: 1.0000e-04\n",
      "Epoch 426/500\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 5.0750e-04 - mse: 5.0750e-04 - lr: 1.0000e-04\n",
      "Epoch 427/500\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 5.0686e-04 - mse: 5.0686e-04 - lr: 1.0000e-04\n",
      "Epoch 428/500\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 5.0568e-04 - mse: 5.0568e-04 - lr: 1.0000e-04\n",
      "Epoch 429/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 5.0483e-04 - mse: 5.0483e-04 - lr: 1.0000e-04\n",
      "Epoch 430/500\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 5.0381e-04 - mse: 5.0381e-04 - lr: 1.0000e-04\n",
      "Epoch 431/500\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 5.0288e-04 - mse: 5.0288e-04 - lr: 1.0000e-04\n",
      "Epoch 432/500\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 5.0163e-04 - mse: 5.0163e-04 - lr: 1.0000e-04\n",
      "Epoch 433/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 5.0114e-04 - mse: 5.0114e-04 - lr: 1.0000e-04\n",
      "Epoch 434/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 4.9989e-04 - mse: 4.9989e-04 - lr: 1.0000e-04\n",
      "Epoch 435/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 4.9956e-04 - mse: 4.9956e-04 - lr: 1.0000e-04\n",
      "Epoch 436/500\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 4.9835e-04 - mse: 4.9835e-04 - lr: 1.0000e-04\n",
      "Epoch 437/500\n",
      "113/113 [==============================] - 1s 13ms/step - loss: 4.9758e-04 - mse: 4.9758e-04 - lr: 1.0000e-04\n",
      "Epoch 438/500\n",
      "113/113 [==============================] - 2s 17ms/step - loss: 4.9709e-04 - mse: 4.9709e-04 - lr: 1.0000e-04\n",
      "Epoch 439/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 4.9650e-04 - mse: 4.9650e-04 - lr: 1.0000e-04\n",
      "Epoch 440/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 4.9600e-04 - mse: 4.9600e-04 - lr: 1.0000e-04\n",
      "Epoch 441/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 4.9536e-04 - mse: 4.9536e-04 - lr: 1.0000e-04\n",
      "Epoch 442/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 4.9488e-04 - mse: 4.9488e-04 - lr: 1.0000e-04\n",
      "Epoch 443/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 4.9522e-04 - mse: 4.9522e-04 - lr: 1.0000e-04\n",
      "Epoch 444/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 4.9465e-04 - mse: 4.9465e-04 - lr: 1.0000e-04\n",
      "Epoch 445/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 4.9526e-04 - mse: 4.9526e-04 - lr: 1.0000e-04\n",
      "Epoch 446/500\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 4.9566e-04 - mse: 4.9566e-04 - lr: 1.0000e-04\n",
      "Epoch 447/500\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 4.9638e-04 - mse: 4.9638e-04 - lr: 1.0000e-04\n",
      "Epoch 448/500\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 4.9733e-04 - mse: 4.9733e-04 - lr: 1.0000e-04\n",
      "Epoch 449/500\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 4.9921e-04 - mse: 4.9921e-04 - lr: 1.0000e-04\n",
      "Epoch 450/500\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 5.0158e-04 - mse: 5.0158e-04 - lr: 1.0000e-04\n",
      "Epoch 451/500\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 5.0530e-04 - mse: 5.0530e-04 - lr: 1.0000e-04\n",
      "Epoch 452/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 5.1047e-04 - mse: 5.1047e-04 - lr: 1.0000e-04\n",
      "Epoch 453/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 5.1816e-04 - mse: 5.1816e-04 - lr: 1.0000e-04\n",
      "Epoch 454/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 5.2759e-04 - mse: 5.2759e-04 - lr: 1.0000e-04\n",
      "Epoch 455/500\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 5.3913e-04 - mse: 5.3913e-04 - lr: 1.0000e-04\n",
      "Epoch 456/500\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 5.4967e-04 - mse: 5.4967e-04 - lr: 1.0000e-04\n",
      "Epoch 457/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 5.5284e-04 - mse: 5.5284e-04 - lr: 1.0000e-04\n",
      "Epoch 458/500\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 5.5225e-04 - mse: 5.5225e-04 - lr: 1.0000e-04\n",
      "Epoch 459/500\n",
      "113/113 [==============================] - 1s 13ms/step - loss: 5.4885e-04 - mse: 5.4885e-04 - lr: 1.0000e-04\n",
      "Epoch 460/500\n",
      "113/113 [==============================] - 2s 18ms/step - loss: 5.4549e-04 - mse: 5.4549e-04 - lr: 1.0000e-04\n",
      "Epoch 461/500\n",
      "113/113 [==============================] - 2s 15ms/step - loss: 5.4480e-04 - mse: 5.4480e-04 - lr: 1.0000e-04\n",
      "Epoch 462/500\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 5.4410e-04 - mse: 5.4410e-04 - lr: 1.0000e-04\n",
      "Epoch 463/500\n",
      "113/113 [==============================] - 1s 13ms/step - loss: 5.4547e-04 - mse: 5.4547e-04 - lr: 1.0000e-04\n",
      "Epoch 464/500\n",
      "113/113 [==============================] - 1s 13ms/step - loss: 5.4825e-04 - mse: 5.4825e-04 - lr: 1.0000e-04\n",
      "Epoch 465/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 5.5292e-04 - mse: 5.5292e-04 - lr: 1.0000e-04\n",
      "Epoch 466/500\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 5.5974e-04 - mse: 5.5974e-04 - lr: 1.0000e-04\n",
      "Epoch 467/500\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 5.6877e-04 - mse: 5.6877e-04 - lr: 1.0000e-04\n",
      "Epoch 468/500\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 5.7615e-04 - mse: 5.7615e-04 - lr: 1.0000e-04\n",
      "Epoch 469/500\n",
      "113/113 [==============================] - 2s 17ms/step - loss: 5.8001e-04 - mse: 5.8001e-04 - lr: 1.0000e-04\n",
      "Epoch 470/500\n",
      "113/113 [==============================] - 2s 14ms/step - loss: 5.7604e-04 - mse: 5.7604e-04 - lr: 1.0000e-04\n",
      "Epoch 471/500\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 5.6803e-04 - mse: 5.6803e-04 - lr: 1.0000e-04\n",
      "Epoch 472/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 5.5929e-04 - mse: 5.5929e-04 - lr: 1.0000e-04\n",
      "Epoch 473/500\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 5.5172e-04 - mse: 5.5172e-04 - lr: 1.0000e-04\n",
      "Epoch 474/500\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 5.4442e-04 - mse: 5.4442e-04 - lr: 1.0000e-04\n",
      "Epoch 475/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 5.3826e-04 - mse: 5.3826e-04 - lr: 1.0000e-04\n",
      "Epoch 476/500\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 5.3183e-04 - mse: 5.3183e-04 - lr: 1.0000e-04\n",
      "Epoch 477/500\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 5.2542e-04 - mse: 5.2542e-04 - lr: 1.0000e-04\n",
      "Epoch 478/500\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 5.1912e-04 - mse: 5.1912e-04 - lr: 1.0000e-04\n",
      "Epoch 479/500\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 5.1346e-04 - mse: 5.1346e-04 - lr: 1.0000e-04\n",
      "Epoch 480/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 5.0757e-04 - mse: 5.0757e-04 - lr: 1.0000e-04\n",
      "Epoch 481/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 5.0154e-04 - mse: 5.0154e-04 - lr: 1.0000e-04\n",
      "Epoch 482/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 4.9636e-04 - mse: 4.9636e-04 - lr: 1.0000e-04\n",
      "Epoch 483/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 4.9095e-04 - mse: 4.9095e-04 - lr: 1.0000e-04\n",
      "Epoch 484/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 4.8555e-04 - mse: 4.8555e-04 - lr: 1.0000e-04\n",
      "Epoch 485/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 4.8025e-04 - mse: 4.8025e-04 - lr: 1.0000e-04\n",
      "Epoch 486/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 4.7550e-04 - mse: 4.7550e-04 - lr: 1.0000e-04\n",
      "Epoch 487/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 4.7047e-04 - mse: 4.7047e-04 - lr: 1.0000e-04\n",
      "Epoch 488/500\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 4.6607e-04 - mse: 4.6607e-04 - lr: 1.0000e-04\n",
      "Epoch 489/500\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 4.6146e-04 - mse: 4.6146e-04 - lr: 1.0000e-04\n",
      "Epoch 490/500\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 4.5690e-04 - mse: 4.5690e-04 - lr: 1.0000e-04\n",
      "Epoch 491/500\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 4.5270e-04 - mse: 4.5270e-04 - lr: 1.0000e-04\n",
      "Epoch 492/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 4.4859e-04 - mse: 4.4859e-04 - lr: 1.0000e-04\n",
      "Epoch 493/500\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 4.4507e-04 - mse: 4.4507e-04 - lr: 1.0000e-04\n",
      "Epoch 494/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 4.4148e-04 - mse: 4.4148e-04 - lr: 1.0000e-04\n",
      "Epoch 495/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 4.3841e-04 - mse: 4.3841e-04 - lr: 1.0000e-04\n",
      "Epoch 496/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 4.3498e-04 - mse: 4.3498e-04 - lr: 1.0000e-04\n",
      "Epoch 497/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 4.3158e-04 - mse: 4.3158e-04 - lr: 1.0000e-04\n",
      "Epoch 498/500\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 4.2894e-04 - mse: 4.2894e-04 - lr: 1.0000e-04\n",
      "Epoch 499/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 4.2643e-04 - mse: 4.2643e-04 - lr: 1.0000e-04\n",
      "Epoch 500/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 4.2380e-04 - mse: 4.2380e-04 - lr: 1.0000e-04\n"
     ]
    }
   ],
   "source": [
    "epochs = 500\n",
    "batch_size = 32\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ReduceLROnPlateau(monitor=\"loss\", factor=0.5, patience=20, min_lr=0.0001),\n",
    "]\n",
    "model_fill.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"mse\",\n",
    "    metrics=[\"mse\"],\n",
    ")\n",
    "history = model_fill.fit(train_ds,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "OyPFh9UYBWdx",
    "outputId": "b0ea3d05-402a-475d-bd35-f1676d131e62"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "metric = \"mse\"\n",
    "plt.plot(history.history[metric])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nWAapOSFYiVP"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vOL_ndnmsOjp"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mHR4ic0hsOmK"
   },
   "outputs": [],
   "source": [
    "df_train_nan = pd.read_csv('/content/drive/MyDrive/train_nan.csv', header=None)\n",
    "df_test_nan = pd.read_csv('/content/drive/MyDrive/test_nan.csv', header=None)\n",
    "\n",
    "df_train_nan_mask = df_train_nan.isna().to_numpy()*1.0\n",
    "df_train_nan_mask = df_train_nan_mask[:, 1:]\n",
    "\n",
    "df_test_nan_mask = df_test_nan.isna().to_numpy()*1.0\n",
    "df_test_nan_mask = df_test_nan_mask[:, 1:]\n",
    "\n",
    "df_train_nan = df_train_nan.fillna(1000)\n",
    "df_test_nan  = df_test_nan.fillna(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CEZAxNyBtizy"
   },
   "outputs": [],
   "source": [
    "df_train_nan = df_train_nan.to_numpy()\n",
    "y_train = df_train_nan[:, 0]\n",
    "x_train = df_train_nan[:, 1:]\n",
    "y_train = y_train.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OQd0MF2bsOof"
   },
   "outputs": [],
   "source": [
    "df_test_nan = df_test_nan.to_numpy()\n",
    "y_test = df_test_nan[:, 0]\n",
    "x_test = df_test_nan[:, 1:]\n",
    "y_test = y_test.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ChU3FOqGt_aP"
   },
   "outputs": [],
   "source": [
    "y_train[y_train == -1] = 0\n",
    "y_test[y_test == -1] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JT93DE3hzKP9",
    "outputId": "6cea81ad-c097-4154-a29f-25ddd79a12e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3601, 500, 1)\n",
      "(3601, 500)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(df_train_nan_mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ujxgzayOsOqo"
   },
   "outputs": [],
   "source": [
    "x_train = x_train.reshape((x_train.shape[0], x_train.shape[1], 1))\n",
    "df_train_nan_mask = df_train_nan_mask.reshape((df_train_nan_mask.shape[0], df_train_nan_mask.shape[1], 1))\n",
    "\n",
    "x_test = x_test.reshape((x_test.shape[0], x_test.shape[1], 1))\n",
    "df_test_nan_mask = df_test_nan_mask.reshape((df_test_nan_mask.shape[0], df_test_nan_mask.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "58uhKZu_8HFq",
    "outputId": "2e0fdb3a-5861-4f0e-a060-f7939c4b9f52"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3601, 500, 2)\n",
      "(1320, 500, 2)\n"
     ]
    }
   ],
   "source": [
    "x_train = np.concatenate([x_train, df_train_nan_mask], axis=2)\n",
    "x_test  = np.concatenate([x_test, df_test_nan_mask], axis=2)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rQMor4ybsOtG",
    "outputId": "0ef025bd-93ac-4d71-f0ab-34c1a2a02f20"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3601, 500)\n",
      "(1320, 500)\n"
     ]
    }
   ],
   "source": [
    "x_train_fill = model_fill(x_train, training=False).numpy()\n",
    "x_test_fill  = model_fill(x_test, training=False).numpy()\n",
    "\n",
    "print(x_train_fill.shape)\n",
    "print(x_test_fill.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "whHQEyVqDSYj"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yFzRmql7DSbg",
    "outputId": "c29ebb1c-f183-44d0-ea33-0bf0aca2c874"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3601, 501)\n"
     ]
    }
   ],
   "source": [
    "data_train = np.concatenate([y_train.reshape(3601, 1), x_train_fill], axis=1)\n",
    "print(data_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1a3TmR82DSd6"
   },
   "outputs": [],
   "source": [
    "np.savetxt(\"/content/drive/MyDrive/train_filled.csv\", data_train, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mSrGtx-vDSfv"
   },
   "outputs": [],
   "source": [
    "data_test = np.concatenate([y_test.reshape(1320, 1), x_test_fill], axis=1)\n",
    "np.savetxt(\"/content/drive/MyDrive/test_filled.csv\", data_test, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L_3yw5E-DSiE"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rkp1to4ZDSkW"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DG-qKmwY9MoV",
    "outputId": "abaedfec-fada-4a20-f534-e9058e02e42f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-7.9717168e-01 -6.6439208e-01 -3.7301463e-01  4.0815121e-02\n",
      "  5.2693599e-01  9.8428794e-01  1.3531202e+00  1.5781078e+00\n",
      "  1.6592509e+00  1.6408093e+00  1.5522896e+00  1.4379516e+00\n",
      "  1.2793537e+00  1.0691193e+00  1.0000000e+03  1.0000000e+03\n",
      " -3.0072351e-01]\n"
     ]
    }
   ],
   "source": [
    "print(x_train[0,:17,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gzEplRAl9Mq1",
    "outputId": "f6d96b82-eb0c-4b55-bc25-758242e3d5e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.79717165 -0.66439205 -0.37301463  0.04081512  0.526936    0.9842879\n",
      "  1.3531202   1.5781078   1.6592509   1.6408093   1.5522896   1.4379516\n",
      "  1.2793537   1.0691193   0.51193243  0.07317767 -0.30072352]\n"
     ]
    }
   ],
   "source": [
    "print(x_train_fill[0,:17])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8Bjgp_N09MyF"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XxxcMoyRsOvT"
   },
   "outputs": [],
   "source": [
    "idx = np.random.permutation(len(x_train_fill))\n",
    "x_train_fill = x_train_fill[idx]\n",
    "y_train = y_train[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BXt6cJW0_efc",
    "outputId": "102e3afd-5afd-432a-8f57-f1518a51b9e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3601, 500, 1)\n",
      "(1320, 500, 1)\n"
     ]
    }
   ],
   "source": [
    "x_train_fill = x_train_fill.reshape((x_train_fill.shape[0], x_train_fill.shape[1], 1))\n",
    "x_test_fill  = x_test_fill.reshape((x_test_fill.shape[0], x_test_fill.shape[1], 1))\n",
    "\n",
    "print(x_train_fill.shape)\n",
    "print(x_test_fill.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3_g7634HsOx_"
   },
   "outputs": [],
   "source": [
    "train_ds_c = tf.data.Dataset.from_tensor_slices((x_train_fill, y_train)).batch(32)\n",
    "train_ds_c = train_ds_c.cache().prefetch(buffer_size=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uza1268tYipY",
    "outputId": "9bd05f7c-f375-4be5-c43b-d4892bb56268"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 500, 2)\n",
      "(32, 500, 1)\n"
     ]
    }
   ],
   "source": [
    "for x,y in train_ds_c:\n",
    "  print(x.shape)\n",
    "  print(y.shape)\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YoKBDYSYYizC"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GCsJYI7dYi5A",
    "outputId": "77b5a111-8062-4c22-e2b8-2b054afb000f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_11 (InputLayer)       [(None, 500, 1)]          0         \n",
      "                                                                 \n",
      " conv1d_34 (Conv1D)          (None, 500, 64)           256       \n",
      "                                                                 \n",
      " batch_normalization_27 (Bat  (None, 500, 64)          256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " re_lu_13 (ReLU)             (None, 500, 64)           0         \n",
      "                                                                 \n",
      " conv1d_35 (Conv1D)          (None, 500, 64)           12352     \n",
      "                                                                 \n",
      " batch_normalization_28 (Bat  (None, 500, 64)          256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " re_lu_14 (ReLU)             (None, 500, 64)           0         \n",
      "                                                                 \n",
      " conv1d_36 (Conv1D)          (None, 500, 64)           12352     \n",
      "                                                                 \n",
      " batch_normalization_29 (Bat  (None, 500, 64)          256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " re_lu_15 (ReLU)             (None, 500, 64)           0         \n",
      "                                                                 \n",
      " global_average_pooling1d_2   (None, 64)               0         \n",
      " (GlobalAveragePooling1D)                                        \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25,858\n",
      "Trainable params: 25,474\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build a model\n",
    "\n",
    "input_layer = keras.layers.Input((500, 1))\n",
    "\n",
    "x = keras.layers.Conv1D(filters=64, kernel_size=3, padding=\"same\")(input_layer)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.ReLU()(x)\n",
    "\n",
    "x = keras.layers.Conv1D(filters=64, kernel_size=3, padding=\"same\")(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.ReLU()(x)\n",
    "\n",
    "x = keras.layers.Conv1D(filters=64, kernel_size=3, padding=\"same\")(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.ReLU()(x)\n",
    "\n",
    "x = keras.layers.GlobalAveragePooling1D()(x)\n",
    "x = keras.layers.Dense(2, activation=\"softmax\")(x)\n",
    "\n",
    "model_c = keras.models.Model(inputs=input_layer, outputs=x)\n",
    "model_c.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0WOipECjiT3D"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "T0L-P2h3iT5h",
    "outputId": "7d7e89d5-af92-44c0-bf3d-d97dda09a73d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "113/113 [==============================] - 4s 11ms/step - loss: 0.6972 - sparse_categorical_accuracy: 0.5054 - val_loss: 0.6944 - val_sparse_categorical_accuracy: 0.5159 - lr: 0.0010\n",
      "Epoch 2/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.6952 - sparse_categorical_accuracy: 0.5057 - val_loss: 0.6926 - val_sparse_categorical_accuracy: 0.5159 - lr: 0.0010\n",
      "Epoch 3/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.6934 - sparse_categorical_accuracy: 0.5057 - val_loss: 0.7186 - val_sparse_categorical_accuracy: 0.5159 - lr: 0.0010\n",
      "Epoch 4/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.6962 - sparse_categorical_accuracy: 0.5096 - val_loss: 0.6925 - val_sparse_categorical_accuracy: 0.4879 - lr: 0.0010\n",
      "Epoch 5/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.6934 - sparse_categorical_accuracy: 0.5018 - val_loss: 0.6907 - val_sparse_categorical_accuracy: 0.5636 - lr: 0.0010\n",
      "Epoch 6/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.6947 - sparse_categorical_accuracy: 0.5057 - val_loss: 0.6954 - val_sparse_categorical_accuracy: 0.4970 - lr: 0.0010\n",
      "Epoch 7/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.6935 - sparse_categorical_accuracy: 0.5190 - val_loss: 0.6929 - val_sparse_categorical_accuracy: 0.4886 - lr: 0.0010\n",
      "Epoch 8/500\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 0.6948 - sparse_categorical_accuracy: 0.5168 - val_loss: 0.6916 - val_sparse_categorical_accuracy: 0.5341 - lr: 0.0010\n",
      "Epoch 9/500\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.6935 - sparse_categorical_accuracy: 0.5076 - val_loss: 0.7060 - val_sparse_categorical_accuracy: 0.4841 - lr: 0.0010\n",
      "Epoch 10/500\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.6934 - sparse_categorical_accuracy: 0.5093 - val_loss: 0.7091 - val_sparse_categorical_accuracy: 0.4841 - lr: 0.0010\n",
      "Epoch 11/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.6931 - sparse_categorical_accuracy: 0.5096 - val_loss: 0.6935 - val_sparse_categorical_accuracy: 0.5326 - lr: 0.0010\n",
      "Epoch 12/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.6939 - sparse_categorical_accuracy: 0.5054 - val_loss: 0.6923 - val_sparse_categorical_accuracy: 0.5053 - lr: 0.0010\n",
      "Epoch 13/500\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.6940 - sparse_categorical_accuracy: 0.5137 - val_loss: 0.6966 - val_sparse_categorical_accuracy: 0.5159 - lr: 0.0010\n",
      "Epoch 14/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.6934 - sparse_categorical_accuracy: 0.5093 - val_loss: 0.6936 - val_sparse_categorical_accuracy: 0.5333 - lr: 0.0010\n",
      "Epoch 15/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.6927 - sparse_categorical_accuracy: 0.5129 - val_loss: 0.7049 - val_sparse_categorical_accuracy: 0.4841 - lr: 0.0010\n",
      "Epoch 16/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.6933 - sparse_categorical_accuracy: 0.5101 - val_loss: 0.6950 - val_sparse_categorical_accuracy: 0.5159 - lr: 0.0010\n",
      "Epoch 17/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.6933 - sparse_categorical_accuracy: 0.5140 - val_loss: 0.6960 - val_sparse_categorical_accuracy: 0.4985 - lr: 0.0010\n",
      "Epoch 18/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.6932 - sparse_categorical_accuracy: 0.5157 - val_loss: 0.6949 - val_sparse_categorical_accuracy: 0.5159 - lr: 0.0010\n",
      "Epoch 19/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.6939 - sparse_categorical_accuracy: 0.5051 - val_loss: 0.6984 - val_sparse_categorical_accuracy: 0.4947 - lr: 0.0010\n",
      "Epoch 20/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.6932 - sparse_categorical_accuracy: 0.5026 - val_loss: 0.7016 - val_sparse_categorical_accuracy: 0.4864 - lr: 0.0010\n",
      "Epoch 21/500\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 0.6922 - sparse_categorical_accuracy: 0.5287 - val_loss: 0.6961 - val_sparse_categorical_accuracy: 0.5174 - lr: 0.0010\n",
      "Epoch 22/500\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.6935 - sparse_categorical_accuracy: 0.5143 - val_loss: 0.6953 - val_sparse_categorical_accuracy: 0.5159 - lr: 0.0010\n",
      "Epoch 23/500\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 0.6947 - sparse_categorical_accuracy: 0.5126 - val_loss: 0.6960 - val_sparse_categorical_accuracy: 0.4689 - lr: 0.0010\n",
      "Epoch 24/500\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.6935 - sparse_categorical_accuracy: 0.5087 - val_loss: 0.6930 - val_sparse_categorical_accuracy: 0.5371 - lr: 0.0010\n",
      "Epoch 25/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.6927 - sparse_categorical_accuracy: 0.5149 - val_loss: 0.7112 - val_sparse_categorical_accuracy: 0.4841 - lr: 0.0010\n",
      "Epoch 26/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.6928 - sparse_categorical_accuracy: 0.5240 - val_loss: 0.6965 - val_sparse_categorical_accuracy: 0.4841 - lr: 5.0000e-04\n",
      "Epoch 27/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.6920 - sparse_categorical_accuracy: 0.5135 - val_loss: 0.6972 - val_sparse_categorical_accuracy: 0.5159 - lr: 5.0000e-04\n",
      "Epoch 28/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.6924 - sparse_categorical_accuracy: 0.5126 - val_loss: 0.6927 - val_sparse_categorical_accuracy: 0.5030 - lr: 5.0000e-04\n",
      "Epoch 29/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.6919 - sparse_categorical_accuracy: 0.5215 - val_loss: 0.6972 - val_sparse_categorical_accuracy: 0.4962 - lr: 5.0000e-04\n",
      "Epoch 30/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.6915 - sparse_categorical_accuracy: 0.5182 - val_loss: 0.6942 - val_sparse_categorical_accuracy: 0.5015 - lr: 5.0000e-04\n",
      "Epoch 31/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.6923 - sparse_categorical_accuracy: 0.5162 - val_loss: 0.6938 - val_sparse_categorical_accuracy: 0.5424 - lr: 5.0000e-04\n",
      "Epoch 32/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.6918 - sparse_categorical_accuracy: 0.5210 - val_loss: 0.6974 - val_sparse_categorical_accuracy: 0.5098 - lr: 5.0000e-04\n",
      "Epoch 33/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.6920 - sparse_categorical_accuracy: 0.5215 - val_loss: 0.6940 - val_sparse_categorical_accuracy: 0.4795 - lr: 5.0000e-04\n",
      "Epoch 34/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.6912 - sparse_categorical_accuracy: 0.5249 - val_loss: 0.6968 - val_sparse_categorical_accuracy: 0.5121 - lr: 5.0000e-04\n",
      "Epoch 35/500\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.6917 - sparse_categorical_accuracy: 0.5199 - val_loss: 0.6980 - val_sparse_categorical_accuracy: 0.5083 - lr: 5.0000e-04\n",
      "Epoch 36/500\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.6918 - sparse_categorical_accuracy: 0.5160 - val_loss: 0.6907 - val_sparse_categorical_accuracy: 0.4917 - lr: 5.0000e-04\n",
      "Epoch 37/500\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.6929 - sparse_categorical_accuracy: 0.5140 - val_loss: 0.6944 - val_sparse_categorical_accuracy: 0.4955 - lr: 5.0000e-04\n",
      "Epoch 38/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.6916 - sparse_categorical_accuracy: 0.5226 - val_loss: 0.6946 - val_sparse_categorical_accuracy: 0.5098 - lr: 5.0000e-04\n",
      "Epoch 39/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.6914 - sparse_categorical_accuracy: 0.5221 - val_loss: 0.6954 - val_sparse_categorical_accuracy: 0.5212 - lr: 5.0000e-04\n",
      "Epoch 40/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.6915 - sparse_categorical_accuracy: 0.5171 - val_loss: 0.7025 - val_sparse_categorical_accuracy: 0.5023 - lr: 5.0000e-04\n",
      "Epoch 41/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.6915 - sparse_categorical_accuracy: 0.5218 - val_loss: 0.6961 - val_sparse_categorical_accuracy: 0.5114 - lr: 5.0000e-04\n",
      "Epoch 42/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.6920 - sparse_categorical_accuracy: 0.5182 - val_loss: 0.6935 - val_sparse_categorical_accuracy: 0.4871 - lr: 5.0000e-04\n",
      "Epoch 43/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.6917 - sparse_categorical_accuracy: 0.5229 - val_loss: 0.7012 - val_sparse_categorical_accuracy: 0.5083 - lr: 5.0000e-04\n",
      "Epoch 44/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.6912 - sparse_categorical_accuracy: 0.5249 - val_loss: 0.6950 - val_sparse_categorical_accuracy: 0.5152 - lr: 5.0000e-04\n",
      "Epoch 45/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.6915 - sparse_categorical_accuracy: 0.5174 - val_loss: 0.6969 - val_sparse_categorical_accuracy: 0.4856 - lr: 5.0000e-04\n",
      "Epoch 46/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.6909 - sparse_categorical_accuracy: 0.5340 - val_loss: 0.6957 - val_sparse_categorical_accuracy: 0.5136 - lr: 2.5000e-04\n",
      "Epoch 47/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.6910 - sparse_categorical_accuracy: 0.5279 - val_loss: 0.6945 - val_sparse_categorical_accuracy: 0.4788 - lr: 2.5000e-04\n",
      "Epoch 48/500\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.6907 - sparse_categorical_accuracy: 0.5354 - val_loss: 0.6944 - val_sparse_categorical_accuracy: 0.5106 - lr: 2.5000e-04\n",
      "Epoch 49/500\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.6910 - sparse_categorical_accuracy: 0.5285 - val_loss: 0.6918 - val_sparse_categorical_accuracy: 0.4924 - lr: 2.5000e-04\n",
      "Epoch 50/500\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.6906 - sparse_categorical_accuracy: 0.5235 - val_loss: 0.6943 - val_sparse_categorical_accuracy: 0.4742 - lr: 2.5000e-04\n",
      "Epoch 51/500\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.6911 - sparse_categorical_accuracy: 0.5240 - val_loss: 0.6955 - val_sparse_categorical_accuracy: 0.4803 - lr: 2.5000e-04\n",
      "Epoch 52/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.6909 - sparse_categorical_accuracy: 0.5265 - val_loss: 0.6959 - val_sparse_categorical_accuracy: 0.5106 - lr: 2.5000e-04\n",
      "Epoch 53/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.6905 - sparse_categorical_accuracy: 0.5332 - val_loss: 0.6978 - val_sparse_categorical_accuracy: 0.4856 - lr: 2.5000e-04\n",
      "Epoch 54/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.6903 - sparse_categorical_accuracy: 0.5368 - val_loss: 0.6934 - val_sparse_categorical_accuracy: 0.4917 - lr: 2.5000e-04\n",
      "Epoch 55/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.6908 - sparse_categorical_accuracy: 0.5362 - val_loss: 0.6956 - val_sparse_categorical_accuracy: 0.4591 - lr: 2.5000e-04\n",
      "Epoch 56/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.6906 - sparse_categorical_accuracy: 0.5279 - val_loss: 0.6949 - val_sparse_categorical_accuracy: 0.5038 - lr: 2.5000e-04\n",
      "Epoch 57/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.6906 - sparse_categorical_accuracy: 0.5249 - val_loss: 0.6925 - val_sparse_categorical_accuracy: 0.5030 - lr: 2.5000e-04\n",
      "Epoch 58/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.6909 - sparse_categorical_accuracy: 0.5351 - val_loss: 0.6930 - val_sparse_categorical_accuracy: 0.4924 - lr: 2.5000e-04\n",
      "Epoch 59/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.6907 - sparse_categorical_accuracy: 0.5301 - val_loss: 0.6919 - val_sparse_categorical_accuracy: 0.5303 - lr: 2.5000e-04\n",
      "Epoch 60/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.6906 - sparse_categorical_accuracy: 0.5260 - val_loss: 0.6945 - val_sparse_categorical_accuracy: 0.4871 - lr: 2.5000e-04\n",
      "Epoch 61/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.6903 - sparse_categorical_accuracy: 0.5374 - val_loss: 0.6900 - val_sparse_categorical_accuracy: 0.5265 - lr: 2.5000e-04\n",
      "Epoch 62/500\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.6907 - sparse_categorical_accuracy: 0.5287 - val_loss: 0.6933 - val_sparse_categorical_accuracy: 0.4924 - lr: 2.5000e-04\n",
      "Epoch 63/500\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.6905 - sparse_categorical_accuracy: 0.5279 - val_loss: 0.6922 - val_sparse_categorical_accuracy: 0.5000 - lr: 2.5000e-04\n",
      "Epoch 64/500\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 0.6905 - sparse_categorical_accuracy: 0.5351 - val_loss: 0.6966 - val_sparse_categorical_accuracy: 0.5129 - lr: 2.5000e-04\n",
      "Epoch 65/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.6905 - sparse_categorical_accuracy: 0.5326 - val_loss: 0.6937 - val_sparse_categorical_accuracy: 0.5015 - lr: 2.5000e-04\n",
      "Epoch 66/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.6906 - sparse_categorical_accuracy: 0.5274 - val_loss: 0.7007 - val_sparse_categorical_accuracy: 0.4856 - lr: 2.5000e-04\n",
      "Epoch 67/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.6903 - sparse_categorical_accuracy: 0.5310 - val_loss: 0.6943 - val_sparse_categorical_accuracy: 0.4985 - lr: 2.5000e-04\n",
      "Epoch 68/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.6905 - sparse_categorical_accuracy: 0.5232 - val_loss: 0.6959 - val_sparse_categorical_accuracy: 0.4848 - lr: 2.5000e-04\n",
      "Epoch 69/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.6897 - sparse_categorical_accuracy: 0.5279 - val_loss: 0.6904 - val_sparse_categorical_accuracy: 0.4917 - lr: 2.5000e-04\n",
      "Epoch 70/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.6899 - sparse_categorical_accuracy: 0.5368 - val_loss: 0.6936 - val_sparse_categorical_accuracy: 0.5144 - lr: 2.5000e-04\n",
      "Epoch 71/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.6909 - sparse_categorical_accuracy: 0.5254 - val_loss: 0.6923 - val_sparse_categorical_accuracy: 0.5152 - lr: 2.5000e-04\n",
      "Epoch 72/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.6900 - sparse_categorical_accuracy: 0.5287 - val_loss: 0.6974 - val_sparse_categorical_accuracy: 0.4818 - lr: 2.5000e-04\n",
      "Epoch 73/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.6906 - sparse_categorical_accuracy: 0.5240 - val_loss: 0.6963 - val_sparse_categorical_accuracy: 0.4985 - lr: 2.5000e-04\n",
      "Epoch 74/500\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.6905 - sparse_categorical_accuracy: 0.5293 - val_loss: 0.6961 - val_sparse_categorical_accuracy: 0.4720 - lr: 2.5000e-04\n",
      "Epoch 75/500\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 0.6901 - sparse_categorical_accuracy: 0.5337 - val_loss: 0.6933 - val_sparse_categorical_accuracy: 0.4841 - lr: 2.5000e-04\n",
      "Epoch 76/500\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.6905 - sparse_categorical_accuracy: 0.5232 - val_loss: 0.6922 - val_sparse_categorical_accuracy: 0.5106 - lr: 2.5000e-04\n",
      "Epoch 77/500\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.6900 - sparse_categorical_accuracy: 0.5354 - val_loss: 0.6938 - val_sparse_categorical_accuracy: 0.5114 - lr: 2.5000e-04\n",
      "Epoch 78/500\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.6904 - sparse_categorical_accuracy: 0.5271 - val_loss: 0.6947 - val_sparse_categorical_accuracy: 0.4864 - lr: 2.5000e-04\n",
      "Epoch 79/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.6903 - sparse_categorical_accuracy: 0.5285 - val_loss: 0.6957 - val_sparse_categorical_accuracy: 0.4902 - lr: 2.5000e-04\n",
      "Epoch 80/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.6902 - sparse_categorical_accuracy: 0.5276 - val_loss: 0.6925 - val_sparse_categorical_accuracy: 0.5417 - lr: 2.5000e-04\n",
      "Epoch 81/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.6896 - sparse_categorical_accuracy: 0.5385 - val_loss: 0.6903 - val_sparse_categorical_accuracy: 0.5030 - lr: 2.5000e-04\n",
      "Epoch 82/500\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.6896 - sparse_categorical_accuracy: 0.5357 - val_loss: 0.6937 - val_sparse_categorical_accuracy: 0.5023 - lr: 1.2500e-04\n",
      "Epoch 83/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.6895 - sparse_categorical_accuracy: 0.5371 - val_loss: 0.6931 - val_sparse_categorical_accuracy: 0.5045 - lr: 1.2500e-04\n",
      "Epoch 84/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.6898 - sparse_categorical_accuracy: 0.5382 - val_loss: 0.6909 - val_sparse_categorical_accuracy: 0.5106 - lr: 1.2500e-04\n",
      "Epoch 85/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.6895 - sparse_categorical_accuracy: 0.5346 - val_loss: 0.6914 - val_sparse_categorical_accuracy: 0.4970 - lr: 1.2500e-04\n",
      "Epoch 86/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.6895 - sparse_categorical_accuracy: 0.5368 - val_loss: 0.6943 - val_sparse_categorical_accuracy: 0.5023 - lr: 1.2500e-04\n",
      "Epoch 87/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.6893 - sparse_categorical_accuracy: 0.5318 - val_loss: 0.6923 - val_sparse_categorical_accuracy: 0.5083 - lr: 1.2500e-04\n",
      "Epoch 88/500\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.6893 - sparse_categorical_accuracy: 0.5471 - val_loss: 0.6935 - val_sparse_categorical_accuracy: 0.5280 - lr: 1.2500e-04\n",
      "Epoch 89/500\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.6893 - sparse_categorical_accuracy: 0.5365 - val_loss: 0.6913 - val_sparse_categorical_accuracy: 0.5000 - lr: 1.2500e-04\n",
      "Epoch 90/500\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.6895 - sparse_categorical_accuracy: 0.5335 - val_loss: 0.6908 - val_sparse_categorical_accuracy: 0.5008 - lr: 1.2500e-04\n",
      "Epoch 91/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.6891 - sparse_categorical_accuracy: 0.5332 - val_loss: 0.6909 - val_sparse_categorical_accuracy: 0.5098 - lr: 1.2500e-04\n",
      "Epoch 92/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.6892 - sparse_categorical_accuracy: 0.5387 - val_loss: 0.6909 - val_sparse_categorical_accuracy: 0.5053 - lr: 1.2500e-04\n",
      "Epoch 93/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.6889 - sparse_categorical_accuracy: 0.5437 - val_loss: 0.6871 - val_sparse_categorical_accuracy: 0.5295 - lr: 1.2500e-04\n",
      "Epoch 94/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.6891 - sparse_categorical_accuracy: 0.5415 - val_loss: 0.6898 - val_sparse_categorical_accuracy: 0.5159 - lr: 1.2500e-04\n",
      "Epoch 95/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.6896 - sparse_categorical_accuracy: 0.5357 - val_loss: 0.6888 - val_sparse_categorical_accuracy: 0.5098 - lr: 1.2500e-04\n",
      "Epoch 96/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.6888 - sparse_categorical_accuracy: 0.5379 - val_loss: 0.6912 - val_sparse_categorical_accuracy: 0.4947 - lr: 1.2500e-04\n",
      "Epoch 97/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.6889 - sparse_categorical_accuracy: 0.5401 - val_loss: 0.6878 - val_sparse_categorical_accuracy: 0.5083 - lr: 1.2500e-04\n",
      "Epoch 98/500\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.6889 - sparse_categorical_accuracy: 0.5379 - val_loss: 0.6883 - val_sparse_categorical_accuracy: 0.5121 - lr: 1.2500e-04\n",
      "Epoch 99/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.6893 - sparse_categorical_accuracy: 0.5362 - val_loss: 0.6908 - val_sparse_categorical_accuracy: 0.5205 - lr: 1.2500e-04\n",
      "Epoch 100/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.6892 - sparse_categorical_accuracy: 0.5407 - val_loss: 0.6921 - val_sparse_categorical_accuracy: 0.5106 - lr: 1.2500e-04\n",
      "Epoch 101/500\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 0.6892 - sparse_categorical_accuracy: 0.5410 - val_loss: 0.6905 - val_sparse_categorical_accuracy: 0.5106 - lr: 1.2500e-04\n",
      "Epoch 102/500\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.6892 - sparse_categorical_accuracy: 0.5368 - val_loss: 0.6908 - val_sparse_categorical_accuracy: 0.5144 - lr: 1.2500e-04\n",
      "Epoch 103/500\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.6888 - sparse_categorical_accuracy: 0.5382 - val_loss: 0.6876 - val_sparse_categorical_accuracy: 0.5106 - lr: 1.2500e-04\n",
      "Epoch 104/500\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.6892 - sparse_categorical_accuracy: 0.5346 - val_loss: 0.6895 - val_sparse_categorical_accuracy: 0.5121 - lr: 1.2500e-04\n",
      "Epoch 105/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.6894 - sparse_categorical_accuracy: 0.5432 - val_loss: 0.6896 - val_sparse_categorical_accuracy: 0.5030 - lr: 1.2500e-04\n",
      "Epoch 106/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.6886 - sparse_categorical_accuracy: 0.5423 - val_loss: 0.6887 - val_sparse_categorical_accuracy: 0.5379 - lr: 1.2500e-04\n",
      "Epoch 107/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.6890 - sparse_categorical_accuracy: 0.5401 - val_loss: 0.6887 - val_sparse_categorical_accuracy: 0.5159 - lr: 1.2500e-04\n",
      "Epoch 108/500\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.6891 - sparse_categorical_accuracy: 0.5360 - val_loss: 0.6910 - val_sparse_categorical_accuracy: 0.5076 - lr: 1.2500e-04\n",
      "Epoch 109/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.6889 - sparse_categorical_accuracy: 0.5415 - val_loss: 0.6884 - val_sparse_categorical_accuracy: 0.5189 - lr: 1.2500e-04\n",
      "Epoch 110/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.6885 - sparse_categorical_accuracy: 0.5382 - val_loss: 0.6906 - val_sparse_categorical_accuracy: 0.5152 - lr: 1.2500e-04\n",
      "Epoch 111/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.6892 - sparse_categorical_accuracy: 0.5290 - val_loss: 0.6903 - val_sparse_categorical_accuracy: 0.5121 - lr: 1.2500e-04\n",
      "Epoch 112/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.6887 - sparse_categorical_accuracy: 0.5332 - val_loss: 0.6878 - val_sparse_categorical_accuracy: 0.5114 - lr: 1.2500e-04\n",
      "Epoch 113/500\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.6889 - sparse_categorical_accuracy: 0.5404 - val_loss: 0.6863 - val_sparse_categorical_accuracy: 0.5129 - lr: 1.2500e-04\n",
      "Epoch 114/500\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.6890 - sparse_categorical_accuracy: 0.5390 - val_loss: 0.6937 - val_sparse_categorical_accuracy: 0.5083 - lr: 1.2500e-04\n",
      "Epoch 115/500\n",
      "113/113 [==============================] - 1s 13ms/step - loss: 0.6889 - sparse_categorical_accuracy: 0.5354 - val_loss: 0.6898 - val_sparse_categorical_accuracy: 0.5492 - lr: 1.2500e-04\n",
      "Epoch 116/500\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.6891 - sparse_categorical_accuracy: 0.5310 - val_loss: 0.6887 - val_sparse_categorical_accuracy: 0.5258 - lr: 1.2500e-04\n",
      "Epoch 117/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.6888 - sparse_categorical_accuracy: 0.5396 - val_loss: 0.6867 - val_sparse_categorical_accuracy: 0.5258 - lr: 1.2500e-04\n",
      "Epoch 118/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.6883 - sparse_categorical_accuracy: 0.5340 - val_loss: 0.6894 - val_sparse_categorical_accuracy: 0.5152 - lr: 1.2500e-04\n",
      "Epoch 119/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.6888 - sparse_categorical_accuracy: 0.5412 - val_loss: 0.6899 - val_sparse_categorical_accuracy: 0.5576 - lr: 1.2500e-04\n",
      "Epoch 120/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.6885 - sparse_categorical_accuracy: 0.5382 - val_loss: 0.6883 - val_sparse_categorical_accuracy: 0.5121 - lr: 1.2500e-04\n",
      "Epoch 121/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.6885 - sparse_categorical_accuracy: 0.5376 - val_loss: 0.6881 - val_sparse_categorical_accuracy: 0.5288 - lr: 1.2500e-04\n",
      "Epoch 122/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.6884 - sparse_categorical_accuracy: 0.5415 - val_loss: 0.6879 - val_sparse_categorical_accuracy: 0.5197 - lr: 1.2500e-04\n",
      "Epoch 123/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.6886 - sparse_categorical_accuracy: 0.5401 - val_loss: 0.6891 - val_sparse_categorical_accuracy: 0.5227 - lr: 1.2500e-04\n",
      "Epoch 124/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.6885 - sparse_categorical_accuracy: 0.5423 - val_loss: 0.6857 - val_sparse_categorical_accuracy: 0.5182 - lr: 1.2500e-04\n",
      "Epoch 125/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.6885 - sparse_categorical_accuracy: 0.5404 - val_loss: 0.6902 - val_sparse_categorical_accuracy: 0.5106 - lr: 1.2500e-04\n",
      "Epoch 126/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.6888 - sparse_categorical_accuracy: 0.5407 - val_loss: 0.6871 - val_sparse_categorical_accuracy: 0.5159 - lr: 1.2500e-04\n",
      "Epoch 127/500\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.6882 - sparse_categorical_accuracy: 0.5446 - val_loss: 0.6846 - val_sparse_categorical_accuracy: 0.5379 - lr: 1.2500e-04\n",
      "Epoch 128/500\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.6880 - sparse_categorical_accuracy: 0.5446 - val_loss: 0.6866 - val_sparse_categorical_accuracy: 0.5341 - lr: 1.2500e-04\n",
      "Epoch 129/500\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.6885 - sparse_categorical_accuracy: 0.5401 - val_loss: 0.6840 - val_sparse_categorical_accuracy: 0.5273 - lr: 1.2500e-04\n",
      "Epoch 130/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.6883 - sparse_categorical_accuracy: 0.5368 - val_loss: 0.6849 - val_sparse_categorical_accuracy: 0.5636 - lr: 1.2500e-04\n",
      "Epoch 131/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.6881 - sparse_categorical_accuracy: 0.5404 - val_loss: 0.6866 - val_sparse_categorical_accuracy: 0.5242 - lr: 1.2500e-04\n",
      "Epoch 132/500\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.6884 - sparse_categorical_accuracy: 0.5462 - val_loss: 0.6868 - val_sparse_categorical_accuracy: 0.5114 - lr: 1.2500e-04\n",
      "Epoch 133/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.6885 - sparse_categorical_accuracy: 0.5460 - val_loss: 0.6892 - val_sparse_categorical_accuracy: 0.5144 - lr: 1.2500e-04\n",
      "Epoch 134/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.6885 - sparse_categorical_accuracy: 0.5357 - val_loss: 0.6891 - val_sparse_categorical_accuracy: 0.5227 - lr: 1.2500e-04\n",
      "Epoch 135/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.6882 - sparse_categorical_accuracy: 0.5385 - val_loss: 0.6862 - val_sparse_categorical_accuracy: 0.5144 - lr: 1.2500e-04\n",
      "Epoch 136/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.6880 - sparse_categorical_accuracy: 0.5440 - val_loss: 0.6863 - val_sparse_categorical_accuracy: 0.5205 - lr: 1.2500e-04\n",
      "Epoch 137/500\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.6884 - sparse_categorical_accuracy: 0.5415 - val_loss: 0.6877 - val_sparse_categorical_accuracy: 0.5318 - lr: 1.2500e-04\n",
      "Epoch 138/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.6881 - sparse_categorical_accuracy: 0.5421 - val_loss: 0.6937 - val_sparse_categorical_accuracy: 0.5068 - lr: 1.2500e-04\n",
      "Epoch 139/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.6877 - sparse_categorical_accuracy: 0.5457 - val_loss: 0.6901 - val_sparse_categorical_accuracy: 0.5136 - lr: 1.2500e-04\n",
      "Epoch 140/500\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.6884 - sparse_categorical_accuracy: 0.5362 - val_loss: 0.6856 - val_sparse_categorical_accuracy: 0.5212 - lr: 1.2500e-04\n",
      "Epoch 141/500\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.6884 - sparse_categorical_accuracy: 0.5387 - val_loss: 0.6907 - val_sparse_categorical_accuracy: 0.5136 - lr: 1.2500e-04\n",
      "Epoch 142/500\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.6884 - sparse_categorical_accuracy: 0.5412 - val_loss: 0.6905 - val_sparse_categorical_accuracy: 0.5174 - lr: 1.2500e-04\n",
      "Epoch 143/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.6878 - sparse_categorical_accuracy: 0.5401 - val_loss: 0.6860 - val_sparse_categorical_accuracy: 0.5129 - lr: 1.2500e-04\n",
      "Epoch 144/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.6885 - sparse_categorical_accuracy: 0.5432 - val_loss: 0.6888 - val_sparse_categorical_accuracy: 0.5258 - lr: 1.2500e-04\n",
      "Epoch 145/500\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.6881 - sparse_categorical_accuracy: 0.5396 - val_loss: 0.6885 - val_sparse_categorical_accuracy: 0.5227 - lr: 1.2500e-04\n",
      "Epoch 146/500\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.6882 - sparse_categorical_accuracy: 0.5404 - val_loss: 0.6866 - val_sparse_categorical_accuracy: 0.5114 - lr: 1.2500e-04\n",
      "Epoch 147/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.6878 - sparse_categorical_accuracy: 0.5412 - val_loss: 0.6897 - val_sparse_categorical_accuracy: 0.5129 - lr: 1.2500e-04\n",
      "Epoch 148/500\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.6879 - sparse_categorical_accuracy: 0.5432 - val_loss: 0.6893 - val_sparse_categorical_accuracy: 0.5182 - lr: 1.2500e-04\n",
      "Epoch 149/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.6885 - sparse_categorical_accuracy: 0.5404 - val_loss: 0.6893 - val_sparse_categorical_accuracy: 0.5583 - lr: 1.2500e-04\n",
      "Epoch 150/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.6876 - sparse_categorical_accuracy: 0.5490 - val_loss: 0.6913 - val_sparse_categorical_accuracy: 0.5121 - lr: 1.0000e-04\n",
      "Epoch 151/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.6875 - sparse_categorical_accuracy: 0.5404 - val_loss: 0.6882 - val_sparse_categorical_accuracy: 0.5280 - lr: 1.0000e-04\n",
      "Epoch 152/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.6872 - sparse_categorical_accuracy: 0.5443 - val_loss: 0.6892 - val_sparse_categorical_accuracy: 0.5068 - lr: 1.0000e-04\n",
      "Epoch 153/500\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.6877 - sparse_categorical_accuracy: 0.5404 - val_loss: 0.6875 - val_sparse_categorical_accuracy: 0.5106 - lr: 1.0000e-04\n",
      "Epoch 154/500\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.6876 - sparse_categorical_accuracy: 0.5490 - val_loss: 0.6898 - val_sparse_categorical_accuracy: 0.5227 - lr: 1.0000e-04\n",
      "Epoch 155/500\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.6876 - sparse_categorical_accuracy: 0.5435 - val_loss: 0.6878 - val_sparse_categorical_accuracy: 0.5114 - lr: 1.0000e-04\n",
      "Epoch 156/500\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.6877 - sparse_categorical_accuracy: 0.5418 - val_loss: 0.6875 - val_sparse_categorical_accuracy: 0.5250 - lr: 1.0000e-04\n",
      "Epoch 157/500\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.6873 - sparse_categorical_accuracy: 0.5426 - val_loss: 0.6860 - val_sparse_categorical_accuracy: 0.5235 - lr: 1.0000e-04\n",
      "Epoch 158/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.6873 - sparse_categorical_accuracy: 0.5440 - val_loss: 0.6849 - val_sparse_categorical_accuracy: 0.5432 - lr: 1.0000e-04\n",
      "Epoch 159/500\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.6873 - sparse_categorical_accuracy: 0.5443 - val_loss: 0.6877 - val_sparse_categorical_accuracy: 0.5250 - lr: 1.0000e-04\n",
      "Epoch 160/500\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.6875 - sparse_categorical_accuracy: 0.5446 - val_loss: 0.6873 - val_sparse_categorical_accuracy: 0.5235 - lr: 1.0000e-04\n",
      "Epoch 161/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.6875 - sparse_categorical_accuracy: 0.5407 - val_loss: 0.6850 - val_sparse_categorical_accuracy: 0.5311 - lr: 1.0000e-04\n",
      "Epoch 162/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.6878 - sparse_categorical_accuracy: 0.5382 - val_loss: 0.6851 - val_sparse_categorical_accuracy: 0.5227 - lr: 1.0000e-04\n",
      "Epoch 163/500\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.6873 - sparse_categorical_accuracy: 0.5421 - val_loss: 0.6960 - val_sparse_categorical_accuracy: 0.4992 - lr: 1.0000e-04\n",
      "Epoch 164/500\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.6876 - sparse_categorical_accuracy: 0.5454 - val_loss: 0.6923 - val_sparse_categorical_accuracy: 0.5326 - lr: 1.0000e-04\n",
      "Epoch 165/500\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.6874 - sparse_categorical_accuracy: 0.5493 - val_loss: 0.6873 - val_sparse_categorical_accuracy: 0.5106 - lr: 1.0000e-04\n",
      "Epoch 166/500\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.6873 - sparse_categorical_accuracy: 0.5468 - val_loss: 0.6879 - val_sparse_categorical_accuracy: 0.5114 - lr: 1.0000e-04\n",
      "Epoch 167/500\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.6874 - sparse_categorical_accuracy: 0.5371 - val_loss: 0.6858 - val_sparse_categorical_accuracy: 0.5182 - lr: 1.0000e-04\n",
      "Epoch 168/500\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.6877 - sparse_categorical_accuracy: 0.5407 - val_loss: 0.6854 - val_sparse_categorical_accuracy: 0.5152 - lr: 1.0000e-04\n",
      "Epoch 169/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.6876 - sparse_categorical_accuracy: 0.5437 - val_loss: 0.6885 - val_sparse_categorical_accuracy: 0.5076 - lr: 1.0000e-04\n",
      "Epoch 170/500\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.6871 - sparse_categorical_accuracy: 0.5437 - val_loss: 0.6878 - val_sparse_categorical_accuracy: 0.5235 - lr: 1.0000e-04\n",
      "Epoch 171/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.6868 - sparse_categorical_accuracy: 0.5498 - val_loss: 0.6860 - val_sparse_categorical_accuracy: 0.5553 - lr: 1.0000e-04\n",
      "Epoch 172/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.6876 - sparse_categorical_accuracy: 0.5446 - val_loss: 0.6848 - val_sparse_categorical_accuracy: 0.5182 - lr: 1.0000e-04\n",
      "Epoch 173/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.6876 - sparse_categorical_accuracy: 0.5471 - val_loss: 0.6854 - val_sparse_categorical_accuracy: 0.5212 - lr: 1.0000e-04\n",
      "Epoch 174/500\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.6875 - sparse_categorical_accuracy: 0.5365 - val_loss: 0.6913 - val_sparse_categorical_accuracy: 0.5174 - lr: 1.0000e-04\n",
      "Epoch 175/500\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.6871 - sparse_categorical_accuracy: 0.5371 - val_loss: 0.6895 - val_sparse_categorical_accuracy: 0.5144 - lr: 1.0000e-04\n",
      "Epoch 176/500\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.6875 - sparse_categorical_accuracy: 0.5390 - val_loss: 0.6885 - val_sparse_categorical_accuracy: 0.5189 - lr: 1.0000e-04\n",
      "Epoch 177/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.6871 - sparse_categorical_accuracy: 0.5454 - val_loss: 0.6931 - val_sparse_categorical_accuracy: 0.5136 - lr: 1.0000e-04\n",
      "Epoch 178/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.6874 - sparse_categorical_accuracy: 0.5432 - val_loss: 0.6852 - val_sparse_categorical_accuracy: 0.5227 - lr: 1.0000e-04\n",
      "Epoch 179/500\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.6877 - sparse_categorical_accuracy: 0.5423 - val_loss: 0.6837 - val_sparse_categorical_accuracy: 0.5614 - lr: 1.0000e-04\n",
      "Epoch 180/500\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.6867 - sparse_categorical_accuracy: 0.5423 - val_loss: 0.6857 - val_sparse_categorical_accuracy: 0.5174 - lr: 1.0000e-04\n",
      "Epoch 181/500\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.6870 - sparse_categorical_accuracy: 0.5485 - val_loss: 0.6861 - val_sparse_categorical_accuracy: 0.5318 - lr: 1.0000e-04\n",
      "Epoch 182/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.6872 - sparse_categorical_accuracy: 0.5421 - val_loss: 0.6868 - val_sparse_categorical_accuracy: 0.5492 - lr: 1.0000e-04\n",
      "Epoch 183/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.6869 - sparse_categorical_accuracy: 0.5560 - val_loss: 0.6861 - val_sparse_categorical_accuracy: 0.5227 - lr: 1.0000e-04\n",
      "Epoch 184/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.6870 - sparse_categorical_accuracy: 0.5501 - val_loss: 0.6869 - val_sparse_categorical_accuracy: 0.5341 - lr: 1.0000e-04\n",
      "Epoch 185/500\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.6873 - sparse_categorical_accuracy: 0.5462 - val_loss: 0.6839 - val_sparse_categorical_accuracy: 0.5591 - lr: 1.0000e-04\n",
      "Epoch 186/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.6871 - sparse_categorical_accuracy: 0.5479 - val_loss: 0.6914 - val_sparse_categorical_accuracy: 0.5144 - lr: 1.0000e-04\n",
      "Epoch 187/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.6870 - sparse_categorical_accuracy: 0.5496 - val_loss: 0.6876 - val_sparse_categorical_accuracy: 0.5250 - lr: 1.0000e-04\n",
      "Epoch 188/500\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.6865 - sparse_categorical_accuracy: 0.5471 - val_loss: 0.6876 - val_sparse_categorical_accuracy: 0.5258 - lr: 1.0000e-04\n",
      "Epoch 189/500\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.6865 - sparse_categorical_accuracy: 0.5487 - val_loss: 0.6870 - val_sparse_categorical_accuracy: 0.5250 - lr: 1.0000e-04\n",
      "Epoch 190/500\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.6862 - sparse_categorical_accuracy: 0.5529 - val_loss: 0.6875 - val_sparse_categorical_accuracy: 0.5197 - lr: 1.0000e-04\n",
      "Epoch 191/500\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.6861 - sparse_categorical_accuracy: 0.5482 - val_loss: 0.6849 - val_sparse_categorical_accuracy: 0.5333 - lr: 1.0000e-04\n",
      "Epoch 192/500\n",
      "113/113 [==============================] - 1s 13ms/step - loss: 0.6874 - sparse_categorical_accuracy: 0.5490 - val_loss: 0.6839 - val_sparse_categorical_accuracy: 0.5288 - lr: 1.0000e-04\n",
      "Epoch 193/500\n",
      "113/113 [==============================] - 1s 13ms/step - loss: 0.6866 - sparse_categorical_accuracy: 0.5421 - val_loss: 0.6905 - val_sparse_categorical_accuracy: 0.5159 - lr: 1.0000e-04\n",
      "Epoch 194/500\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 0.6874 - sparse_categorical_accuracy: 0.5376 - val_loss: 0.6865 - val_sparse_categorical_accuracy: 0.5439 - lr: 1.0000e-04\n",
      "Epoch 195/500\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.6869 - sparse_categorical_accuracy: 0.5454 - val_loss: 0.6873 - val_sparse_categorical_accuracy: 0.5242 - lr: 1.0000e-04\n",
      "Epoch 196/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.6869 - sparse_categorical_accuracy: 0.5512 - val_loss: 0.6884 - val_sparse_categorical_accuracy: 0.5205 - lr: 1.0000e-04\n",
      "Epoch 197/500\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.6874 - sparse_categorical_accuracy: 0.5423 - val_loss: 0.6867 - val_sparse_categorical_accuracy: 0.5250 - lr: 1.0000e-04\n",
      "Epoch 198/500\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.6864 - sparse_categorical_accuracy: 0.5518 - val_loss: 0.6927 - val_sparse_categorical_accuracy: 0.5371 - lr: 1.0000e-04\n",
      "Epoch 199/500\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.6865 - sparse_categorical_accuracy: 0.5501 - val_loss: 0.6892 - val_sparse_categorical_accuracy: 0.5159 - lr: 1.0000e-04\n",
      "Epoch 200/500\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.6866 - sparse_categorical_accuracy: 0.5490 - val_loss: 0.6886 - val_sparse_categorical_accuracy: 0.5409 - lr: 1.0000e-04\n",
      "Epoch 201/500\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.6861 - sparse_categorical_accuracy: 0.5471 - val_loss: 0.6848 - val_sparse_categorical_accuracy: 0.5303 - lr: 1.0000e-04\n",
      "Epoch 202/500\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.6867 - sparse_categorical_accuracy: 0.5501 - val_loss: 0.6853 - val_sparse_categorical_accuracy: 0.5258 - lr: 1.0000e-04\n",
      "Epoch 203/500\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.6868 - sparse_categorical_accuracy: 0.5479 - val_loss: 0.6840 - val_sparse_categorical_accuracy: 0.5205 - lr: 1.0000e-04\n",
      "Epoch 204/500\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.6868 - sparse_categorical_accuracy: 0.5451 - val_loss: 0.6871 - val_sparse_categorical_accuracy: 0.5705 - lr: 1.0000e-04\n",
      "Epoch 205/500\n",
      "113/113 [==============================] - 1s 13ms/step - loss: 0.6866 - sparse_categorical_accuracy: 0.5462 - val_loss: 0.6799 - val_sparse_categorical_accuracy: 0.5303 - lr: 1.0000e-04\n",
      "Epoch 206/500\n",
      "113/113 [==============================] - 1s 13ms/step - loss: 0.6865 - sparse_categorical_accuracy: 0.5515 - val_loss: 0.6945 - val_sparse_categorical_accuracy: 0.5076 - lr: 1.0000e-04\n",
      "Epoch 207/500\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.6866 - sparse_categorical_accuracy: 0.5551 - val_loss: 0.6943 - val_sparse_categorical_accuracy: 0.5129 - lr: 1.0000e-04\n",
      "Epoch 208/500\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.6870 - sparse_categorical_accuracy: 0.5451 - val_loss: 0.6920 - val_sparse_categorical_accuracy: 0.5083 - lr: 1.0000e-04\n",
      "Epoch 209/500\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.6866 - sparse_categorical_accuracy: 0.5518 - val_loss: 0.6851 - val_sparse_categorical_accuracy: 0.5258 - lr: 1.0000e-04\n",
      "Epoch 210/500\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.6864 - sparse_categorical_accuracy: 0.5487 - val_loss: 0.6876 - val_sparse_categorical_accuracy: 0.5205 - lr: 1.0000e-04\n",
      "Epoch 211/500\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.6865 - sparse_categorical_accuracy: 0.5451 - val_loss: 0.6925 - val_sparse_categorical_accuracy: 0.5121 - lr: 1.0000e-04\n",
      "Epoch 212/500\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.6865 - sparse_categorical_accuracy: 0.5443 - val_loss: 0.6861 - val_sparse_categorical_accuracy: 0.5205 - lr: 1.0000e-04\n",
      "Epoch 213/500\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.6861 - sparse_categorical_accuracy: 0.5554 - val_loss: 0.6880 - val_sparse_categorical_accuracy: 0.5417 - lr: 1.0000e-04\n",
      "Epoch 214/500\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.6866 - sparse_categorical_accuracy: 0.5440 - val_loss: 0.6834 - val_sparse_categorical_accuracy: 0.5523 - lr: 1.0000e-04\n",
      "Epoch 215/500\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.6862 - sparse_categorical_accuracy: 0.5493 - val_loss: 0.6877 - val_sparse_categorical_accuracy: 0.5212 - lr: 1.0000e-04\n",
      "Epoch 216/500\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 0.6862 - sparse_categorical_accuracy: 0.5518 - val_loss: 0.6888 - val_sparse_categorical_accuracy: 0.5242 - lr: 1.0000e-04\n",
      "Epoch 217/500\n",
      "113/113 [==============================] - 1s 13ms/step - loss: 0.6861 - sparse_categorical_accuracy: 0.5482 - val_loss: 0.6876 - val_sparse_categorical_accuracy: 0.5136 - lr: 1.0000e-04\n",
      "Epoch 218/500\n",
      "113/113 [==============================] - 1s 13ms/step - loss: 0.6865 - sparse_categorical_accuracy: 0.5479 - val_loss: 0.6855 - val_sparse_categorical_accuracy: 0.5333 - lr: 1.0000e-04\n",
      "Epoch 219/500\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 0.6863 - sparse_categorical_accuracy: 0.5535 - val_loss: 0.6911 - val_sparse_categorical_accuracy: 0.5121 - lr: 1.0000e-04\n",
      "Epoch 220/500\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.6867 - sparse_categorical_accuracy: 0.5457 - val_loss: 0.6989 - val_sparse_categorical_accuracy: 0.5091 - lr: 1.0000e-04\n",
      "Epoch 221/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.6858 - sparse_categorical_accuracy: 0.5560 - val_loss: 0.6831 - val_sparse_categorical_accuracy: 0.5220 - lr: 1.0000e-04\n",
      "Epoch 222/500\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.6858 - sparse_categorical_accuracy: 0.5523 - val_loss: 0.6812 - val_sparse_categorical_accuracy: 0.5242 - lr: 1.0000e-04\n",
      "Epoch 223/500\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.6863 - sparse_categorical_accuracy: 0.5429 - val_loss: 0.6897 - val_sparse_categorical_accuracy: 0.5174 - lr: 1.0000e-04\n",
      "Epoch 224/500\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.6859 - sparse_categorical_accuracy: 0.5498 - val_loss: 0.6885 - val_sparse_categorical_accuracy: 0.5409 - lr: 1.0000e-04\n",
      "Epoch 225/500\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.6863 - sparse_categorical_accuracy: 0.5535 - val_loss: 0.6844 - val_sparse_categorical_accuracy: 0.5273 - lr: 1.0000e-04\n",
      "Epoch 226/500\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.6861 - sparse_categorical_accuracy: 0.5426 - val_loss: 0.6873 - val_sparse_categorical_accuracy: 0.5348 - lr: 1.0000e-04\n",
      "Epoch 227/500\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.6857 - sparse_categorical_accuracy: 0.5487 - val_loss: 0.6842 - val_sparse_categorical_accuracy: 0.5326 - lr: 1.0000e-04\n",
      "Epoch 228/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.6858 - sparse_categorical_accuracy: 0.5432 - val_loss: 0.6831 - val_sparse_categorical_accuracy: 0.5356 - lr: 1.0000e-04\n",
      "Epoch 229/500\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.6857 - sparse_categorical_accuracy: 0.5565 - val_loss: 0.6901 - val_sparse_categorical_accuracy: 0.5144 - lr: 1.0000e-04\n",
      "Epoch 230/500\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.6857 - sparse_categorical_accuracy: 0.5493 - val_loss: 0.6886 - val_sparse_categorical_accuracy: 0.5379 - lr: 1.0000e-04\n",
      "Epoch 231/500\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.6855 - sparse_categorical_accuracy: 0.5515 - val_loss: 0.6926 - val_sparse_categorical_accuracy: 0.5114 - lr: 1.0000e-04\n",
      "Epoch 232/500\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.6857 - sparse_categorical_accuracy: 0.5565 - val_loss: 0.6862 - val_sparse_categorical_accuracy: 0.5227 - lr: 1.0000e-04\n",
      "Epoch 233/500\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.6865 - sparse_categorical_accuracy: 0.5521 - val_loss: 0.6862 - val_sparse_categorical_accuracy: 0.5295 - lr: 1.0000e-04\n",
      "Epoch 234/500\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.6855 - sparse_categorical_accuracy: 0.5587 - val_loss: 0.6860 - val_sparse_categorical_accuracy: 0.5439 - lr: 1.0000e-04\n",
      "Epoch 235/500\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.6848 - sparse_categorical_accuracy: 0.5604 - val_loss: 0.6902 - val_sparse_categorical_accuracy: 0.5121 - lr: 1.0000e-04\n",
      "Epoch 236/500\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.6855 - sparse_categorical_accuracy: 0.5504 - val_loss: 0.6852 - val_sparse_categorical_accuracy: 0.5295 - lr: 1.0000e-04\n",
      "Epoch 237/500\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.6851 - sparse_categorical_accuracy: 0.5512 - val_loss: 0.6808 - val_sparse_categorical_accuracy: 0.5295 - lr: 1.0000e-04\n",
      "Epoch 238/500\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.6859 - sparse_categorical_accuracy: 0.5568 - val_loss: 0.6862 - val_sparse_categorical_accuracy: 0.5250 - lr: 1.0000e-04\n",
      "Epoch 239/500\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.6857 - sparse_categorical_accuracy: 0.5490 - val_loss: 0.6911 - val_sparse_categorical_accuracy: 0.5159 - lr: 1.0000e-04\n",
      "Epoch 240/500\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.6856 - sparse_categorical_accuracy: 0.5512 - val_loss: 0.6906 - val_sparse_categorical_accuracy: 0.5485 - lr: 1.0000e-04\n",
      "Epoch 241/500\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.6858 - sparse_categorical_accuracy: 0.5521 - val_loss: 0.6873 - val_sparse_categorical_accuracy: 0.5235 - lr: 1.0000e-04\n",
      "Epoch 242/500\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.6858 - sparse_categorical_accuracy: 0.5457 - val_loss: 0.6858 - val_sparse_categorical_accuracy: 0.5727 - lr: 1.0000e-04\n",
      "Epoch 243/500\n",
      "113/113 [==============================] - 1s 13ms/step - loss: 0.6854 - sparse_categorical_accuracy: 0.5476 - val_loss: 0.6914 - val_sparse_categorical_accuracy: 0.5167 - lr: 1.0000e-04\n",
      "Epoch 244/500\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.6858 - sparse_categorical_accuracy: 0.5496 - val_loss: 0.6890 - val_sparse_categorical_accuracy: 0.5189 - lr: 1.0000e-04\n",
      "Epoch 245/500\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.6858 - sparse_categorical_accuracy: 0.5526 - val_loss: 0.6897 - val_sparse_categorical_accuracy: 0.5174 - lr: 1.0000e-04\n",
      "Epoch 246/500\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.6852 - sparse_categorical_accuracy: 0.5529 - val_loss: 0.6844 - val_sparse_categorical_accuracy: 0.5303 - lr: 1.0000e-04\n",
      "Epoch 247/500\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.6861 - sparse_categorical_accuracy: 0.5493 - val_loss: 0.6887 - val_sparse_categorical_accuracy: 0.5348 - lr: 1.0000e-04\n",
      "Epoch 248/500\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.6856 - sparse_categorical_accuracy: 0.5532 - val_loss: 0.6875 - val_sparse_categorical_accuracy: 0.5167 - lr: 1.0000e-04\n",
      "Epoch 249/500\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.6858 - sparse_categorical_accuracy: 0.5468 - val_loss: 0.6852 - val_sparse_categorical_accuracy: 0.5235 - lr: 1.0000e-04\n",
      "Epoch 250/500\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.6854 - sparse_categorical_accuracy: 0.5535 - val_loss: 0.6842 - val_sparse_categorical_accuracy: 0.5250 - lr: 1.0000e-04\n",
      "Epoch 251/500\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.6851 - sparse_categorical_accuracy: 0.5537 - val_loss: 0.6899 - val_sparse_categorical_accuracy: 0.5129 - lr: 1.0000e-04\n",
      "Epoch 252/500\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.6856 - sparse_categorical_accuracy: 0.5496 - val_loss: 0.6872 - val_sparse_categorical_accuracy: 0.5265 - lr: 1.0000e-04\n",
      "Epoch 253/500\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.6854 - sparse_categorical_accuracy: 0.5554 - val_loss: 0.6934 - val_sparse_categorical_accuracy: 0.5053 - lr: 1.0000e-04\n",
      "Epoch 254/500\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.6851 - sparse_categorical_accuracy: 0.5476 - val_loss: 0.6906 - val_sparse_categorical_accuracy: 0.5220 - lr: 1.0000e-04\n",
      "Epoch 255/500\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.6857 - sparse_categorical_accuracy: 0.5557 - val_loss: 0.6895 - val_sparse_categorical_accuracy: 0.5523 - lr: 1.0000e-04\n",
      "Epoch 256/500\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.6849 - sparse_categorical_accuracy: 0.5598 - val_loss: 0.6877 - val_sparse_categorical_accuracy: 0.5205 - lr: 1.0000e-04\n",
      "Epoch 257/500\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 0.6851 - sparse_categorical_accuracy: 0.5515 - val_loss: 0.6834 - val_sparse_categorical_accuracy: 0.5811 - lr: 1.0000e-04\n",
      "Epoch 258/500\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.6852 - sparse_categorical_accuracy: 0.5568 - val_loss: 0.6891 - val_sparse_categorical_accuracy: 0.5545 - lr: 1.0000e-04\n",
      "Epoch 259/500\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.6850 - sparse_categorical_accuracy: 0.5562 - val_loss: 0.6837 - val_sparse_categorical_accuracy: 0.5280 - lr: 1.0000e-04\n",
      "Epoch 260/500\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.6853 - sparse_categorical_accuracy: 0.5496 - val_loss: 0.6907 - val_sparse_categorical_accuracy: 0.5114 - lr: 1.0000e-04\n",
      "Epoch 261/500\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.6852 - sparse_categorical_accuracy: 0.5543 - val_loss: 0.6909 - val_sparse_categorical_accuracy: 0.5356 - lr: 1.0000e-04\n",
      "Epoch 262/500\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.6848 - sparse_categorical_accuracy: 0.5637 - val_loss: 0.6954 - val_sparse_categorical_accuracy: 0.5091 - lr: 1.0000e-04\n",
      "Epoch 263/500\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.6855 - sparse_categorical_accuracy: 0.5510 - val_loss: 0.6908 - val_sparse_categorical_accuracy: 0.5159 - lr: 1.0000e-04\n",
      "Epoch 264/500\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.6852 - sparse_categorical_accuracy: 0.5504 - val_loss: 0.6896 - val_sparse_categorical_accuracy: 0.5470 - lr: 1.0000e-04\n",
      "Epoch 265/500\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.6850 - sparse_categorical_accuracy: 0.5582 - val_loss: 0.6970 - val_sparse_categorical_accuracy: 0.4962 - lr: 1.0000e-04\n",
      "Epoch 266/500\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.6850 - sparse_categorical_accuracy: 0.5498 - val_loss: 0.6983 - val_sparse_categorical_accuracy: 0.4886 - lr: 1.0000e-04\n",
      "Epoch 267/500\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.6850 - sparse_categorical_accuracy: 0.5496 - val_loss: 0.6849 - val_sparse_categorical_accuracy: 0.5205 - lr: 1.0000e-04\n",
      "Epoch 268/500\n",
      "113/113 [==============================] - 2s 13ms/step - loss: 0.6856 - sparse_categorical_accuracy: 0.5518 - val_loss: 0.6949 - val_sparse_categorical_accuracy: 0.5023 - lr: 1.0000e-04\n",
      "Epoch 269/500\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 0.6850 - sparse_categorical_accuracy: 0.5529 - val_loss: 0.6954 - val_sparse_categorical_accuracy: 0.5129 - lr: 1.0000e-04\n",
      "Epoch 270/500\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.6846 - sparse_categorical_accuracy: 0.5612 - val_loss: 0.6862 - val_sparse_categorical_accuracy: 0.5318 - lr: 1.0000e-04\n",
      "Epoch 271/500\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.6857 - sparse_categorical_accuracy: 0.5521 - val_loss: 0.6966 - val_sparse_categorical_accuracy: 0.5386 - lr: 1.0000e-04\n",
      "Epoch 272/500\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.6854 - sparse_categorical_accuracy: 0.5576 - val_loss: 0.6854 - val_sparse_categorical_accuracy: 0.5235 - lr: 1.0000e-04\n",
      "Epoch 273/500\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.6847 - sparse_categorical_accuracy: 0.5593 - val_loss: 0.6846 - val_sparse_categorical_accuracy: 0.5242 - lr: 1.0000e-04\n",
      "Epoch 274/500\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.6856 - sparse_categorical_accuracy: 0.5521 - val_loss: 0.6896 - val_sparse_categorical_accuracy: 0.5152 - lr: 1.0000e-04\n",
      "Epoch 275/500\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.6846 - sparse_categorical_accuracy: 0.5557 - val_loss: 0.6870 - val_sparse_categorical_accuracy: 0.5318 - lr: 1.0000e-04\n",
      "Epoch 276/500\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.6850 - sparse_categorical_accuracy: 0.5576 - val_loss: 0.6913 - val_sparse_categorical_accuracy: 0.5106 - lr: 1.0000e-04\n",
      "Epoch 277/500\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.6850 - sparse_categorical_accuracy: 0.5532 - val_loss: 0.6933 - val_sparse_categorical_accuracy: 0.5061 - lr: 1.0000e-04\n",
      "Epoch 278/500\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.6852 - sparse_categorical_accuracy: 0.5560 - val_loss: 0.6882 - val_sparse_categorical_accuracy: 0.5432 - lr: 1.0000e-04\n",
      "Epoch 279/500\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 0.6846 - sparse_categorical_accuracy: 0.5562 - val_loss: 0.6885 - val_sparse_categorical_accuracy: 0.5136 - lr: 1.0000e-04\n",
      "Epoch 280/500\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.6846 - sparse_categorical_accuracy: 0.5610 - val_loss: 0.6865 - val_sparse_categorical_accuracy: 0.5682 - lr: 1.0000e-04\n",
      "Epoch 281/500\n",
      " 67/113 [================>.............] - ETA: 0s - loss: 0.6844 - sparse_categorical_accuracy: 0.5504"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-81-dca417d1f361>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"sparse_categorical_accuracy\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m )\n\u001b[0;32m---> 12\u001b[0;31m history = model_c.fit(\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mx_train_fill\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1648\u001b[0m                         ):\n\u001b[1;32m   1649\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1650\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1651\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1652\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    888\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    889\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mwithout_tracing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 890\u001b[0;31m         _frequent_tracing_detector_manager.called_without_tracing(\n\u001b[0m\u001b[1;32m    891\u001b[0m             self._key_for_call_stats)\n\u001b[1;32m    892\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36mcalled_without_tracing\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    191\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcalled_without_tracing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m       \u001b[0mdetector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_detector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m       \u001b[0mdetector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_get_detector\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_detectors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_detectors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_FrequentTracingDetector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_detectors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcalled_without_tracing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.9/weakref.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    414\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 500\n",
    "batch_size = 32\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=20, min_lr=0.0001),\n",
    "]\n",
    "model_c.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"sparse_categorical_accuracy\"],\n",
    ")\n",
    "history = model_c.fit(\n",
    "    x_train_fill, y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    callbacks=callbacks,\n",
    "    validation_data=(x_test_fill, y_test),\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7n6VaPAoiT76"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p-8VEGj2iT-I"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0cg8iNmKiUAc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KDrMvmo-iUC2"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
