{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "N3KVvRYZDED5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9ff5e94-dba2-4cb8-a1f0-8be5b6bc8b07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jr-T9XJ-BWdm"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AAqN4QaTsHdT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train_nan = pd.read_csv('/content/drive/MyDrive/train_nan.csv', header=None)\n",
        "df_train_nan.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "YCoj9TuusHfv",
        "outputId": "ab648287-f7d9-4e94-99ec-54d3bed22582"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   0         1         2         3         4         5         6         7    \\\n",
              "0 -1.0 -0.797172 -0.664392 -0.373015  0.040815  0.526936  0.984288  1.353120   \n",
              "1  1.0  0.804855       NaN  0.373474  0.038343       NaN -0.740860       NaN   \n",
              "2 -1.0  0.727985       NaN -0.499124 -1.068629 -1.578351 -1.990534       NaN   \n",
              "3 -1.0 -0.234439 -0.502157 -0.732488 -0.946128 -1.139739 -1.323336 -1.490243   \n",
              "4 -1.0       NaN -0.062285  0.235829  0.710396  1.239969  1.649823  1.876321   \n",
              "\n",
              "        8         9    ...       491       492       493       494       495  \\\n",
              "0  1.578108  1.659251  ...       NaN       NaN  0.362068  0.092083 -0.081268   \n",
              "1 -1.395357 -1.570192  ...  0.386403  0.049213 -0.258138       NaN -0.683647   \n",
              "2 -2.503403 -2.585211  ...  0.394463  0.463685       NaN  0.517174       NaN   \n",
              "3 -1.607077 -1.620430  ... -0.952804 -0.929437 -0.922761 -0.929437 -0.909409   \n",
              "4  1.865535       NaN  ...  0.776188  0.725496       NaN  0.731967  0.808545   \n",
              "\n",
              "        496       497       498       499       500  \n",
              "0 -0.212573       NaN -0.664392 -1.073796 -1.564343  \n",
              "1 -0.773817 -0.785255 -0.714885 -0.560443 -0.319086  \n",
              "2  0.476270  0.438513  0.394463       NaN  0.255391  \n",
              "3 -0.835970 -0.695768 -0.478790 -0.188707  0.119736  \n",
              "4  0.839823       NaN  0.437520       NaN -0.602213  \n",
              "\n",
              "[5 rows x 501 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5cae13c7-d9a3-4143-8c28-668cd7d83189\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>491</th>\n",
              "      <th>492</th>\n",
              "      <th>493</th>\n",
              "      <th>494</th>\n",
              "      <th>495</th>\n",
              "      <th>496</th>\n",
              "      <th>497</th>\n",
              "      <th>498</th>\n",
              "      <th>499</th>\n",
              "      <th>500</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.797172</td>\n",
              "      <td>-0.664392</td>\n",
              "      <td>-0.373015</td>\n",
              "      <td>0.040815</td>\n",
              "      <td>0.526936</td>\n",
              "      <td>0.984288</td>\n",
              "      <td>1.353120</td>\n",
              "      <td>1.578108</td>\n",
              "      <td>1.659251</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.362068</td>\n",
              "      <td>0.092083</td>\n",
              "      <td>-0.081268</td>\n",
              "      <td>-0.212573</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.664392</td>\n",
              "      <td>-1.073796</td>\n",
              "      <td>-1.564343</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.804855</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.373474</td>\n",
              "      <td>0.038343</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.740860</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-1.395357</td>\n",
              "      <td>-1.570192</td>\n",
              "      <td>...</td>\n",
              "      <td>0.386403</td>\n",
              "      <td>0.049213</td>\n",
              "      <td>-0.258138</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.683647</td>\n",
              "      <td>-0.773817</td>\n",
              "      <td>-0.785255</td>\n",
              "      <td>-0.714885</td>\n",
              "      <td>-0.560443</td>\n",
              "      <td>-0.319086</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.727985</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.499124</td>\n",
              "      <td>-1.068629</td>\n",
              "      <td>-1.578351</td>\n",
              "      <td>-1.990534</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-2.503403</td>\n",
              "      <td>-2.585211</td>\n",
              "      <td>...</td>\n",
              "      <td>0.394463</td>\n",
              "      <td>0.463685</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.517174</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.476270</td>\n",
              "      <td>0.438513</td>\n",
              "      <td>0.394463</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.255391</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.234439</td>\n",
              "      <td>-0.502157</td>\n",
              "      <td>-0.732488</td>\n",
              "      <td>-0.946128</td>\n",
              "      <td>-1.139739</td>\n",
              "      <td>-1.323336</td>\n",
              "      <td>-1.490243</td>\n",
              "      <td>-1.607077</td>\n",
              "      <td>-1.620430</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.952804</td>\n",
              "      <td>-0.929437</td>\n",
              "      <td>-0.922761</td>\n",
              "      <td>-0.929437</td>\n",
              "      <td>-0.909409</td>\n",
              "      <td>-0.835970</td>\n",
              "      <td>-0.695768</td>\n",
              "      <td>-0.478790</td>\n",
              "      <td>-0.188707</td>\n",
              "      <td>0.119736</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.062285</td>\n",
              "      <td>0.235829</td>\n",
              "      <td>0.710396</td>\n",
              "      <td>1.239969</td>\n",
              "      <td>1.649823</td>\n",
              "      <td>1.876321</td>\n",
              "      <td>1.865535</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0.776188</td>\n",
              "      <td>0.725496</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.731967</td>\n",
              "      <td>0.808545</td>\n",
              "      <td>0.839823</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.437520</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.602213</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 501 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5cae13c7-d9a3-4143-8c28-668cd7d83189')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5cae13c7-d9a3-4143-8c28-668cd7d83189 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5cae13c7-d9a3-4143-8c28-668cd7d83189');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train_nan_mask = df_train_nan.isna()\n",
        "df_train_nan_mask.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "id": "VVUQzglL1S74",
        "outputId": "dd76afe3-f809-4496-f774-4499e85437b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     0      1      2      3      4      5      6      7      8      9    ...  \\\n",
              "0  False  False  False  False  False  False  False  False  False  False  ...   \n",
              "1  False  False   True  False  False   True  False   True  False  False  ...   \n",
              "2  False  False   True  False  False  False  False   True  False  False  ...   \n",
              "3  False  False  False  False  False  False  False  False  False  False  ...   \n",
              "4  False   True  False  False  False  False  False  False  False   True  ...   \n",
              "\n",
              "     491    492    493    494    495    496    497    498    499    500  \n",
              "0   True   True  False  False  False  False   True  False  False  False  \n",
              "1  False  False  False   True  False  False  False  False  False  False  \n",
              "2  False  False   True  False   True  False  False  False   True  False  \n",
              "3  False  False  False  False  False  False  False  False  False  False  \n",
              "4  False  False   True  False  False  False   True  False   True  False  \n",
              "\n",
              "[5 rows x 501 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-beab62ae-c9e4-49d8-8af7-a85da9573468\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>491</th>\n",
              "      <th>492</th>\n",
              "      <th>493</th>\n",
              "      <th>494</th>\n",
              "      <th>495</th>\n",
              "      <th>496</th>\n",
              "      <th>497</th>\n",
              "      <th>498</th>\n",
              "      <th>499</th>\n",
              "      <th>500</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 501 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-beab62ae-c9e4-49d8-8af7-a85da9573468')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-beab62ae-c9e4-49d8-8af7-a85da9573468 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-beab62ae-c9e4-49d8-8af7-a85da9573468');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train_nan_mask = df_train_nan_mask.to_numpy()\n",
        "print(df_train_nan_mask[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QHIzv5DV1S-m",
        "outputId": "c2f1223a-1f9e-45e3-fcd5-b78465518c89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[False False False False False False False False False False False False\n",
            " False False False  True  True False False  True False False False  True\n",
            " False False False  True False False False False False False False False\n",
            "  True False  True False False False False False False False False False\n",
            " False False False False False False False False  True False False False\n",
            "  True False False  True False  True  True False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False  True False False False False False False False\n",
            " False False False False False False False  True False False  True False\n",
            "  True False False False False False False False False False False  True\n",
            " False False False False  True False False False False False False False\n",
            " False  True False False False False False False False False False False\n",
            " False False False False False False False False  True False  True False\n",
            " False False False False False  True False False False  True False False\n",
            " False False False False False False False False False False False  True\n",
            " False False False False False False False False False False False False\n",
            " False False False False False  True False False False  True False False\n",
            "  True  True False False False False False False False  True False  True\n",
            " False False False  True False False False False False False False False\n",
            " False False False  True False  True False False False  True False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False  True False\n",
            " False False False False  True False False  True False False False False\n",
            " False False False False False  True False False False  True False False\n",
            " False  True False False False False  True  True False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False  True False False\n",
            " False False False  True False  True  True False  True False False False\n",
            " False False False False False False False False False False False False\n",
            " False False  True False False False False False  True False  True False\n",
            " False False False False False False False  True False False False  True\n",
            " False False False False False False False False False False False  True\n",
            " False False False False  True False False False  True  True False False\n",
            " False False False False False False False False  True False False False\n",
            " False False False False False False  True False False False False False\n",
            "  True False False  True False  True  True False False False  True False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False  True False False False False False False  True False  True\n",
            "  True False False False False  True False False False]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train_nan_mask = df_train_nan_mask*1.0\n",
        "print(df_train_nan_mask[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EB2YuRhr153u",
        "outputId": "77cd6ff7-a426-4995-92e7-d04ca29a1b99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 1.\n",
            " 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
            " 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1.\n",
            " 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 1. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
            " 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 1. 0. 0. 0. 1. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train_nan_mask = df_train_nan_mask[:, 1:]\n",
        "print(df_train_nan_mask.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hflz4LBf2JO5",
        "outputId": "7d440ef6-6c2f-4d3f-9eec-75670245b5d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3601, 500)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rqanNmjt2JRI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train_nan = df_train_nan.fillna(1000)\n",
        "df_train_nan.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "UJbvTPP-aFz4",
        "outputId": "6f3f1056-a2af-4945-ec29-8e6884c4e487"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   0            1            2         3         4            5         6    \\\n",
              "0 -1.0    -0.797172    -0.664392 -0.373015  0.040815     0.526936  0.984288   \n",
              "1  1.0     0.804855  1000.000000  0.373474  0.038343  1000.000000 -0.740860   \n",
              "2 -1.0     0.727985  1000.000000 -0.499124 -1.068629    -1.578351 -1.990534   \n",
              "3 -1.0    -0.234439    -0.502157 -0.732488 -0.946128    -1.139739 -1.323336   \n",
              "4 -1.0  1000.000000    -0.062285  0.235829  0.710396     1.239969  1.649823   \n",
              "\n",
              "           7         8            9    ...          491          492  \\\n",
              "0     1.353120  1.578108     1.659251  ...  1000.000000  1000.000000   \n",
              "1  1000.000000 -1.395357    -1.570192  ...     0.386403     0.049213   \n",
              "2  1000.000000 -2.503403    -2.585211  ...     0.394463     0.463685   \n",
              "3    -1.490243 -1.607077    -1.620430  ...    -0.952804    -0.929437   \n",
              "4     1.876321  1.865535  1000.000000  ...     0.776188     0.725496   \n",
              "\n",
              "           493          494          495       496          497       498  \\\n",
              "0     0.362068     0.092083    -0.081268 -0.212573  1000.000000 -0.664392   \n",
              "1    -0.258138  1000.000000    -0.683647 -0.773817    -0.785255 -0.714885   \n",
              "2  1000.000000     0.517174  1000.000000  0.476270     0.438513  0.394463   \n",
              "3    -0.922761    -0.929437    -0.909409 -0.835970    -0.695768 -0.478790   \n",
              "4  1000.000000     0.731967     0.808545  0.839823  1000.000000  0.437520   \n",
              "\n",
              "           499       500  \n",
              "0    -1.073796 -1.564343  \n",
              "1    -0.560443 -0.319086  \n",
              "2  1000.000000  0.255391  \n",
              "3    -0.188707  0.119736  \n",
              "4  1000.000000 -0.602213  \n",
              "\n",
              "[5 rows x 501 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d133ae22-2e4c-433d-8853-1dd075ad6d0e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>491</th>\n",
              "      <th>492</th>\n",
              "      <th>493</th>\n",
              "      <th>494</th>\n",
              "      <th>495</th>\n",
              "      <th>496</th>\n",
              "      <th>497</th>\n",
              "      <th>498</th>\n",
              "      <th>499</th>\n",
              "      <th>500</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.797172</td>\n",
              "      <td>-0.664392</td>\n",
              "      <td>-0.373015</td>\n",
              "      <td>0.040815</td>\n",
              "      <td>0.526936</td>\n",
              "      <td>0.984288</td>\n",
              "      <td>1.353120</td>\n",
              "      <td>1.578108</td>\n",
              "      <td>1.659251</td>\n",
              "      <td>...</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>0.362068</td>\n",
              "      <td>0.092083</td>\n",
              "      <td>-0.081268</td>\n",
              "      <td>-0.212573</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>-0.664392</td>\n",
              "      <td>-1.073796</td>\n",
              "      <td>-1.564343</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.804855</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>0.373474</td>\n",
              "      <td>0.038343</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>-0.740860</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>-1.395357</td>\n",
              "      <td>-1.570192</td>\n",
              "      <td>...</td>\n",
              "      <td>0.386403</td>\n",
              "      <td>0.049213</td>\n",
              "      <td>-0.258138</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>-0.683647</td>\n",
              "      <td>-0.773817</td>\n",
              "      <td>-0.785255</td>\n",
              "      <td>-0.714885</td>\n",
              "      <td>-0.560443</td>\n",
              "      <td>-0.319086</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.727985</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>-0.499124</td>\n",
              "      <td>-1.068629</td>\n",
              "      <td>-1.578351</td>\n",
              "      <td>-1.990534</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>-2.503403</td>\n",
              "      <td>-2.585211</td>\n",
              "      <td>...</td>\n",
              "      <td>0.394463</td>\n",
              "      <td>0.463685</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>0.517174</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>0.476270</td>\n",
              "      <td>0.438513</td>\n",
              "      <td>0.394463</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>0.255391</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.234439</td>\n",
              "      <td>-0.502157</td>\n",
              "      <td>-0.732488</td>\n",
              "      <td>-0.946128</td>\n",
              "      <td>-1.139739</td>\n",
              "      <td>-1.323336</td>\n",
              "      <td>-1.490243</td>\n",
              "      <td>-1.607077</td>\n",
              "      <td>-1.620430</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.952804</td>\n",
              "      <td>-0.929437</td>\n",
              "      <td>-0.922761</td>\n",
              "      <td>-0.929437</td>\n",
              "      <td>-0.909409</td>\n",
              "      <td>-0.835970</td>\n",
              "      <td>-0.695768</td>\n",
              "      <td>-0.478790</td>\n",
              "      <td>-0.188707</td>\n",
              "      <td>0.119736</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-1.0</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>-0.062285</td>\n",
              "      <td>0.235829</td>\n",
              "      <td>0.710396</td>\n",
              "      <td>1.239969</td>\n",
              "      <td>1.649823</td>\n",
              "      <td>1.876321</td>\n",
              "      <td>1.865535</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.776188</td>\n",
              "      <td>0.725496</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>0.731967</td>\n",
              "      <td>0.808545</td>\n",
              "      <td>0.839823</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>0.437520</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>-0.602213</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 501 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d133ae22-2e4c-433d-8853-1dd075ad6d0e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d133ae22-2e4c-433d-8853-1dd075ad6d0e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d133ae22-2e4c-433d-8853-1dd075ad6d0e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train_nan = df_train_nan.to_numpy()\n",
        "x_train_nan = df_train_nan[:, 1:]"
      ],
      "metadata": {
        "id": "ZedM7aGJsHso"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_nan = x_train_nan.reshape((x_train_nan.shape[0], x_train_nan.shape[1], 1))\n",
        "print(x_train_nan.shape)"
      ],
      "metadata": {
        "id": "wrXWii6-snJ6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04548c9f-7dd3-4b69-9c32-3ee86b543e82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3601, 500, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train_nan_mask = df_train_nan_mask.reshape((df_train_nan_mask.shape[0], df_train_nan_mask.shape[1], 1))\n",
        "print(df_train_nan_mask.shape)"
      ],
      "metadata": {
        "id": "6fDxzj74Y9Jz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9198cbbf-82ba-4a5b-8b9d-1103df2085d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3601, 500, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Oc9oEu-5LIA1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_input = np.concatenate([x_train_nan, df_train_nan_mask], axis=2)\n",
        "print(x_train_input.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lifs4hyH2vhG",
        "outputId": "ccbc8d42-6f69-4280-9088-bcf7d391aae9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3601, 500, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train_input[0, :20, 0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SndZjE5X2vjq",
        "outputId": "422b9e1d-1d12-4ae9-e127-96699c16a4d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-7.9717168e-01 -6.6439208e-01 -3.7301463e-01  4.0815121e-02\n",
            "  5.2693599e-01  9.8428794e-01  1.3531202e+00  1.5781078e+00\n",
            "  1.6592509e+00  1.6408093e+00  1.5522896e+00  1.4379516e+00\n",
            "  1.2793537e+00  1.0691193e+00  1.0000000e+03  1.0000000e+03\n",
            " -3.0072351e-01 -9.3732792e-01  1.0000000e+03 -1.9516165e+00]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train_input[0, :20, 1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uoAjiDx83dnh",
        "outputId": "8147b9fe-de2e-490f-de21-061b7fa79a97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UuAUfl2x3dpx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-d50cnAhtTDU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def readucr(filename):\n",
        "    data = np.loadtxt(filename, delimiter=\"\\t\")\n",
        "    y = data[:, 0]\n",
        "    x = data[:, 1:]\n",
        "    return x, y.astype(int)\n",
        "\n",
        "x_train_target, y_train = readucr(\"/content/drive/MyDrive/FordA_TRAIN.tsv\")\n",
        "y_train = y_train.astype(int)\n",
        "print(y_train.shape)\n",
        "\n",
        "x_train_target = x_train_target.reshape((x_train_target.shape[0], x_train_target.shape[1]))\n",
        "print(x_train_target.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g12wOnFxTH2o",
        "outputId": "99a63b0d-33a2-4bdf-9c3e-17a4f8bb612b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3601,)\n",
            "(3601, 500)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "O-SHn8THTH5D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train_input[0,:20,0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7NJBEYcxTH7a",
        "outputId": "aa99c6cc-9f4a-4661-d8e6-d72c9381e3d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-7.9717168e-01 -6.6439208e-01 -3.7301463e-01  4.0815121e-02\n",
            "  5.2693599e-01  9.8428794e-01  1.3531202e+00  1.5781078e+00\n",
            "  1.6592509e+00  1.6408093e+00  1.5522896e+00  1.4379516e+00\n",
            "  1.2793537e+00  1.0691193e+00  1.0000000e+03  1.0000000e+03\n",
            " -3.0072351e-01 -9.3732792e-01  1.0000000e+03 -1.9516165e+00]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train_target[0,:20])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GvTZRo5XTH9g",
        "outputId": "53541f08-d1d5-450e-9b5f-503101acf4e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-0.79717168 -0.66439208 -0.37301463  0.04081512  0.52693599  0.98428794\n",
            "  1.3531202   1.5781078   1.6592509   1.6408093   1.5522896   1.4379516\n",
            "  1.2793537   1.0691193   0.744547    0.27760541 -0.30072351 -0.93732792\n",
            " -1.5200828  -1.9516165 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train[y_train == -1] = 0"
      ],
      "metadata": {
        "id": "XBSEdiWkTH_3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idx = np.random.permutation(len(x_train_target))\n",
        "x_train_input  = x_train_input[idx]\n",
        "x_train_target = x_train_target[idx]\n",
        "y_train = y_train[idx]"
      ],
      "metadata": {
        "id": "iJWGUNBLGCGv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = tf.data.Dataset.from_tensor_slices((x_train_input, (y_train, x_train_target))).batch(32)\n",
        "#train_ds = tf.data.Dataset.from_tensor_slices((x_train_input, y_train)).batch(32)\n",
        "train_ds = train_ds.cache().prefetch(buffer_size=tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "3JRGml5lsnSa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for x_nan, y in train_ds:\n",
        "  print(x_nan.shape)\n",
        "  print(y)\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jCqE9dXbXF9o",
        "outputId": "3f35aee0-f670-4e5c-a6a2-d451a1182a0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(32, 500, 2)\n",
            "tf.Tensor([0 0 0 1 0 1 0 0 1 0 0 0 1 1 1 0 0 0 0 0 0 1 1 1 0 1 0 1 1 1 1 0], shape=(32,), dtype=int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "F_DTYzU0ITQe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8jt05iMpITSk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load test data\n",
        "\n",
        "df_test_nan = pd.read_csv('/content/drive/MyDrive/test_nan.csv', header=None)\n",
        "df_test_nan.head(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "AsE7tgJxITVF",
        "outputId": "1458d219-f059-40d6-ff2c-e0aad4937b30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   0         1         2         3         4         5         6         7    \\\n",
              "0 -1.0 -0.140402  0.171641  0.302044       NaN  0.033853 -0.224183 -0.469987   \n",
              "1 -1.0  0.334038       NaN       NaN  0.671852  0.887897       NaN  1.059750   \n",
              "2 -1.0  0.716686  0.744367  0.725913  0.661325  0.555217  0.413585  0.246580   \n",
              "\n",
              "        8         9    ...       491       492       493       494       495  \\\n",
              "0 -0.645396 -0.617700  ...       NaN       NaN  0.974831  1.258717  1.143316   \n",
              "1  1.030290       NaN  ...  0.435186 -0.346502 -0.924912 -1.208716 -1.247996   \n",
              "2  0.065273 -0.121109  ...  3.171020  2.276019  1.219548  0.081881 -1.050250   \n",
              "\n",
              "        496       497       498       499       500  \n",
              "0  0.647092       NaN -0.690402 -0.976596       NaN  \n",
              "1 -1.139974 -1.041772 -1.041772 -1.159614 -1.375659  \n",
              "2 -2.092881 -2.983269 -3.675281 -4.136622 -4.339612  \n",
              "\n",
              "[3 rows x 501 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0a969d68-5b8a-4b36-afe0-c42424995e53\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>491</th>\n",
              "      <th>492</th>\n",
              "      <th>493</th>\n",
              "      <th>494</th>\n",
              "      <th>495</th>\n",
              "      <th>496</th>\n",
              "      <th>497</th>\n",
              "      <th>498</th>\n",
              "      <th>499</th>\n",
              "      <th>500</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.140402</td>\n",
              "      <td>0.171641</td>\n",
              "      <td>0.302044</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.033853</td>\n",
              "      <td>-0.224183</td>\n",
              "      <td>-0.469987</td>\n",
              "      <td>-0.645396</td>\n",
              "      <td>-0.617700</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.974831</td>\n",
              "      <td>1.258717</td>\n",
              "      <td>1.143316</td>\n",
              "      <td>0.647092</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.690402</td>\n",
              "      <td>-0.976596</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.334038</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.671852</td>\n",
              "      <td>0.887897</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.059750</td>\n",
              "      <td>1.030290</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0.435186</td>\n",
              "      <td>-0.346502</td>\n",
              "      <td>-0.924912</td>\n",
              "      <td>-1.208716</td>\n",
              "      <td>-1.247996</td>\n",
              "      <td>-1.139974</td>\n",
              "      <td>-1.041772</td>\n",
              "      <td>-1.041772</td>\n",
              "      <td>-1.159614</td>\n",
              "      <td>-1.375659</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.716686</td>\n",
              "      <td>0.744367</td>\n",
              "      <td>0.725913</td>\n",
              "      <td>0.661325</td>\n",
              "      <td>0.555217</td>\n",
              "      <td>0.413585</td>\n",
              "      <td>0.246580</td>\n",
              "      <td>0.065273</td>\n",
              "      <td>-0.121109</td>\n",
              "      <td>...</td>\n",
              "      <td>3.171020</td>\n",
              "      <td>2.276019</td>\n",
              "      <td>1.219548</td>\n",
              "      <td>0.081881</td>\n",
              "      <td>-1.050250</td>\n",
              "      <td>-2.092881</td>\n",
              "      <td>-2.983269</td>\n",
              "      <td>-3.675281</td>\n",
              "      <td>-4.136622</td>\n",
              "      <td>-4.339612</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3 rows × 501 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0a969d68-5b8a-4b36-afe0-c42424995e53')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0a969d68-5b8a-4b36-afe0-c42424995e53 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0a969d68-5b8a-4b36-afe0-c42424995e53');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_test_nan_mask = df_test_nan.isna()\n",
        "df_test_nan_mask.head(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "dxGQqWZUIudE",
        "outputId": "e7357f67-aca4-4f21-db51-63bc26503f2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     0      1      2      3      4      5      6      7      8      9    ...  \\\n",
              "0  False  False  False  False   True  False  False  False  False  False  ...   \n",
              "1  False  False   True   True  False  False   True  False  False   True  ...   \n",
              "2  False  False  False  False  False  False  False  False  False  False  ...   \n",
              "\n",
              "     491    492    493    494    495    496    497    498    499    500  \n",
              "0   True   True  False  False  False  False   True  False  False   True  \n",
              "1  False  False  False  False  False  False  False  False  False  False  \n",
              "2  False  False  False  False  False  False  False  False  False  False  \n",
              "\n",
              "[3 rows x 501 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-566af4e5-c2ec-4847-8ffa-30201ad8439b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>491</th>\n",
              "      <th>492</th>\n",
              "      <th>493</th>\n",
              "      <th>494</th>\n",
              "      <th>495</th>\n",
              "      <th>496</th>\n",
              "      <th>497</th>\n",
              "      <th>498</th>\n",
              "      <th>499</th>\n",
              "      <th>500</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3 rows × 501 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-566af4e5-c2ec-4847-8ffa-30201ad8439b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-566af4e5-c2ec-4847-8ffa-30201ad8439b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-566af4e5-c2ec-4847-8ffa-30201ad8439b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "t4iukopSOBCa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test_nan_mask = df_test_nan_mask.to_numpy()\n",
        "df_test_nan_mask = df_test_nan_mask*1.0\n",
        "df_test_nan_mask = df_test_nan_mask.reshape((df_test_nan_mask.shape[0], df_test_nan_mask.shape[1], 1))\n",
        "print(df_test_nan_mask.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6StvmZEUJFfW",
        "outputId": "f1f7261a-0fe5-4996-ce13-22bf6e7ff80b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1320, 501, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_test_nan_mask = df_test_nan_mask[:, 1:]\n",
        "print(df_test_nan_mask.shape)"
      ],
      "metadata": {
        "id": "wd0MPX6_JFhz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a0e882b-aff4-477c-c82f-add687d64b85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1320, 500, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_test_nan = df_test_nan.fillna(1000)\n",
        "df_test_nan = df_test_nan.to_numpy()\n",
        "x_test_nan = df_test_nan[:, 1:]\n",
        "\n",
        "x_test_nan = x_test_nan.reshape((x_test_nan.shape[0], x_test_nan.shape[1], 1))\n",
        "print(x_test_nan.shape)\n",
        "\n",
        "y_test = df_test_nan[:, 0]\n",
        "y_test = y_test.astype(int)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Td5UjsyLa5d",
        "outputId": "922c4204-121e-40ed-b9ce-096f60256ca2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1320, 500, 1)\n",
            "(1320,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_test_input = np.concatenate([x_test_nan, df_test_nan_mask], axis=2)\n",
        "print(x_train_input.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4tJHnrqpLa_S",
        "outputId": "c6095d77-ef25-49f9-b50a-0c74dd8b07b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3601, 500, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test[y_test == -1] = 0"
      ],
      "metadata": {
        "id": "w5nXR_yCXhs1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_test_input.shape)\n",
        "print(y_test[:20])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UzGX5TLcXhvB",
        "outputId": "8f9b6748-4d52-41e8-88ae-9c7ff44e57d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1320, 500, 2)\n",
            "[0 0 0 1 0 1 0 0 1 1 0 1 0 1 0 1 0 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RZMU13cdXhxD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FIKvYsplBWdu"
      },
      "source": [
        "## Build a model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dASnMDEnBWdu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b4a0a35-c869-4692-f6ad-3d70e0d10638"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_13\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_14 (InputLayer)          [(None, 500, 2)]     0           []                               \n",
            "                                                                                                  \n",
            " conv1d_91 (Conv1D)             (None, 500, 64)      448         ['input_14[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_78 (BatchN  (None, 500, 64)     256         ['conv1d_91[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_52 (ReLU)                (None, 500, 64)      0           ['batch_normalization_78[0][0]'] \n",
            "                                                                                                  \n",
            " conv1d_92 (Conv1D)             (None, 500, 64)      12352       ['re_lu_52[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_79 (BatchN  (None, 500, 64)     256         ['conv1d_92[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " p_re_lu_26 (PReLU)             (None, 500, 64)      32000       ['batch_normalization_79[0][0]'] \n",
            "                                                                                                  \n",
            " dropout_62 (Dropout)           (None, 500, 64)      0           ['p_re_lu_26[0][0]']             \n",
            "                                                                                                  \n",
            " conv1d_93 (Conv1D)             (None, 500, 64)      12352       ['dropout_62[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_80 (BatchN  (None, 500, 64)     256         ['conv1d_93[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " p_re_lu_27 (PReLU)             (None, 500, 64)      32000       ['batch_normalization_80[0][0]'] \n",
            "                                                                                                  \n",
            " tf.__operators__.add (TFOpLamb  (None, 500, 64)     0           ['p_re_lu_27[0][0]',             \n",
            " da)                                                              're_lu_52[0][0]']               \n",
            "                                                                                                  \n",
            " dropout_63 (Dropout)           (None, 500, 64)      0           ['tf.__operators__.add[0][0]']   \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_27 (S  (None, 500)         0           ['input_14[0][0]']               \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " conv1d_94 (Conv1D)             (None, 500, 1)       193         ['dropout_63[0][0]']             \n",
            "                                                                                                  \n",
            " tf.cast_13 (TFOpLambda)        (None, 500)          0           ['tf.__operators__.getitem_27[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " flatten_13 (Flatten)           (None, 500)          0           ['conv1d_94[0][0]']              \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_26 (S  (None, 500)         0           ['input_14[0][0]']               \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " tf.where_13 (TFOpLambda)       (None, 500)          0           ['tf.cast_13[0][0]',             \n",
            "                                                                  'flatten_13[0][0]',             \n",
            "                                                                  'tf.__operators__.getitem_26[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " reshape_13 (Reshape)           (None, 500, 1)       0           ['tf.where_13[0][0]']            \n",
            "                                                                                                  \n",
            " conv1d_95 (Conv1D)             (None, 500, 64)      256         ['reshape_13[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_81 (BatchN  (None, 500, 64)     256         ['conv1d_95[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_53 (ReLU)                (None, 500, 64)      0           ['batch_normalization_81[0][0]'] \n",
            "                                                                                                  \n",
            " dropout_64 (Dropout)           (None, 500, 64)      0           ['re_lu_53[0][0]']               \n",
            "                                                                                                  \n",
            " conv1d_96 (Conv1D)             (None, 500, 64)      12352       ['dropout_64[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_82 (BatchN  (None, 500, 64)     256         ['conv1d_96[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_54 (ReLU)                (None, 500, 64)      0           ['batch_normalization_82[0][0]'] \n",
            "                                                                                                  \n",
            " dropout_65 (Dropout)           (None, 500, 64)      0           ['re_lu_54[0][0]']               \n",
            "                                                                                                  \n",
            " conv1d_97 (Conv1D)             (None, 500, 64)      12352       ['dropout_65[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_83 (BatchN  (None, 500, 64)     256         ['conv1d_97[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_55 (ReLU)                (None, 500, 64)      0           ['batch_normalization_83[0][0]'] \n",
            "                                                                                                  \n",
            " tf.__operators__.add_1 (TFOpLa  (None, 500, 64)     0           ['re_lu_55[0][0]',               \n",
            " mbda)                                                            're_lu_53[0][0]']               \n",
            "                                                                                                  \n",
            " dropout_66 (Dropout)           (None, 500, 64)      0           ['tf.__operators__.add_1[0][0]'] \n",
            "                                                                                                  \n",
            " global_average_pooling1d_13 (G  (None, 64)          0           ['dropout_66[0][0]']             \n",
            " lobalAveragePooling1D)                                                                           \n",
            "                                                                                                  \n",
            " pred (Dense)                   (None, 2)            130         ['global_average_pooling1d_13[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 115,971\n",
            "Trainable params: 115,203\n",
            "Non-trainable params: 768\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Build a filling model\n",
        "\n",
        "input_layer = keras.layers.Input((500, 2))\n",
        "\n",
        "origin = input_layer[:,:,0]\n",
        "condition = tf.cast(input_layer[:,:,1], dtype=tf.bool)\n",
        "\n",
        "x = keras.layers.Conv1D(filters=64, kernel_size=3, padding=\"same\")(input_layer)\n",
        "x = keras.layers.BatchNormalization()(x)\n",
        "x = keras.layers.ReLU()(x)\n",
        "\n",
        "pre = x\n",
        "x = keras.layers.Conv1D(filters=64, kernel_size=3, padding=\"same\")(x)\n",
        "x = keras.layers.BatchNormalization()(x)\n",
        "x = keras.layers.PReLU()(x)\n",
        "x = keras.layers.Dropout(0.2)(x)\n",
        "\n",
        "x = keras.layers.Conv1D(filters=64, kernel_size=3, padding=\"same\")(x)\n",
        "x = keras.layers.BatchNormalization()(x)\n",
        "x = keras.layers.PReLU()(x)\n",
        "\n",
        "x = x + pre\n",
        "\n",
        "x = keras.layers.Dropout(0.2)(x)\n",
        "\n",
        "x = keras.layers.Conv1D(filters=1, kernel_size=3, padding=\"same\")(x)\n",
        "x = keras.layers.Flatten()(x)\n",
        "data_filled = tf.where(condition, x, origin)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Build a classification model\n",
        "x = keras.layers.Reshape((500, 1))(data_filled)\n",
        "\n",
        "x = keras.layers.Conv1D(filters=64, kernel_size=3, padding=\"same\")(x)\n",
        "x = keras.layers.BatchNormalization()(x)\n",
        "x = keras.layers.ReLU()(x)\n",
        "\n",
        "pre = x\n",
        "\n",
        "x = keras.layers.Dropout(0.2)(x)\n",
        "\n",
        "x = keras.layers.Conv1D(filters=64, kernel_size=3, padding=\"same\")(x)\n",
        "x = keras.layers.BatchNormalization()(x)\n",
        "x = keras.layers.ReLU()(x)\n",
        "x = keras.layers.Dropout(0.2)(x)\n",
        "\n",
        "x = keras.layers.Conv1D(filters=64, kernel_size=3, padding=\"same\")(x)\n",
        "x = keras.layers.BatchNormalization()(x)\n",
        "x = keras.layers.ReLU()(x)\n",
        "\n",
        "x = x + pre\n",
        "\n",
        "x = keras.layers.Dropout(0.3)(x)\n",
        "\n",
        "x = keras.layers.GlobalAveragePooling1D()(x)\n",
        "pred = keras.layers.Dense(2, activation=\"softmax\", name='pred')(x)\n",
        "\n",
        "model = keras.models.Model(inputs=input_layer, outputs=[pred, data_filled])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tYVmk2QSBWdu"
      },
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "muPLmcaVBWdv",
        "outputId": "344aa02e-bda1-4007-a131-5a4445386be0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "113/113 [==============================] - 9s 19ms/step - loss: 9.9205 - pred_loss: 0.6667 - tf.where_10_loss: 0.1851 - pred_sparse_categorical_accuracy: 0.5590 - val_loss: 1.2280 - val_pred_loss: 1.2280 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.4841 - lr: 0.0010\n",
            "Epoch 2/500\n",
            "113/113 [==============================] - 2s 15ms/step - loss: 8.1820 - pred_loss: 0.6403 - tf.where_10_loss: 0.1508 - pred_sparse_categorical_accuracy: 0.5957 - val_loss: 1.3139 - val_pred_loss: 1.3139 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.4841 - lr: 0.0010\n",
            "Epoch 3/500\n",
            "113/113 [==============================] - 2s 15ms/step - loss: 8.1227 - pred_loss: 0.6160 - tf.where_10_loss: 0.1501 - pred_sparse_categorical_accuracy: 0.6373 - val_loss: 0.8565 - val_pred_loss: 0.8565 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.4841 - lr: 0.0010\n",
            "Epoch 4/500\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 8.0792 - pred_loss: 0.5835 - tf.where_10_loss: 0.1499 - pred_sparse_categorical_accuracy: 0.6904 - val_loss: 0.6493 - val_pred_loss: 0.6493 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.5970 - lr: 0.0010\n",
            "Epoch 5/500\n",
            "113/113 [==============================] - 2s 15ms/step - loss: 8.0563 - pred_loss: 0.5655 - tf.where_10_loss: 0.1498 - pred_sparse_categorical_accuracy: 0.6959 - val_loss: 0.7559 - val_pred_loss: 0.7559 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6129 - lr: 0.0010\n",
            "Epoch 6/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 8.0358 - pred_loss: 0.5482 - tf.where_10_loss: 0.1498 - pred_sparse_categorical_accuracy: 0.7029 - val_loss: 0.8111 - val_pred_loss: 0.8111 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.5205 - lr: 0.0010\n",
            "Epoch 7/500\n",
            "113/113 [==============================] - 2s 20ms/step - loss: 8.0194 - pred_loss: 0.5357 - tf.where_10_loss: 0.1497 - pred_sparse_categorical_accuracy: 0.7067 - val_loss: 1.0126 - val_pred_loss: 1.0126 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.5561 - lr: 0.0010\n",
            "Epoch 8/500\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 7.9996 - pred_loss: 0.5182 - tf.where_10_loss: 0.1496 - pred_sparse_categorical_accuracy: 0.7309 - val_loss: 0.5018 - val_pred_loss: 0.5018 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7432 - lr: 0.0010\n",
            "Epoch 9/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 7.9890 - pred_loss: 0.5118 - tf.where_10_loss: 0.1495 - pred_sparse_categorical_accuracy: 0.7334 - val_loss: 0.6277 - val_pred_loss: 0.6277 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6871 - lr: 0.0010\n",
            "Epoch 10/500\n",
            "113/113 [==============================] - 2s 15ms/step - loss: 7.9732 - pred_loss: 0.4993 - tf.where_10_loss: 0.1495 - pred_sparse_categorical_accuracy: 0.7384 - val_loss: 0.6864 - val_pred_loss: 0.6864 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6455 - lr: 0.0010\n",
            "Epoch 11/500\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 7.9637 - pred_loss: 0.4947 - tf.where_10_loss: 0.1494 - pred_sparse_categorical_accuracy: 0.7431 - val_loss: 0.5528 - val_pred_loss: 0.5528 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7121 - lr: 0.0010\n",
            "Epoch 12/500\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 7.9401 - pred_loss: 0.4911 - tf.where_10_loss: 0.1490 - pred_sparse_categorical_accuracy: 0.7415 - val_loss: 0.6668 - val_pred_loss: 0.6668 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6364 - lr: 0.0010\n",
            "Epoch 13/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 7.8406 - pred_loss: 0.4823 - tf.where_10_loss: 0.1472 - pred_sparse_categorical_accuracy: 0.7470 - val_loss: 1.7318 - val_pred_loss: 1.7318 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.5167 - lr: 0.0010\n",
            "Epoch 14/500\n",
            "113/113 [==============================] - 2s 20ms/step - loss: 7.8162 - pred_loss: 0.4838 - tf.where_10_loss: 0.1466 - pred_sparse_categorical_accuracy: 0.7442 - val_loss: 0.7015 - val_pred_loss: 0.7015 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6947 - lr: 0.0010\n",
            "Epoch 15/500\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 7.6860 - pred_loss: 0.4771 - tf.where_10_loss: 0.1442 - pred_sparse_categorical_accuracy: 0.7517 - val_loss: 0.6374 - val_pred_loss: 0.6374 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6894 - lr: 0.0010\n",
            "Epoch 16/500\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 7.3868 - pred_loss: 0.4700 - tf.where_10_loss: 0.1383 - pred_sparse_categorical_accuracy: 0.7595 - val_loss: 1.9481 - val_pred_loss: 1.9481 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.5205 - lr: 0.0010\n",
            "Epoch 17/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 7.2683 - pred_loss: 0.4682 - tf.where_10_loss: 0.1360 - pred_sparse_categorical_accuracy: 0.7598 - val_loss: 0.5728 - val_pred_loss: 0.5728 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6902 - lr: 0.0010\n",
            "Epoch 18/500\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 6.5632 - pred_loss: 0.4617 - tf.where_10_loss: 0.1220 - pred_sparse_categorical_accuracy: 0.7645 - val_loss: 0.6535 - val_pred_loss: 0.6535 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6553 - lr: 0.0010\n",
            "Epoch 19/500\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 5.8475 - pred_loss: 0.4549 - tf.where_10_loss: 0.1079 - pred_sparse_categorical_accuracy: 0.7751 - val_loss: 0.6588 - val_pred_loss: 0.6588 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6500 - lr: 0.0010\n",
            "Epoch 20/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 5.1092 - pred_loss: 0.4661 - tf.where_10_loss: 0.0929 - pred_sparse_categorical_accuracy: 0.7573 - val_loss: 0.5180 - val_pred_loss: 0.5180 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7258 - lr: 0.0010\n",
            "Epoch 21/500\n",
            "113/113 [==============================] - 2s 20ms/step - loss: 4.6945 - pred_loss: 0.4522 - tf.where_10_loss: 0.0848 - pred_sparse_categorical_accuracy: 0.7717 - val_loss: 0.5633 - val_pred_loss: 0.5633 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6886 - lr: 0.0010\n",
            "Epoch 22/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 4.2607 - pred_loss: 0.4429 - tf.where_10_loss: 0.0764 - pred_sparse_categorical_accuracy: 0.7776 - val_loss: 1.0347 - val_pred_loss: 1.0347 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.5909 - lr: 0.0010\n",
            "Epoch 23/500\n",
            "113/113 [==============================] - 2s 15ms/step - loss: 3.9594 - pred_loss: 0.4455 - tf.where_10_loss: 0.0703 - pred_sparse_categorical_accuracy: 0.7748 - val_loss: 0.4343 - val_pred_loss: 0.4343 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7841 - lr: 0.0010\n",
            "Epoch 24/500\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 4.1201 - pred_loss: 0.4415 - tf.where_10_loss: 0.0736 - pred_sparse_categorical_accuracy: 0.7773 - val_loss: 0.4355 - val_pred_loss: 0.4355 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7758 - lr: 0.0010\n",
            "Epoch 25/500\n",
            "113/113 [==============================] - 2s 15ms/step - loss: 3.7357 - pred_loss: 0.4360 - tf.where_10_loss: 0.0660 - pred_sparse_categorical_accuracy: 0.7723 - val_loss: 0.5143 - val_pred_loss: 0.5143 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7356 - lr: 0.0010\n",
            "Epoch 26/500\n",
            "113/113 [==============================] - 2s 15ms/step - loss: 3.8664 - pred_loss: 0.4445 - tf.where_10_loss: 0.0684 - pred_sparse_categorical_accuracy: 0.7820 - val_loss: 0.5114 - val_pred_loss: 0.5114 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7205 - lr: 0.0010\n",
            "Epoch 27/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 3.6296 - pred_loss: 0.4388 - tf.where_10_loss: 0.0638 - pred_sparse_categorical_accuracy: 0.7767 - val_loss: 0.5425 - val_pred_loss: 0.5425 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6985 - lr: 0.0010\n",
            "Epoch 28/500\n",
            "113/113 [==============================] - 2s 19ms/step - loss: 3.3829 - pred_loss: 0.4349 - tf.where_10_loss: 0.0590 - pred_sparse_categorical_accuracy: 0.7759 - val_loss: 0.5904 - val_pred_loss: 0.5904 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6818 - lr: 0.0010\n",
            "Epoch 29/500\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 3.3803 - pred_loss: 0.4253 - tf.where_10_loss: 0.0591 - pred_sparse_categorical_accuracy: 0.7845 - val_loss: 0.5379 - val_pred_loss: 0.5379 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7106 - lr: 0.0010\n",
            "Epoch 30/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 3.2915 - pred_loss: 0.4220 - tf.where_10_loss: 0.0574 - pred_sparse_categorical_accuracy: 0.7906 - val_loss: 0.3855 - val_pred_loss: 0.3855 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8098 - lr: 0.0010\n",
            "Epoch 31/500\n",
            "113/113 [==============================] - 2s 15ms/step - loss: 3.3249 - pred_loss: 0.4372 - tf.where_10_loss: 0.0578 - pred_sparse_categorical_accuracy: 0.7767 - val_loss: 0.5348 - val_pred_loss: 0.5348 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6955 - lr: 0.0010\n",
            "Epoch 32/500\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 3.0954 - pred_loss: 0.4274 - tf.where_10_loss: 0.0534 - pred_sparse_categorical_accuracy: 0.7862 - val_loss: 0.5297 - val_pred_loss: 0.5297 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6939 - lr: 0.0010\n",
            "Epoch 33/500\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 3.1569 - pred_loss: 0.4299 - tf.where_10_loss: 0.0545 - pred_sparse_categorical_accuracy: 0.7798 - val_loss: 0.4055 - val_pred_loss: 0.4055 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7826 - lr: 0.0010\n",
            "Epoch 34/500\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 3.0893 - pred_loss: 0.4245 - tf.where_10_loss: 0.0533 - pred_sparse_categorical_accuracy: 0.7898 - val_loss: 0.5335 - val_pred_loss: 0.5335 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7159 - lr: 0.0010\n",
            "Epoch 35/500\n",
            "113/113 [==============================] - 2s 21ms/step - loss: 2.9267 - pred_loss: 0.4223 - tf.where_10_loss: 0.0501 - pred_sparse_categorical_accuracy: 0.7889 - val_loss: 0.4757 - val_pred_loss: 0.4757 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7265 - lr: 0.0010\n",
            "Epoch 36/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 3.1380 - pred_loss: 0.4194 - tf.where_10_loss: 0.0544 - pred_sparse_categorical_accuracy: 0.7906 - val_loss: 0.3888 - val_pred_loss: 0.3888 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8015 - lr: 0.0010\n",
            "Epoch 37/500\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 2.7251 - pred_loss: 0.4108 - tf.where_10_loss: 0.0463 - pred_sparse_categorical_accuracy: 0.7934 - val_loss: 0.5650 - val_pred_loss: 0.5650 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6720 - lr: 0.0010\n",
            "Epoch 38/500\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 2.7248 - pred_loss: 0.4144 - tf.where_10_loss: 0.0462 - pred_sparse_categorical_accuracy: 0.7937 - val_loss: 0.5024 - val_pred_loss: 0.5024 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7114 - lr: 0.0010\n",
            "Epoch 39/500\n",
            "113/113 [==============================] - 2s 15ms/step - loss: 2.7694 - pred_loss: 0.4226 - tf.where_10_loss: 0.0469 - pred_sparse_categorical_accuracy: 0.7864 - val_loss: 0.4996 - val_pred_loss: 0.4996 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7220 - lr: 0.0010\n",
            "Epoch 40/500\n",
            "113/113 [==============================] - 2s 15ms/step - loss: 2.4924 - pred_loss: 0.4145 - tf.where_10_loss: 0.0416 - pred_sparse_categorical_accuracy: 0.7914 - val_loss: 0.4366 - val_pred_loss: 0.4366 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7561 - lr: 0.0010\n",
            "Epoch 41/500\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 2.7444 - pred_loss: 0.4159 - tf.where_10_loss: 0.0466 - pred_sparse_categorical_accuracy: 0.7914 - val_loss: 0.4247 - val_pred_loss: 0.4247 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7538 - lr: 0.0010\n",
            "Epoch 42/500\n",
            "113/113 [==============================] - 2s 19ms/step - loss: 2.4448 - pred_loss: 0.4031 - tf.where_10_loss: 0.0408 - pred_sparse_categorical_accuracy: 0.8009 - val_loss: 0.3980 - val_pred_loss: 0.3980 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7735 - lr: 0.0010\n",
            "Epoch 43/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 2.3952 - pred_loss: 0.4017 - tf.where_10_loss: 0.0399 - pred_sparse_categorical_accuracy: 0.7967 - val_loss: 0.4199 - val_pred_loss: 0.4199 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7667 - lr: 0.0010\n",
            "Epoch 44/500\n",
            "113/113 [==============================] - 2s 15ms/step - loss: 2.3724 - pred_loss: 0.4053 - tf.where_10_loss: 0.0393 - pred_sparse_categorical_accuracy: 0.8028 - val_loss: 0.5472 - val_pred_loss: 0.5472 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7000 - lr: 0.0010\n",
            "Epoch 45/500\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 2.4258 - pred_loss: 0.3931 - tf.where_10_loss: 0.0407 - pred_sparse_categorical_accuracy: 0.8131 - val_loss: 0.3686 - val_pred_loss: 0.3686 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8167 - lr: 0.0010\n",
            "Epoch 46/500\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 2.2345 - pred_loss: 0.3974 - tf.where_10_loss: 0.0367 - pred_sparse_categorical_accuracy: 0.8089 - val_loss: 0.3865 - val_pred_loss: 0.3865 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8045 - lr: 0.0010\n",
            "Epoch 47/500\n",
            "113/113 [==============================] - 2s 15ms/step - loss: 2.1488 - pred_loss: 0.3863 - tf.where_10_loss: 0.0353 - pred_sparse_categorical_accuracy: 0.8128 - val_loss: 0.4535 - val_pred_loss: 0.4535 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7432 - lr: 0.0010\n",
            "Epoch 48/500\n",
            "113/113 [==============================] - 2s 15ms/step - loss: 2.1297 - pred_loss: 0.3895 - tf.where_10_loss: 0.0348 - pred_sparse_categorical_accuracy: 0.8114 - val_loss: 0.8275 - val_pred_loss: 0.8275 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6523 - lr: 0.0010\n",
            "Epoch 49/500\n",
            "113/113 [==============================] - 2s 19ms/step - loss: 2.0312 - pred_loss: 0.3957 - tf.where_10_loss: 0.0327 - pred_sparse_categorical_accuracy: 0.8023 - val_loss: 0.4124 - val_pred_loss: 0.4124 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7455 - lr: 0.0010\n",
            "Epoch 50/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 2.0756 - pred_loss: 0.3913 - tf.where_10_loss: 0.0337 - pred_sparse_categorical_accuracy: 0.8126 - val_loss: 0.6226 - val_pred_loss: 0.6226 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6773 - lr: 0.0010\n",
            "Epoch 51/500\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 2.1051 - pred_loss: 0.3916 - tf.where_10_loss: 0.0343 - pred_sparse_categorical_accuracy: 0.8081 - val_loss: 0.5450 - val_pred_loss: 0.5450 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7212 - lr: 0.0010\n",
            "Epoch 52/500\n",
            "113/113 [==============================] - 2s 15ms/step - loss: 1.9584 - pred_loss: 0.3730 - tf.where_10_loss: 0.0317 - pred_sparse_categorical_accuracy: 0.8214 - val_loss: 0.4083 - val_pred_loss: 0.4083 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7818 - lr: 0.0010\n",
            "Epoch 53/500\n",
            "113/113 [==============================] - 2s 15ms/step - loss: 2.0405 - pred_loss: 0.3786 - tf.where_10_loss: 0.0332 - pred_sparse_categorical_accuracy: 0.8120 - val_loss: 0.3788 - val_pred_loss: 0.3788 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7909 - lr: 0.0010\n",
            "Epoch 54/500\n",
            "113/113 [==============================] - 2s 15ms/step - loss: 1.9279 - pred_loss: 0.3778 - tf.where_10_loss: 0.0310 - pred_sparse_categorical_accuracy: 0.8248 - val_loss: 0.9046 - val_pred_loss: 0.9046 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6242 - lr: 0.0010\n",
            "Epoch 55/500\n",
            "113/113 [==============================] - 2s 15ms/step - loss: 1.8821 - pred_loss: 0.3838 - tf.where_10_loss: 0.0300 - pred_sparse_categorical_accuracy: 0.8112 - val_loss: 0.5028 - val_pred_loss: 0.5028 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7174 - lr: 0.0010\n",
            "Epoch 56/500\n",
            "113/113 [==============================] - 2s 20ms/step - loss: 1.9388 - pred_loss: 0.3745 - tf.where_10_loss: 0.0313 - pred_sparse_categorical_accuracy: 0.8225 - val_loss: 0.4962 - val_pred_loss: 0.4962 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7114 - lr: 0.0010\n",
            "Epoch 57/500\n",
            "113/113 [==============================] - 2s 20ms/step - loss: 1.9629 - pred_loss: 0.3669 - tf.where_10_loss: 0.0319 - pred_sparse_categorical_accuracy: 0.8284 - val_loss: 0.7893 - val_pred_loss: 0.7893 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6689 - lr: 0.0010\n",
            "Epoch 58/500\n",
            "113/113 [==============================] - 2s 15ms/step - loss: 1.8379 - pred_loss: 0.3746 - tf.where_10_loss: 0.0293 - pred_sparse_categorical_accuracy: 0.8223 - val_loss: 0.9370 - val_pred_loss: 0.9370 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6947 - lr: 0.0010\n",
            "Epoch 59/500\n",
            "113/113 [==============================] - 2s 15ms/step - loss: 1.8337 - pred_loss: 0.3660 - tf.where_10_loss: 0.0294 - pred_sparse_categorical_accuracy: 0.8264 - val_loss: 0.5070 - val_pred_loss: 0.5070 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7242 - lr: 0.0010\n",
            "Epoch 60/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 1.7678 - pred_loss: 0.3608 - tf.where_10_loss: 0.0281 - pred_sparse_categorical_accuracy: 0.8375 - val_loss: 0.4392 - val_pred_loss: 0.4392 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7674 - lr: 0.0010\n",
            "Epoch 61/500\n",
            "113/113 [==============================] - 2s 15ms/step - loss: 1.7791 - pred_loss: 0.3686 - tf.where_10_loss: 0.0282 - pred_sparse_categorical_accuracy: 0.8284 - val_loss: 0.4724 - val_pred_loss: 0.4724 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7386 - lr: 0.0010\n",
            "Epoch 62/500\n",
            "113/113 [==============================] - 2s 15ms/step - loss: 1.7667 - pred_loss: 0.3590 - tf.where_10_loss: 0.0282 - pred_sparse_categorical_accuracy: 0.8314 - val_loss: 0.3723 - val_pred_loss: 0.3723 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8273 - lr: 0.0010\n",
            "Epoch 63/500\n",
            "113/113 [==============================] - 2s 20ms/step - loss: 1.7178 - pred_loss: 0.3614 - tf.where_10_loss: 0.0271 - pred_sparse_categorical_accuracy: 0.8331 - val_loss: 0.6442 - val_pred_loss: 0.6442 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6841 - lr: 0.0010\n",
            "Epoch 64/500\n",
            "113/113 [==============================] - 2s 21ms/step - loss: 1.7358 - pred_loss: 0.3572 - tf.where_10_loss: 0.0276 - pred_sparse_categorical_accuracy: 0.8320 - val_loss: 0.3459 - val_pred_loss: 0.3459 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8447 - lr: 0.0010\n",
            "Epoch 65/500\n",
            "113/113 [==============================] - 2s 15ms/step - loss: 1.8348 - pred_loss: 0.3648 - tf.where_10_loss: 0.0294 - pred_sparse_categorical_accuracy: 0.8223 - val_loss: 0.3212 - val_pred_loss: 0.3212 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8629 - lr: 0.0010\n",
            "Epoch 66/500\n",
            "113/113 [==============================] - 2s 15ms/step - loss: 1.6696 - pred_loss: 0.3494 - tf.where_10_loss: 0.0264 - pred_sparse_categorical_accuracy: 0.8414 - val_loss: 0.3302 - val_pred_loss: 0.3302 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8432 - lr: 0.0010\n",
            "Epoch 67/500\n",
            "113/113 [==============================] - 2s 15ms/step - loss: 1.8278 - pred_loss: 0.3566 - tf.where_10_loss: 0.0294 - pred_sparse_categorical_accuracy: 0.8423 - val_loss: 0.4582 - val_pred_loss: 0.4582 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7568 - lr: 0.0010\n",
            "Epoch 68/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 1.6973 - pred_loss: 0.3554 - tf.where_10_loss: 0.0268 - pred_sparse_categorical_accuracy: 0.8370 - val_loss: 0.9950 - val_pred_loss: 0.9950 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6098 - lr: 0.0010\n",
            "Epoch 69/500\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 1.6579 - pred_loss: 0.3463 - tf.where_10_loss: 0.0262 - pred_sparse_categorical_accuracy: 0.8409 - val_loss: 0.7805 - val_pred_loss: 0.7805 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6758 - lr: 0.0010\n",
            "Epoch 70/500\n",
            "113/113 [==============================] - 2s 19ms/step - loss: 1.6360 - pred_loss: 0.3435 - tf.where_10_loss: 0.0258 - pred_sparse_categorical_accuracy: 0.8470 - val_loss: 1.2303 - val_pred_loss: 1.2303 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6030 - lr: 0.0010\n",
            "Epoch 71/500\n",
            "113/113 [==============================] - 2s 19ms/step - loss: 1.5814 - pred_loss: 0.3384 - tf.where_10_loss: 0.0249 - pred_sparse_categorical_accuracy: 0.8456 - val_loss: 0.3855 - val_pred_loss: 0.3855 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7826 - lr: 0.0010\n",
            "Epoch 72/500\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 1.7457 - pred_loss: 0.3538 - tf.where_10_loss: 0.0278 - pred_sparse_categorical_accuracy: 0.8409 - val_loss: 0.4115 - val_pred_loss: 0.4115 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8068 - lr: 0.0010\n",
            "Epoch 73/500\n",
            "113/113 [==============================] - 2s 15ms/step - loss: 1.5057 - pred_loss: 0.3391 - tf.where_10_loss: 0.0233 - pred_sparse_categorical_accuracy: 0.8475 - val_loss: 0.6880 - val_pred_loss: 0.6880 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6788 - lr: 0.0010\n",
            "Epoch 74/500\n",
            "113/113 [==============================] - 2s 15ms/step - loss: 1.5459 - pred_loss: 0.3403 - tf.where_10_loss: 0.0241 - pred_sparse_categorical_accuracy: 0.8453 - val_loss: 0.3731 - val_pred_loss: 0.3731 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8098 - lr: 0.0010\n",
            "Epoch 75/500\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 1.5764 - pred_loss: 0.3444 - tf.where_10_loss: 0.0246 - pred_sparse_categorical_accuracy: 0.8406 - val_loss: 0.3145 - val_pred_loss: 0.3145 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8606 - lr: 0.0010\n",
            "Epoch 76/500\n",
            "113/113 [==============================] - 2s 15ms/step - loss: 1.7008 - pred_loss: 0.3458 - tf.where_10_loss: 0.0271 - pred_sparse_categorical_accuracy: 0.8367 - val_loss: 0.7990 - val_pred_loss: 0.7990 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6939 - lr: 0.0010\n",
            "Epoch 77/500\n",
            "113/113 [==============================] - 2s 19ms/step - loss: 1.5665 - pred_loss: 0.3428 - tf.where_10_loss: 0.0245 - pred_sparse_categorical_accuracy: 0.8448 - val_loss: 2.0869 - val_pred_loss: 2.0869 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.5303 - lr: 0.0010\n",
            "Epoch 78/500\n",
            "113/113 [==============================] - 2s 20ms/step - loss: 1.5149 - pred_loss: 0.3316 - tf.where_10_loss: 0.0237 - pred_sparse_categorical_accuracy: 0.8525 - val_loss: 0.3301 - val_pred_loss: 0.3301 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8439 - lr: 0.0010\n",
            "Epoch 79/500\n",
            "113/113 [==============================] - 2s 15ms/step - loss: 1.5018 - pred_loss: 0.3378 - tf.where_10_loss: 0.0233 - pred_sparse_categorical_accuracy: 0.8492 - val_loss: 0.5884 - val_pred_loss: 0.5884 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7000 - lr: 0.0010\n",
            "Epoch 80/500\n",
            "113/113 [==============================] - 2s 15ms/step - loss: 1.4472 - pred_loss: 0.3295 - tf.where_10_loss: 0.0224 - pred_sparse_categorical_accuracy: 0.8489 - val_loss: 0.4999 - val_pred_loss: 0.4999 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7341 - lr: 0.0010\n",
            "Epoch 81/500\n",
            "113/113 [==============================] - 2s 15ms/step - loss: 1.5460 - pred_loss: 0.3379 - tf.where_10_loss: 0.0242 - pred_sparse_categorical_accuracy: 0.8531 - val_loss: 0.5890 - val_pred_loss: 0.5890 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6765 - lr: 0.0010\n",
            "Epoch 82/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 1.4471 - pred_loss: 0.3442 - tf.where_10_loss: 0.0221 - pred_sparse_categorical_accuracy: 0.8417 - val_loss: 1.0694 - val_pred_loss: 1.0694 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6136 - lr: 0.0010\n",
            "Epoch 83/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 1.3798 - pred_loss: 0.3244 - tf.where_10_loss: 0.0211 - pred_sparse_categorical_accuracy: 0.8573 - val_loss: 1.7800 - val_pred_loss: 1.7800 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.5561 - lr: 0.0010\n",
            "Epoch 84/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 1.4033 - pred_loss: 0.3361 - tf.where_10_loss: 0.0213 - pred_sparse_categorical_accuracy: 0.8495 - val_loss: 0.3675 - val_pred_loss: 0.3675 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7977 - lr: 0.0010\n",
            "Epoch 85/500\n",
            "113/113 [==============================] - 2s 21ms/step - loss: 1.4452 - pred_loss: 0.3246 - tf.where_10_loss: 0.0224 - pred_sparse_categorical_accuracy: 0.8587 - val_loss: 0.7315 - val_pred_loss: 0.7315 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6735 - lr: 0.0010\n",
            "Epoch 86/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 1.3603 - pred_loss: 0.3282 - tf.where_10_loss: 0.0206 - pred_sparse_categorical_accuracy: 0.8578 - val_loss: 0.5788 - val_pred_loss: 0.5788 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7114 - lr: 0.0010\n",
            "Epoch 87/500\n",
            "113/113 [==============================] - 2s 15ms/step - loss: 1.3632 - pred_loss: 0.3231 - tf.where_10_loss: 0.0208 - pred_sparse_categorical_accuracy: 0.8520 - val_loss: 0.4002 - val_pred_loss: 0.4002 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7826 - lr: 0.0010\n",
            "Epoch 88/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 1.4679 - pred_loss: 0.3349 - tf.where_10_loss: 0.0227 - pred_sparse_categorical_accuracy: 0.8520 - val_loss: 0.3026 - val_pred_loss: 0.3026 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8750 - lr: 0.0010\n",
            "Epoch 89/500\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 1.3948 - pred_loss: 0.3191 - tf.where_10_loss: 0.0215 - pred_sparse_categorical_accuracy: 0.8545 - val_loss: 0.6127 - val_pred_loss: 0.6127 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7288 - lr: 0.0010\n",
            "Epoch 90/500\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 1.3504 - pred_loss: 0.3271 - tf.where_10_loss: 0.0205 - pred_sparse_categorical_accuracy: 0.8528 - val_loss: 0.7770 - val_pred_loss: 0.7770 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6811 - lr: 0.0010\n",
            "Epoch 91/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 1.3316 - pred_loss: 0.3206 - tf.where_10_loss: 0.0202 - pred_sparse_categorical_accuracy: 0.8567 - val_loss: 0.7771 - val_pred_loss: 0.7771 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6712 - lr: 0.0010\n",
            "Epoch 92/500\n",
            "113/113 [==============================] - 2s 20ms/step - loss: 1.3484 - pred_loss: 0.3223 - tf.where_10_loss: 0.0205 - pred_sparse_categorical_accuracy: 0.8539 - val_loss: 0.4655 - val_pred_loss: 0.4655 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7265 - lr: 0.0010\n",
            "Epoch 93/500\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 1.3478 - pred_loss: 0.3274 - tf.where_10_loss: 0.0204 - pred_sparse_categorical_accuracy: 0.8550 - val_loss: 1.3951 - val_pred_loss: 1.3951 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6576 - lr: 0.0010\n",
            "Epoch 94/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 1.2772 - pred_loss: 0.3379 - tf.where_10_loss: 0.0188 - pred_sparse_categorical_accuracy: 0.8442 - val_loss: 0.7106 - val_pred_loss: 0.7106 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7008 - lr: 0.0010\n",
            "Epoch 95/500\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 1.3941 - pred_loss: 0.3207 - tf.where_10_loss: 0.0215 - pred_sparse_categorical_accuracy: 0.8611 - val_loss: 0.4548 - val_pred_loss: 0.4548 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7470 - lr: 0.0010\n",
            "Epoch 96/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 1.2781 - pred_loss: 0.3191 - tf.where_10_loss: 0.0192 - pred_sparse_categorical_accuracy: 0.8539 - val_loss: 0.4154 - val_pred_loss: 0.4154 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7689 - lr: 0.0010\n",
            "Epoch 97/500\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 1.2600 - pred_loss: 0.3259 - tf.where_10_loss: 0.0187 - pred_sparse_categorical_accuracy: 0.8628 - val_loss: 1.0404 - val_pred_loss: 1.0404 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6636 - lr: 0.0010\n",
            "Epoch 98/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 1.3049 - pred_loss: 0.3179 - tf.where_10_loss: 0.0197 - pred_sparse_categorical_accuracy: 0.8609 - val_loss: 0.4369 - val_pred_loss: 0.4369 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7682 - lr: 0.0010\n",
            "Epoch 99/500\n",
            "113/113 [==============================] - 2s 20ms/step - loss: 1.2842 - pred_loss: 0.3242 - tf.where_10_loss: 0.0192 - pred_sparse_categorical_accuracy: 0.8484 - val_loss: 1.2803 - val_pred_loss: 1.2803 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.5258 - lr: 0.0010\n",
            "Epoch 100/500\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 1.2414 - pred_loss: 0.3207 - tf.where_10_loss: 0.0184 - pred_sparse_categorical_accuracy: 0.8620 - val_loss: 2.7295 - val_pred_loss: 2.7295 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.5341 - lr: 0.0010\n",
            "Epoch 101/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 1.1817 - pred_loss: 0.3165 - tf.where_10_loss: 0.0173 - pred_sparse_categorical_accuracy: 0.8567 - val_loss: 2.7773 - val_pred_loss: 2.7773 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.5098 - lr: 0.0010\n",
            "Epoch 102/500\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 1.2047 - pred_loss: 0.3068 - tf.where_10_loss: 0.0180 - pred_sparse_categorical_accuracy: 0.8664 - val_loss: 1.0420 - val_pred_loss: 1.0420 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6591 - lr: 0.0010\n",
            "Epoch 103/500\n",
            "113/113 [==============================] - 2s 15ms/step - loss: 1.2559 - pred_loss: 0.3017 - tf.where_10_loss: 0.0191 - pred_sparse_categorical_accuracy: 0.8678 - val_loss: 0.5147 - val_pred_loss: 0.5147 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7182 - lr: 0.0010\n",
            "Epoch 104/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 1.1382 - pred_loss: 0.3020 - tf.where_10_loss: 0.0167 - pred_sparse_categorical_accuracy: 0.8700 - val_loss: 0.8917 - val_pred_loss: 0.8917 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6295 - lr: 0.0010\n",
            "Epoch 105/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 1.2343 - pred_loss: 0.3184 - tf.where_10_loss: 0.0183 - pred_sparse_categorical_accuracy: 0.8537 - val_loss: 0.4440 - val_pred_loss: 0.4440 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7864 - lr: 0.0010\n",
            "Epoch 106/500\n",
            "113/113 [==============================] - 2s 21ms/step - loss: 1.1884 - pred_loss: 0.3128 - tf.where_10_loss: 0.0175 - pred_sparse_categorical_accuracy: 0.8623 - val_loss: 0.4115 - val_pred_loss: 0.4115 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7962 - lr: 0.0010\n",
            "Epoch 107/500\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 1.1522 - pred_loss: 0.3135 - tf.where_10_loss: 0.0168 - pred_sparse_categorical_accuracy: 0.8559 - val_loss: 0.7003 - val_pred_loss: 0.7003 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6773 - lr: 0.0010\n",
            "Epoch 108/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 1.1321 - pred_loss: 0.3078 - tf.where_10_loss: 0.0165 - pred_sparse_categorical_accuracy: 0.8625 - val_loss: 0.4427 - val_pred_loss: 0.4427 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7568 - lr: 0.0010\n",
            "Epoch 109/500\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 0.9802 - pred_loss: 0.2872 - tf.where_10_loss: 0.0139 - pred_sparse_categorical_accuracy: 0.8778 - val_loss: 1.2428 - val_pred_loss: 1.2428 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6303 - lr: 5.0000e-04\n",
            "Epoch 110/500\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 0.9401 - pred_loss: 0.2837 - tf.where_10_loss: 0.0131 - pred_sparse_categorical_accuracy: 0.8759 - val_loss: 0.6034 - val_pred_loss: 0.6034 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7053 - lr: 5.0000e-04\n",
            "Epoch 111/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.9390 - pred_loss: 0.2807 - tf.where_10_loss: 0.0132 - pred_sparse_categorical_accuracy: 0.8823 - val_loss: 1.0720 - val_pred_loss: 1.0720 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6561 - lr: 5.0000e-04\n",
            "Epoch 112/500\n",
            "113/113 [==============================] - 2s 19ms/step - loss: 0.9349 - pred_loss: 0.2867 - tf.where_10_loss: 0.0130 - pred_sparse_categorical_accuracy: 0.8753 - val_loss: 0.5028 - val_pred_loss: 0.5028 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7402 - lr: 5.0000e-04\n",
            "Epoch 113/500\n",
            "113/113 [==============================] - 2s 20ms/step - loss: 0.9517 - pred_loss: 0.2892 - tf.where_10_loss: 0.0132 - pred_sparse_categorical_accuracy: 0.8725 - val_loss: 0.7930 - val_pred_loss: 0.7930 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6932 - lr: 5.0000e-04\n",
            "Epoch 114/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.9749 - pred_loss: 0.2904 - tf.where_10_loss: 0.0137 - pred_sparse_categorical_accuracy: 0.8736 - val_loss: 1.2613 - val_pred_loss: 1.2613 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6697 - lr: 5.0000e-04\n",
            "Epoch 115/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.9135 - pred_loss: 0.2862 - tf.where_10_loss: 0.0125 - pred_sparse_categorical_accuracy: 0.8761 - val_loss: 0.5997 - val_pred_loss: 0.5997 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7144 - lr: 5.0000e-04\n",
            "Epoch 116/500\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 0.9456 - pred_loss: 0.2904 - tf.where_10_loss: 0.0131 - pred_sparse_categorical_accuracy: 0.8773 - val_loss: 0.4851 - val_pred_loss: 0.4851 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7508 - lr: 5.0000e-04\n",
            "Epoch 117/500\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 0.9300 - pred_loss: 0.2822 - tf.where_10_loss: 0.0130 - pred_sparse_categorical_accuracy: 0.8842 - val_loss: 0.7591 - val_pred_loss: 0.7591 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7235 - lr: 5.0000e-04\n",
            "Epoch 118/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.9422 - pred_loss: 0.2782 - tf.where_10_loss: 0.0133 - pred_sparse_categorical_accuracy: 0.8764 - val_loss: 1.2856 - val_pred_loss: 1.2856 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6621 - lr: 5.0000e-04\n",
            "Epoch 119/500\n",
            "113/113 [==============================] - 2s 19ms/step - loss: 0.9315 - pred_loss: 0.2822 - tf.where_10_loss: 0.0130 - pred_sparse_categorical_accuracy: 0.8773 - val_loss: 1.2748 - val_pred_loss: 1.2748 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6644 - lr: 5.0000e-04\n",
            "Epoch 120/500\n",
            "113/113 [==============================] - 2s 19ms/step - loss: 0.9314 - pred_loss: 0.2891 - tf.where_10_loss: 0.0128 - pred_sparse_categorical_accuracy: 0.8736 - val_loss: 0.6737 - val_pred_loss: 0.6737 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7121 - lr: 5.0000e-04\n",
            "Epoch 121/500\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 0.8712 - pred_loss: 0.2759 - tf.where_10_loss: 0.0119 - pred_sparse_categorical_accuracy: 0.8828 - val_loss: 0.7042 - val_pred_loss: 0.7042 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7023 - lr: 5.0000e-04\n",
            "Epoch 122/500\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 0.9452 - pred_loss: 0.2949 - tf.where_10_loss: 0.0130 - pred_sparse_categorical_accuracy: 0.8673 - val_loss: 0.7594 - val_pred_loss: 0.7594 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6977 - lr: 5.0000e-04\n",
            "Epoch 123/500\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 0.8753 - pred_loss: 0.2839 - tf.where_10_loss: 0.0118 - pred_sparse_categorical_accuracy: 0.8792 - val_loss: 0.5541 - val_pred_loss: 0.5541 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7379 - lr: 5.0000e-04\n",
            "Epoch 124/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.8945 - pred_loss: 0.2879 - tf.where_10_loss: 0.0121 - pred_sparse_categorical_accuracy: 0.8734 - val_loss: 0.3432 - val_pred_loss: 0.3432 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8250 - lr: 5.0000e-04\n",
            "Epoch 125/500\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 0.8631 - pred_loss: 0.2776 - tf.where_10_loss: 0.0117 - pred_sparse_categorical_accuracy: 0.8820 - val_loss: 0.7421 - val_pred_loss: 0.7421 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6992 - lr: 5.0000e-04\n",
            "Epoch 126/500\n",
            "113/113 [==============================] - 2s 19ms/step - loss: 0.8969 - pred_loss: 0.2785 - tf.where_10_loss: 0.0124 - pred_sparse_categorical_accuracy: 0.8792 - val_loss: 0.3317 - val_pred_loss: 0.3317 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8424 - lr: 5.0000e-04\n",
            "Epoch 127/500\n",
            "113/113 [==============================] - 2s 20ms/step - loss: 0.8803 - pred_loss: 0.2774 - tf.where_10_loss: 0.0121 - pred_sparse_categorical_accuracy: 0.8750 - val_loss: 1.2385 - val_pred_loss: 1.2385 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6750 - lr: 5.0000e-04\n",
            "Epoch 128/500\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 0.8893 - pred_loss: 0.2713 - tf.where_10_loss: 0.0124 - pred_sparse_categorical_accuracy: 0.8898 - val_loss: 1.0177 - val_pred_loss: 1.0177 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6803 - lr: 5.0000e-04\n",
            "Epoch 129/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.8044 - pred_loss: 0.2747 - tf.where_10_loss: 0.0106 - pred_sparse_categorical_accuracy: 0.8834 - val_loss: 0.3158 - val_pred_loss: 0.3158 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8492 - lr: 2.5000e-04\n",
            "Epoch 130/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.7749 - pred_loss: 0.2740 - tf.where_10_loss: 0.0100 - pred_sparse_categorical_accuracy: 0.8842 - val_loss: 0.3803 - val_pred_loss: 0.3803 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8091 - lr: 2.5000e-04\n",
            "Epoch 131/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.8226 - pred_loss: 0.2772 - tf.where_10_loss: 0.0109 - pred_sparse_categorical_accuracy: 0.8814 - val_loss: 0.2735 - val_pred_loss: 0.2735 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8803 - lr: 2.5000e-04\n",
            "Epoch 132/500\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 0.7834 - pred_loss: 0.2615 - tf.where_10_loss: 0.0104 - pred_sparse_categorical_accuracy: 0.8900 - val_loss: 0.4583 - val_pred_loss: 0.4583 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7773 - lr: 2.5000e-04\n",
            "Epoch 133/500\n",
            "113/113 [==============================] - 2s 19ms/step - loss: 0.7855 - pred_loss: 0.2667 - tf.where_10_loss: 0.0104 - pred_sparse_categorical_accuracy: 0.8875 - val_loss: 0.3423 - val_pred_loss: 0.3423 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8356 - lr: 2.5000e-04\n",
            "Epoch 134/500\n",
            "113/113 [==============================] - 2s 20ms/step - loss: 0.7795 - pred_loss: 0.2694 - tf.where_10_loss: 0.0102 - pred_sparse_categorical_accuracy: 0.8875 - val_loss: 0.3883 - val_pred_loss: 0.3883 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8030 - lr: 2.5000e-04\n",
            "Epoch 135/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.7841 - pred_loss: 0.2725 - tf.where_10_loss: 0.0102 - pred_sparse_categorical_accuracy: 0.8864 - val_loss: 0.2839 - val_pred_loss: 0.2839 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8697 - lr: 2.5000e-04\n",
            "Epoch 136/500\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 0.7720 - pred_loss: 0.2665 - tf.where_10_loss: 0.0101 - pred_sparse_categorical_accuracy: 0.8848 - val_loss: 0.4170 - val_pred_loss: 0.4170 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7939 - lr: 2.5000e-04\n",
            "Epoch 137/500\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 0.7608 - pred_loss: 0.2684 - tf.where_10_loss: 0.0098 - pred_sparse_categorical_accuracy: 0.8873 - val_loss: 0.4267 - val_pred_loss: 0.4267 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7788 - lr: 2.5000e-04\n",
            "Epoch 138/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.7622 - pred_loss: 0.2722 - tf.where_10_loss: 0.0098 - pred_sparse_categorical_accuracy: 0.8839 - val_loss: 0.3086 - val_pred_loss: 0.3086 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8492 - lr: 2.5000e-04\n",
            "Epoch 139/500\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 0.7669 - pred_loss: 0.2657 - tf.where_10_loss: 0.0100 - pred_sparse_categorical_accuracy: 0.8875 - val_loss: 0.8016 - val_pred_loss: 0.8016 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6924 - lr: 2.5000e-04\n",
            "Epoch 140/500\n",
            "113/113 [==============================] - 2s 19ms/step - loss: 0.8086 - pred_loss: 0.2669 - tf.where_10_loss: 0.0108 - pred_sparse_categorical_accuracy: 0.8881 - val_loss: 0.3802 - val_pred_loss: 0.3802 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8212 - lr: 2.5000e-04\n",
            "Epoch 141/500\n",
            "113/113 [==============================] - 2s 21ms/step - loss: 0.7475 - pred_loss: 0.2675 - tf.where_10_loss: 0.0096 - pred_sparse_categorical_accuracy: 0.8856 - val_loss: 0.7453 - val_pred_loss: 0.7453 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7030 - lr: 2.5000e-04\n",
            "Epoch 142/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.7634 - pred_loss: 0.2563 - tf.where_10_loss: 0.0101 - pred_sparse_categorical_accuracy: 0.8945 - val_loss: 0.6234 - val_pred_loss: 0.6234 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7258 - lr: 2.5000e-04\n",
            "Epoch 143/500\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 0.7614 - pred_loss: 0.2667 - tf.where_10_loss: 0.0099 - pred_sparse_categorical_accuracy: 0.8867 - val_loss: 0.6383 - val_pred_loss: 0.6383 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7136 - lr: 2.5000e-04\n",
            "Epoch 144/500\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 0.7498 - pred_loss: 0.2609 - tf.where_10_loss: 0.0098 - pred_sparse_categorical_accuracy: 0.8900 - val_loss: 0.9424 - val_pred_loss: 0.9424 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7000 - lr: 2.5000e-04\n",
            "Epoch 145/500\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 0.7628 - pred_loss: 0.2692 - tf.where_10_loss: 0.0099 - pred_sparse_categorical_accuracy: 0.8867 - val_loss: 0.3399 - val_pred_loss: 0.3399 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8348 - lr: 2.5000e-04\n",
            "Epoch 146/500\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 0.7449 - pred_loss: 0.2663 - tf.where_10_loss: 0.0096 - pred_sparse_categorical_accuracy: 0.8814 - val_loss: 0.3075 - val_pred_loss: 0.3075 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8485 - lr: 2.5000e-04\n",
            "Epoch 147/500\n",
            "113/113 [==============================] - 2s 21ms/step - loss: 0.7536 - pred_loss: 0.2548 - tf.where_10_loss: 0.0100 - pred_sparse_categorical_accuracy: 0.8964 - val_loss: 0.4445 - val_pred_loss: 0.4445 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7720 - lr: 2.5000e-04\n",
            "Epoch 148/500\n",
            "113/113 [==============================] - 2s 19ms/step - loss: 0.7542 - pred_loss: 0.2614 - tf.where_10_loss: 0.0099 - pred_sparse_categorical_accuracy: 0.8917 - val_loss: 0.3036 - val_pred_loss: 0.3036 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8606 - lr: 2.5000e-04\n",
            "Epoch 149/500\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 0.7489 - pred_loss: 0.2652 - tf.where_10_loss: 0.0097 - pred_sparse_categorical_accuracy: 0.8859 - val_loss: 0.3583 - val_pred_loss: 0.3583 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8235 - lr: 2.5000e-04\n",
            "Epoch 150/500\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 0.7162 - pred_loss: 0.2588 - tf.where_10_loss: 0.0091 - pred_sparse_categorical_accuracy: 0.8953 - val_loss: 0.5730 - val_pred_loss: 0.5730 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7364 - lr: 2.5000e-04\n",
            "Epoch 151/500\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 0.7754 - pred_loss: 0.2671 - tf.where_10_loss: 0.0102 - pred_sparse_categorical_accuracy: 0.8861 - val_loss: 0.5303 - val_pred_loss: 0.5303 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7455 - lr: 2.5000e-04\n",
            "Epoch 152/500\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 0.7228 - pred_loss: 0.2613 - tf.where_10_loss: 0.0092 - pred_sparse_categorical_accuracy: 0.8945 - val_loss: 0.5124 - val_pred_loss: 0.5124 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7530 - lr: 1.2500e-04\n",
            "Epoch 153/500\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 0.7182 - pred_loss: 0.2706 - tf.where_10_loss: 0.0090 - pred_sparse_categorical_accuracy: 0.8861 - val_loss: 0.4441 - val_pred_loss: 0.4441 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7735 - lr: 1.2500e-04\n",
            "Epoch 154/500\n",
            "113/113 [==============================] - 2s 20ms/step - loss: 0.7007 - pred_loss: 0.2606 - tf.where_10_loss: 0.0088 - pred_sparse_categorical_accuracy: 0.8892 - val_loss: 0.8039 - val_pred_loss: 0.8039 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6886 - lr: 1.2500e-04\n",
            "Epoch 155/500\n",
            "113/113 [==============================] - 2s 20ms/step - loss: 0.6938 - pred_loss: 0.2583 - tf.where_10_loss: 0.0087 - pred_sparse_categorical_accuracy: 0.8842 - val_loss: 0.3430 - val_pred_loss: 0.3430 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8333 - lr: 1.2500e-04\n",
            "Epoch 156/500\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 0.7257 - pred_loss: 0.2622 - tf.where_10_loss: 0.0093 - pred_sparse_categorical_accuracy: 0.8884 - val_loss: 0.4371 - val_pred_loss: 0.4371 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7886 - lr: 1.2500e-04\n",
            "Epoch 157/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.6895 - pred_loss: 0.2583 - tf.where_10_loss: 0.0086 - pred_sparse_categorical_accuracy: 0.8906 - val_loss: 0.2902 - val_pred_loss: 0.2902 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8697 - lr: 1.2500e-04\n",
            "Epoch 158/500\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 0.7163 - pred_loss: 0.2585 - tf.where_10_loss: 0.0092 - pred_sparse_categorical_accuracy: 0.8895 - val_loss: 0.2717 - val_pred_loss: 0.2717 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8765 - lr: 1.2500e-04\n",
            "Epoch 159/500\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 0.6867 - pred_loss: 0.2562 - tf.where_10_loss: 0.0086 - pred_sparse_categorical_accuracy: 0.8939 - val_loss: 0.5631 - val_pred_loss: 0.5631 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7326 - lr: 1.2500e-04\n",
            "Epoch 160/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.7157 - pred_loss: 0.2625 - tf.where_10_loss: 0.0091 - pred_sparse_categorical_accuracy: 0.8853 - val_loss: 0.3721 - val_pred_loss: 0.3721 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8167 - lr: 1.2500e-04\n",
            "Epoch 161/500\n",
            "113/113 [==============================] - 2s 21ms/step - loss: 0.6881 - pred_loss: 0.2506 - tf.where_10_loss: 0.0087 - pred_sparse_categorical_accuracy: 0.8948 - val_loss: 0.4058 - val_pred_loss: 0.4058 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7962 - lr: 1.2500e-04\n",
            "Epoch 162/500\n",
            "113/113 [==============================] - 2s 20ms/step - loss: 0.6956 - pred_loss: 0.2552 - tf.where_10_loss: 0.0088 - pred_sparse_categorical_accuracy: 0.8931 - val_loss: 0.3002 - val_pred_loss: 0.3002 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8667 - lr: 1.2500e-04\n",
            "Epoch 163/500\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 0.6844 - pred_loss: 0.2487 - tf.where_10_loss: 0.0087 - pred_sparse_categorical_accuracy: 0.9014 - val_loss: 0.4498 - val_pred_loss: 0.4498 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7833 - lr: 1.2500e-04\n",
            "Epoch 164/500\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 0.6848 - pred_loss: 0.2551 - tf.where_10_loss: 0.0086 - pred_sparse_categorical_accuracy: 0.8889 - val_loss: 0.3665 - val_pred_loss: 0.3665 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8205 - lr: 1.2500e-04\n",
            "Epoch 165/500\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 0.7058 - pred_loss: 0.2586 - tf.where_10_loss: 0.0089 - pred_sparse_categorical_accuracy: 0.8923 - val_loss: 0.3341 - val_pred_loss: 0.3341 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8432 - lr: 1.2500e-04\n",
            "Epoch 166/500\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 0.6978 - pred_loss: 0.2580 - tf.where_10_loss: 0.0088 - pred_sparse_categorical_accuracy: 0.8900 - val_loss: 0.5049 - val_pred_loss: 0.5049 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7553 - lr: 1.2500e-04\n",
            "Epoch 167/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.6673 - pred_loss: 0.2467 - tf.where_10_loss: 0.0084 - pred_sparse_categorical_accuracy: 0.8998 - val_loss: 0.3915 - val_pred_loss: 0.3915 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8023 - lr: 1.2500e-04\n",
            "Epoch 168/500\n",
            "113/113 [==============================] - 2s 19ms/step - loss: 0.6984 - pred_loss: 0.2529 - tf.where_10_loss: 0.0089 - pred_sparse_categorical_accuracy: 0.8936 - val_loss: 0.3921 - val_pred_loss: 0.3921 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8045 - lr: 1.2500e-04\n",
            "Epoch 169/500\n",
            "113/113 [==============================] - 2s 20ms/step - loss: 0.6749 - pred_loss: 0.2510 - tf.where_10_loss: 0.0085 - pred_sparse_categorical_accuracy: 0.9009 - val_loss: 0.3806 - val_pred_loss: 0.3806 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8083 - lr: 1.2500e-04\n",
            "Epoch 170/500\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 0.6654 - pred_loss: 0.2554 - tf.where_10_loss: 0.0082 - pred_sparse_categorical_accuracy: 0.8889 - val_loss: 0.3402 - val_pred_loss: 0.3402 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8341 - lr: 1.2500e-04\n",
            "Epoch 171/500\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 0.6907 - pred_loss: 0.2548 - tf.where_10_loss: 0.0087 - pred_sparse_categorical_accuracy: 0.8939 - val_loss: 0.2761 - val_pred_loss: 0.2761 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8773 - lr: 1.2500e-04\n",
            "Epoch 172/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.6947 - pred_loss: 0.2569 - tf.where_10_loss: 0.0088 - pred_sparse_categorical_accuracy: 0.8950 - val_loss: 0.3456 - val_pred_loss: 0.3456 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8364 - lr: 1.2500e-04\n",
            "Epoch 173/500\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 0.6809 - pred_loss: 0.2553 - tf.where_10_loss: 0.0085 - pred_sparse_categorical_accuracy: 0.8886 - val_loss: 0.3241 - val_pred_loss: 0.3241 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8477 - lr: 1.2500e-04\n",
            "Epoch 174/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.6997 - pred_loss: 0.2537 - tf.where_10_loss: 0.0089 - pred_sparse_categorical_accuracy: 0.8970 - val_loss: 0.2577 - val_pred_loss: 0.2577 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8932 - lr: 1.2500e-04\n",
            "Epoch 175/500\n",
            "113/113 [==============================] - 2s 20ms/step - loss: 0.6741 - pred_loss: 0.2444 - tf.where_10_loss: 0.0086 - pred_sparse_categorical_accuracy: 0.9022 - val_loss: 0.2791 - val_pred_loss: 0.2791 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8780 - lr: 1.2500e-04\n",
            "Epoch 176/500\n",
            "113/113 [==============================] - 2s 19ms/step - loss: 0.6831 - pred_loss: 0.2561 - tf.where_10_loss: 0.0085 - pred_sparse_categorical_accuracy: 0.8925 - val_loss: 0.2887 - val_pred_loss: 0.2887 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8682 - lr: 1.2500e-04\n",
            "Epoch 177/500\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 0.6703 - pred_loss: 0.2453 - tf.where_10_loss: 0.0085 - pred_sparse_categorical_accuracy: 0.8989 - val_loss: 0.5371 - val_pred_loss: 0.5371 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7523 - lr: 1.2500e-04\n",
            "Epoch 178/500\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 0.6768 - pred_loss: 0.2573 - tf.where_10_loss: 0.0084 - pred_sparse_categorical_accuracy: 0.8939 - val_loss: 0.3506 - val_pred_loss: 0.3506 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8341 - lr: 1.2500e-04\n",
            "Epoch 179/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.6579 - pred_loss: 0.2511 - tf.where_10_loss: 0.0081 - pred_sparse_categorical_accuracy: 0.8923 - val_loss: 0.3188 - val_pred_loss: 0.3188 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8568 - lr: 1.2500e-04\n",
            "Epoch 180/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.6734 - pred_loss: 0.2539 - tf.where_10_loss: 0.0084 - pred_sparse_categorical_accuracy: 0.8989 - val_loss: 0.2705 - val_pred_loss: 0.2705 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8765 - lr: 1.2500e-04\n",
            "Epoch 181/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.6859 - pred_loss: 0.2472 - tf.where_10_loss: 0.0088 - pred_sparse_categorical_accuracy: 0.8961 - val_loss: 0.4362 - val_pred_loss: 0.4362 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7818 - lr: 1.2500e-04\n",
            "Epoch 182/500\n",
            "113/113 [==============================] - 2s 20ms/step - loss: 0.6671 - pred_loss: 0.2528 - tf.where_10_loss: 0.0083 - pred_sparse_categorical_accuracy: 0.8950 - val_loss: 0.4995 - val_pred_loss: 0.4995 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7576 - lr: 1.2500e-04\n",
            "Epoch 183/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.6817 - pred_loss: 0.2501 - tf.where_10_loss: 0.0086 - pred_sparse_categorical_accuracy: 0.8920 - val_loss: 0.2818 - val_pred_loss: 0.2818 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8689 - lr: 1.2500e-04\n",
            "Epoch 184/500\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 0.6685 - pred_loss: 0.2533 - tf.where_10_loss: 0.0083 - pred_sparse_categorical_accuracy: 0.8898 - val_loss: 0.3997 - val_pred_loss: 0.3997 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7985 - lr: 1.2500e-04\n",
            "Epoch 185/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.6934 - pred_loss: 0.2638 - tf.where_10_loss: 0.0086 - pred_sparse_categorical_accuracy: 0.8806 - val_loss: 0.3737 - val_pred_loss: 0.3737 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8212 - lr: 1.2500e-04\n",
            "Epoch 186/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.6726 - pred_loss: 0.2522 - tf.where_10_loss: 0.0084 - pred_sparse_categorical_accuracy: 0.8936 - val_loss: 0.2543 - val_pred_loss: 0.2543 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8848 - lr: 1.2500e-04\n",
            "Epoch 187/500\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 0.6940 - pred_loss: 0.2588 - tf.where_10_loss: 0.0087 - pred_sparse_categorical_accuracy: 0.8845 - val_loss: 0.4005 - val_pred_loss: 0.4005 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8038 - lr: 1.2500e-04\n",
            "Epoch 188/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.6884 - pred_loss: 0.2557 - tf.where_10_loss: 0.0087 - pred_sparse_categorical_accuracy: 0.8920 - val_loss: 0.3102 - val_pred_loss: 0.3102 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8561 - lr: 1.2500e-04\n",
            "Epoch 189/500\n",
            "113/113 [==============================] - 2s 21ms/step - loss: 0.6734 - pred_loss: 0.2590 - tf.where_10_loss: 0.0083 - pred_sparse_categorical_accuracy: 0.8911 - val_loss: 0.2869 - val_pred_loss: 0.2869 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8735 - lr: 1.2500e-04\n",
            "Epoch 190/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.6668 - pred_loss: 0.2509 - tf.where_10_loss: 0.0083 - pred_sparse_categorical_accuracy: 0.8889 - val_loss: 0.5722 - val_pred_loss: 0.5722 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7394 - lr: 1.2500e-04\n",
            "Epoch 191/500\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 0.6756 - pred_loss: 0.2480 - tf.where_10_loss: 0.0086 - pred_sparse_categorical_accuracy: 0.8989 - val_loss: 0.6864 - val_pred_loss: 0.6864 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7174 - lr: 1.2500e-04\n",
            "Epoch 192/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.6656 - pred_loss: 0.2484 - tf.where_10_loss: 0.0083 - pred_sparse_categorical_accuracy: 0.8931 - val_loss: 0.4835 - val_pred_loss: 0.4835 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7689 - lr: 1.2500e-04\n",
            "Epoch 193/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.6712 - pred_loss: 0.2530 - tf.where_10_loss: 0.0084 - pred_sparse_categorical_accuracy: 0.8934 - val_loss: 0.3644 - val_pred_loss: 0.3644 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8280 - lr: 1.2500e-04\n",
            "Epoch 194/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.6726 - pred_loss: 0.2629 - tf.where_10_loss: 0.0082 - pred_sparse_categorical_accuracy: 0.8850 - val_loss: 0.4631 - val_pred_loss: 0.4631 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7742 - lr: 1.2500e-04\n",
            "Epoch 195/500\n",
            "113/113 [==============================] - 2s 21ms/step - loss: 0.6539 - pred_loss: 0.2478 - tf.where_10_loss: 0.0081 - pred_sparse_categorical_accuracy: 0.8942 - val_loss: 0.3806 - val_pred_loss: 0.3806 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8159 - lr: 1.2500e-04\n",
            "Epoch 196/500\n",
            "113/113 [==============================] - 2s 21ms/step - loss: 0.6522 - pred_loss: 0.2507 - tf.where_10_loss: 0.0080 - pred_sparse_categorical_accuracy: 0.8920 - val_loss: 0.5740 - val_pred_loss: 0.5740 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7364 - lr: 1.2500e-04\n",
            "Epoch 197/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.6580 - pred_loss: 0.2485 - tf.where_10_loss: 0.0082 - pred_sparse_categorical_accuracy: 0.8942 - val_loss: 0.4285 - val_pred_loss: 0.4285 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7879 - lr: 1.2500e-04\n",
            "Epoch 198/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.6580 - pred_loss: 0.2470 - tf.where_10_loss: 0.0082 - pred_sparse_categorical_accuracy: 0.8984 - val_loss: 0.2665 - val_pred_loss: 0.2665 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8879 - lr: 1.2500e-04\n",
            "Epoch 199/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.6632 - pred_loss: 0.2545 - tf.where_10_loss: 0.0082 - pred_sparse_categorical_accuracy: 0.8934 - val_loss: 0.3565 - val_pred_loss: 0.3565 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8311 - lr: 1.2500e-04\n",
            "Epoch 200/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.6752 - pred_loss: 0.2493 - tf.where_10_loss: 0.0085 - pred_sparse_categorical_accuracy: 0.8906 - val_loss: 0.4354 - val_pred_loss: 0.4354 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7833 - lr: 1.2500e-04\n",
            "Epoch 201/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.6820 - pred_loss: 0.2513 - tf.where_10_loss: 0.0086 - pred_sparse_categorical_accuracy: 0.8950 - val_loss: 0.5455 - val_pred_loss: 0.5455 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7424 - lr: 1.2500e-04\n",
            "Epoch 202/500\n",
            "113/113 [==============================] - 2s 21ms/step - loss: 0.6757 - pred_loss: 0.2563 - tf.where_10_loss: 0.0084 - pred_sparse_categorical_accuracy: 0.8914 - val_loss: 0.3479 - val_pred_loss: 0.3479 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8341 - lr: 1.2500e-04\n",
            "Epoch 203/500\n",
            "113/113 [==============================] - 2s 20ms/step - loss: 0.6703 - pred_loss: 0.2539 - tf.where_10_loss: 0.0083 - pred_sparse_categorical_accuracy: 0.8878 - val_loss: 0.5089 - val_pred_loss: 0.5089 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7553 - lr: 1.2500e-04\n",
            "Epoch 204/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.6530 - pred_loss: 0.2572 - tf.where_10_loss: 0.0079 - pred_sparse_categorical_accuracy: 0.8873 - val_loss: 0.2812 - val_pred_loss: 0.2812 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8727 - lr: 1.2500e-04\n",
            "Epoch 205/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.6655 - pred_loss: 0.2587 - tf.where_10_loss: 0.0081 - pred_sparse_categorical_accuracy: 0.8881 - val_loss: 0.4719 - val_pred_loss: 0.4719 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7705 - lr: 1.2500e-04\n",
            "Epoch 206/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.6484 - pred_loss: 0.2486 - tf.where_10_loss: 0.0080 - pred_sparse_categorical_accuracy: 0.8986 - val_loss: 0.3049 - val_pred_loss: 0.3049 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8644 - lr: 1.2500e-04\n",
            "Epoch 207/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.6317 - pred_loss: 0.2454 - tf.where_10_loss: 0.0077 - pred_sparse_categorical_accuracy: 0.8948 - val_loss: 0.4058 - val_pred_loss: 0.4058 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7962 - lr: 1.0000e-04\n",
            "Epoch 208/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.6498 - pred_loss: 0.2488 - tf.where_10_loss: 0.0080 - pred_sparse_categorical_accuracy: 0.8964 - val_loss: 0.4479 - val_pred_loss: 0.4479 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7811 - lr: 1.0000e-04\n",
            "Epoch 209/500\n",
            "113/113 [==============================] - 2s 21ms/step - loss: 0.6410 - pred_loss: 0.2442 - tf.where_10_loss: 0.0079 - pred_sparse_categorical_accuracy: 0.9011 - val_loss: 0.3431 - val_pred_loss: 0.3431 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8356 - lr: 1.0000e-04\n",
            "Epoch 210/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.6347 - pred_loss: 0.2430 - tf.where_10_loss: 0.0078 - pred_sparse_categorical_accuracy: 0.9000 - val_loss: 0.4039 - val_pred_loss: 0.4039 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8098 - lr: 1.0000e-04\n",
            "Epoch 211/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.6436 - pred_loss: 0.2623 - tf.where_10_loss: 0.0076 - pred_sparse_categorical_accuracy: 0.8892 - val_loss: 0.6125 - val_pred_loss: 0.6125 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7250 - lr: 1.0000e-04\n",
            "Epoch 212/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.6591 - pred_loss: 0.2438 - tf.where_10_loss: 0.0083 - pred_sparse_categorical_accuracy: 0.8970 - val_loss: 0.2534 - val_pred_loss: 0.2534 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8917 - lr: 1.0000e-04\n",
            "Epoch 213/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.6336 - pred_loss: 0.2438 - tf.where_10_loss: 0.0078 - pred_sparse_categorical_accuracy: 0.8950 - val_loss: 0.4509 - val_pred_loss: 0.4509 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7780 - lr: 1.0000e-04\n",
            "Epoch 214/500\n",
            "113/113 [==============================] - 2s 19ms/step - loss: 0.6345 - pred_loss: 0.2458 - tf.where_10_loss: 0.0078 - pred_sparse_categorical_accuracy: 0.9017 - val_loss: 0.4407 - val_pred_loss: 0.4407 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7947 - lr: 1.0000e-04\n",
            "Epoch 215/500\n",
            "113/113 [==============================] - 2s 20ms/step - loss: 0.6789 - pred_loss: 0.2523 - tf.where_10_loss: 0.0085 - pred_sparse_categorical_accuracy: 0.8945 - val_loss: 0.5172 - val_pred_loss: 0.5172 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7598 - lr: 1.0000e-04\n",
            "Epoch 216/500\n",
            "113/113 [==============================] - 3s 23ms/step - loss: 0.6390 - pred_loss: 0.2479 - tf.where_10_loss: 0.0078 - pred_sparse_categorical_accuracy: 0.8964 - val_loss: 0.3517 - val_pred_loss: 0.3517 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8341 - lr: 1.0000e-04\n",
            "Epoch 217/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.6388 - pred_loss: 0.2535 - tf.where_10_loss: 0.0077 - pred_sparse_categorical_accuracy: 0.8945 - val_loss: 0.4786 - val_pred_loss: 0.4786 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7697 - lr: 1.0000e-04\n",
            "Epoch 218/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.6613 - pred_loss: 0.2614 - tf.where_10_loss: 0.0080 - pred_sparse_categorical_accuracy: 0.8936 - val_loss: 0.3479 - val_pred_loss: 0.3479 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8364 - lr: 1.0000e-04\n",
            "Epoch 219/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.6187 - pred_loss: 0.2416 - tf.where_10_loss: 0.0075 - pred_sparse_categorical_accuracy: 0.8989 - val_loss: 0.3354 - val_pred_loss: 0.3354 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8432 - lr: 1.0000e-04\n",
            "Epoch 220/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.6281 - pred_loss: 0.2451 - tf.where_10_loss: 0.0077 - pred_sparse_categorical_accuracy: 0.8998 - val_loss: 0.3224 - val_pred_loss: 0.3224 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8530 - lr: 1.0000e-04\n",
            "Epoch 221/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.6303 - pred_loss: 0.2467 - tf.where_10_loss: 0.0077 - pred_sparse_categorical_accuracy: 0.8973 - val_loss: 0.9365 - val_pred_loss: 0.9365 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6826 - lr: 1.0000e-04\n",
            "Epoch 222/500\n",
            "113/113 [==============================] - 2s 22ms/step - loss: 0.6256 - pred_loss: 0.2374 - tf.where_10_loss: 0.0078 - pred_sparse_categorical_accuracy: 0.9020 - val_loss: 0.4451 - val_pred_loss: 0.4451 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7841 - lr: 1.0000e-04\n",
            "Epoch 223/500\n",
            "113/113 [==============================] - 2s 20ms/step - loss: 0.6232 - pred_loss: 0.2461 - tf.where_10_loss: 0.0075 - pred_sparse_categorical_accuracy: 0.8973 - val_loss: 0.2957 - val_pred_loss: 0.2957 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8712 - lr: 1.0000e-04\n",
            "Epoch 224/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.6379 - pred_loss: 0.2505 - tf.where_10_loss: 0.0077 - pred_sparse_categorical_accuracy: 0.8939 - val_loss: 0.2979 - val_pred_loss: 0.2979 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8689 - lr: 1.0000e-04\n",
            "Epoch 225/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.6454 - pred_loss: 0.2478 - tf.where_10_loss: 0.0080 - pred_sparse_categorical_accuracy: 0.8931 - val_loss: 0.4335 - val_pred_loss: 0.4335 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7826 - lr: 1.0000e-04\n",
            "Epoch 226/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.6257 - pred_loss: 0.2435 - tf.where_10_loss: 0.0076 - pred_sparse_categorical_accuracy: 0.9022 - val_loss: 0.6496 - val_pred_loss: 0.6496 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7235 - lr: 1.0000e-04\n",
            "Epoch 227/500\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 0.6256 - pred_loss: 0.2378 - tf.where_10_loss: 0.0078 - pred_sparse_categorical_accuracy: 0.9017 - val_loss: 0.3834 - val_pred_loss: 0.3834 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8159 - lr: 1.0000e-04\n",
            "Epoch 228/500\n",
            "113/113 [==============================] - 2s 19ms/step - loss: 0.6256 - pred_loss: 0.2458 - tf.where_10_loss: 0.0076 - pred_sparse_categorical_accuracy: 0.8956 - val_loss: 0.4548 - val_pred_loss: 0.4548 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7765 - lr: 1.0000e-04\n",
            "Epoch 229/500\n",
            "113/113 [==============================] - 2s 21ms/step - loss: 0.6417 - pred_loss: 0.2547 - tf.where_10_loss: 0.0077 - pred_sparse_categorical_accuracy: 0.8928 - val_loss: 0.2887 - val_pred_loss: 0.2887 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8742 - lr: 1.0000e-04\n",
            "Epoch 230/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.6285 - pred_loss: 0.2469 - tf.where_10_loss: 0.0076 - pred_sparse_categorical_accuracy: 0.8970 - val_loss: 0.4525 - val_pred_loss: 0.4525 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7864 - lr: 1.0000e-04\n",
            "Epoch 231/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.6406 - pred_loss: 0.2507 - tf.where_10_loss: 0.0078 - pred_sparse_categorical_accuracy: 0.8959 - val_loss: 0.3541 - val_pred_loss: 0.3541 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8326 - lr: 1.0000e-04\n",
            "Epoch 232/500\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 0.6345 - pred_loss: 0.2427 - tf.where_10_loss: 0.0078 - pred_sparse_categorical_accuracy: 0.8961 - val_loss: 0.3938 - val_pred_loss: 0.3938 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8023 - lr: 1.0000e-04\n",
            "Epoch 233/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.6420 - pred_loss: 0.2527 - tf.where_10_loss: 0.0078 - pred_sparse_categorical_accuracy: 0.8873 - val_loss: 0.6744 - val_pred_loss: 0.6744 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7129 - lr: 1.0000e-04\n",
            "Epoch 234/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.6110 - pred_loss: 0.2400 - tf.where_10_loss: 0.0074 - pred_sparse_categorical_accuracy: 0.9028 - val_loss: 0.3057 - val_pred_loss: 0.3057 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8659 - lr: 1.0000e-04\n",
            "Epoch 235/500\n",
            "113/113 [==============================] - 2s 19ms/step - loss: 0.6263 - pred_loss: 0.2488 - tf.where_10_loss: 0.0075 - pred_sparse_categorical_accuracy: 0.8931 - val_loss: 0.2580 - val_pred_loss: 0.2580 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8848 - lr: 1.0000e-04\n",
            "Epoch 236/500\n",
            "113/113 [==============================] - 2s 20ms/step - loss: 0.6445 - pred_loss: 0.2558 - tf.where_10_loss: 0.0078 - pred_sparse_categorical_accuracy: 0.8925 - val_loss: 0.3044 - val_pred_loss: 0.3044 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8621 - lr: 1.0000e-04\n",
            "Epoch 237/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.6284 - pred_loss: 0.2433 - tf.where_10_loss: 0.0077 - pred_sparse_categorical_accuracy: 0.9020 - val_loss: 0.5951 - val_pred_loss: 0.5951 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7348 - lr: 1.0000e-04\n",
            "Epoch 238/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.6375 - pred_loss: 0.2531 - tf.where_10_loss: 0.0077 - pred_sparse_categorical_accuracy: 0.8931 - val_loss: 0.5738 - val_pred_loss: 0.5738 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7386 - lr: 1.0000e-04\n",
            "Epoch 239/500\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 0.6149 - pred_loss: 0.2455 - tf.where_10_loss: 0.0074 - pred_sparse_categorical_accuracy: 0.8978 - val_loss: 0.2567 - val_pred_loss: 0.2567 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8962 - lr: 1.0000e-04\n",
            "Epoch 240/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.6288 - pred_loss: 0.2521 - tf.where_10_loss: 0.0075 - pred_sparse_categorical_accuracy: 0.8861 - val_loss: 0.5163 - val_pred_loss: 0.5163 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7644 - lr: 1.0000e-04\n",
            "Epoch 241/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.6587 - pred_loss: 0.2598 - tf.where_10_loss: 0.0080 - pred_sparse_categorical_accuracy: 0.8914 - val_loss: 0.3768 - val_pred_loss: 0.3768 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8197 - lr: 1.0000e-04\n",
            "Epoch 242/500\n",
            "113/113 [==============================] - 2s 19ms/step - loss: 0.6306 - pred_loss: 0.2448 - tf.where_10_loss: 0.0077 - pred_sparse_categorical_accuracy: 0.9006 - val_loss: 0.3923 - val_pred_loss: 0.3923 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8189 - lr: 1.0000e-04\n",
            "Epoch 243/500\n",
            "113/113 [==============================] - 2s 21ms/step - loss: 0.6352 - pred_loss: 0.2510 - tf.where_10_loss: 0.0077 - pred_sparse_categorical_accuracy: 0.8950 - val_loss: 0.2990 - val_pred_loss: 0.2990 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8682 - lr: 1.0000e-04\n",
            "Epoch 244/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.6327 - pred_loss: 0.2441 - tf.where_10_loss: 0.0078 - pred_sparse_categorical_accuracy: 0.9034 - val_loss: 0.3431 - val_pred_loss: 0.3431 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8432 - lr: 1.0000e-04\n",
            "Epoch 245/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.6139 - pred_loss: 0.2480 - tf.where_10_loss: 0.0073 - pred_sparse_categorical_accuracy: 0.8967 - val_loss: 0.3030 - val_pred_loss: 0.3030 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8636 - lr: 1.0000e-04\n",
            "Epoch 246/500\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 0.6236 - pred_loss: 0.2516 - tf.where_10_loss: 0.0074 - pred_sparse_categorical_accuracy: 0.8953 - val_loss: 0.3502 - val_pred_loss: 0.3502 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8371 - lr: 1.0000e-04\n",
            "Epoch 247/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.6214 - pred_loss: 0.2458 - tf.where_10_loss: 0.0075 - pred_sparse_categorical_accuracy: 0.8986 - val_loss: 0.6469 - val_pred_loss: 0.6469 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7197 - lr: 1.0000e-04\n",
            "Epoch 248/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.6174 - pred_loss: 0.2491 - tf.where_10_loss: 0.0074 - pred_sparse_categorical_accuracy: 0.8995 - val_loss: 0.3796 - val_pred_loss: 0.3796 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8235 - lr: 1.0000e-04\n",
            "Epoch 249/500\n",
            "113/113 [==============================] - 2s 20ms/step - loss: 0.6162 - pred_loss: 0.2483 - tf.where_10_loss: 0.0074 - pred_sparse_categorical_accuracy: 0.8956 - val_loss: 0.4071 - val_pred_loss: 0.4071 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8008 - lr: 1.0000e-04\n",
            "Epoch 250/500\n",
            "113/113 [==============================] - 2s 21ms/step - loss: 0.6264 - pred_loss: 0.2497 - tf.where_10_loss: 0.0075 - pred_sparse_categorical_accuracy: 0.8967 - val_loss: 0.4477 - val_pred_loss: 0.4477 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7886 - lr: 1.0000e-04\n",
            "Epoch 251/500\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 0.6239 - pred_loss: 0.2455 - tf.where_10_loss: 0.0076 - pred_sparse_categorical_accuracy: 0.9003 - val_loss: 0.3406 - val_pred_loss: 0.3406 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8379 - lr: 1.0000e-04\n",
            "Epoch 252/500\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 0.6351 - pred_loss: 0.2456 - tf.where_10_loss: 0.0078 - pred_sparse_categorical_accuracy: 0.8931 - val_loss: 0.2913 - val_pred_loss: 0.2913 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8727 - lr: 1.0000e-04\n",
            "Epoch 253/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.6232 - pred_loss: 0.2488 - tf.where_10_loss: 0.0075 - pred_sparse_categorical_accuracy: 0.8973 - val_loss: 0.2986 - val_pred_loss: 0.2986 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8682 - lr: 1.0000e-04\n",
            "Epoch 254/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.6267 - pred_loss: 0.2542 - tf.where_10_loss: 0.0074 - pred_sparse_categorical_accuracy: 0.8942 - val_loss: 0.3552 - val_pred_loss: 0.3552 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8295 - lr: 1.0000e-04\n",
            "Epoch 255/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.6232 - pred_loss: 0.2459 - tf.where_10_loss: 0.0075 - pred_sparse_categorical_accuracy: 0.8981 - val_loss: 0.3770 - val_pred_loss: 0.3770 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8189 - lr: 1.0000e-04\n",
            "Epoch 256/500\n",
            "113/113 [==============================] - 2s 19ms/step - loss: 0.6396 - pred_loss: 0.2561 - tf.where_10_loss: 0.0077 - pred_sparse_categorical_accuracy: 0.8948 - val_loss: 0.7147 - val_pred_loss: 0.7147 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7159 - lr: 1.0000e-04\n",
            "Epoch 257/500\n",
            "113/113 [==============================] - 2s 20ms/step - loss: 0.6116 - pred_loss: 0.2399 - tf.where_10_loss: 0.0074 - pred_sparse_categorical_accuracy: 0.8989 - val_loss: 0.3823 - val_pred_loss: 0.3823 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8144 - lr: 1.0000e-04\n",
            "Epoch 258/500\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 0.6140 - pred_loss: 0.2484 - tf.where_10_loss: 0.0073 - pred_sparse_categorical_accuracy: 0.8995 - val_loss: 0.3944 - val_pred_loss: 0.3944 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8136 - lr: 1.0000e-04\n",
            "Epoch 259/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.6023 - pred_loss: 0.2438 - tf.where_10_loss: 0.0072 - pred_sparse_categorical_accuracy: 0.8975 - val_loss: 0.7137 - val_pred_loss: 0.7137 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7114 - lr: 1.0000e-04\n",
            "Epoch 260/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.6164 - pred_loss: 0.2404 - tf.where_10_loss: 0.0075 - pred_sparse_categorical_accuracy: 0.8975 - val_loss: 0.3735 - val_pred_loss: 0.3735 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8197 - lr: 1.0000e-04\n",
            "Epoch 261/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.6231 - pred_loss: 0.2461 - tf.where_10_loss: 0.0075 - pred_sparse_categorical_accuracy: 0.8973 - val_loss: 0.3082 - val_pred_loss: 0.3082 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8644 - lr: 1.0000e-04\n",
            "Epoch 262/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.6060 - pred_loss: 0.2447 - tf.where_10_loss: 0.0072 - pred_sparse_categorical_accuracy: 0.8895 - val_loss: 0.2974 - val_pred_loss: 0.2974 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8674 - lr: 1.0000e-04\n",
            "Epoch 263/500\n",
            "113/113 [==============================] - 2s 21ms/step - loss: 0.6210 - pred_loss: 0.2470 - tf.where_10_loss: 0.0075 - pred_sparse_categorical_accuracy: 0.8998 - val_loss: 0.3621 - val_pred_loss: 0.3621 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8227 - lr: 1.0000e-04\n",
            "Epoch 264/500\n",
            "113/113 [==============================] - 2s 22ms/step - loss: 0.6127 - pred_loss: 0.2487 - tf.where_10_loss: 0.0073 - pred_sparse_categorical_accuracy: 0.8964 - val_loss: 0.3969 - val_pred_loss: 0.3969 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8136 - lr: 1.0000e-04\n",
            "Epoch 265/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.6154 - pred_loss: 0.2481 - tf.where_10_loss: 0.0073 - pred_sparse_categorical_accuracy: 0.8959 - val_loss: 0.2945 - val_pred_loss: 0.2945 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8697 - lr: 1.0000e-04\n",
            "Epoch 266/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.6086 - pred_loss: 0.2409 - tf.where_10_loss: 0.0074 - pred_sparse_categorical_accuracy: 0.9011 - val_loss: 0.3851 - val_pred_loss: 0.3851 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8182 - lr: 1.0000e-04\n",
            "Epoch 267/500\n",
            "113/113 [==============================] - 2s 19ms/step - loss: 0.6269 - pred_loss: 0.2488 - tf.where_10_loss: 0.0076 - pred_sparse_categorical_accuracy: 0.8970 - val_loss: 1.0020 - val_pred_loss: 1.0020 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6818 - lr: 1.0000e-04\n",
            "Epoch 268/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.6206 - pred_loss: 0.2408 - tf.where_10_loss: 0.0076 - pred_sparse_categorical_accuracy: 0.8975 - val_loss: 0.2618 - val_pred_loss: 0.2618 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8864 - lr: 1.0000e-04\n",
            "Epoch 269/500\n",
            "113/113 [==============================] - 2s 19ms/step - loss: 0.6093 - pred_loss: 0.2423 - tf.where_10_loss: 0.0073 - pred_sparse_categorical_accuracy: 0.8984 - val_loss: 0.4462 - val_pred_loss: 0.4462 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7871 - lr: 1.0000e-04\n",
            "Epoch 270/500\n",
            "113/113 [==============================] - 2s 21ms/step - loss: 0.6014 - pred_loss: 0.2435 - tf.where_10_loss: 0.0072 - pred_sparse_categorical_accuracy: 0.8939 - val_loss: 0.2583 - val_pred_loss: 0.2583 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8864 - lr: 1.0000e-04\n",
            "Epoch 271/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.6249 - pred_loss: 0.2515 - tf.where_10_loss: 0.0075 - pred_sparse_categorical_accuracy: 0.8931 - val_loss: 0.3764 - val_pred_loss: 0.3764 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8144 - lr: 1.0000e-04\n",
            "Epoch 272/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.5979 - pred_loss: 0.2391 - tf.where_10_loss: 0.0072 - pred_sparse_categorical_accuracy: 0.8995 - val_loss: 0.3860 - val_pred_loss: 0.3860 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8152 - lr: 1.0000e-04\n",
            "Epoch 273/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.6036 - pred_loss: 0.2394 - tf.where_10_loss: 0.0073 - pred_sparse_categorical_accuracy: 0.9006 - val_loss: 0.3505 - val_pred_loss: 0.3505 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8333 - lr: 1.0000e-04\n",
            "Epoch 274/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.6006 - pred_loss: 0.2407 - tf.where_10_loss: 0.0072 - pred_sparse_categorical_accuracy: 0.9039 - val_loss: 0.4424 - val_pred_loss: 0.4424 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7932 - lr: 1.0000e-04\n",
            "Epoch 275/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.6043 - pred_loss: 0.2406 - tf.where_10_loss: 0.0073 - pred_sparse_categorical_accuracy: 0.9020 - val_loss: 0.3095 - val_pred_loss: 0.3095 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8621 - lr: 1.0000e-04\n",
            "Epoch 276/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.6113 - pred_loss: 0.2392 - tf.where_10_loss: 0.0074 - pred_sparse_categorical_accuracy: 0.9031 - val_loss: 0.3341 - val_pred_loss: 0.3341 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8439 - lr: 1.0000e-04\n",
            "Epoch 277/500\n",
            "113/113 [==============================] - 2s 20ms/step - loss: 0.5985 - pred_loss: 0.2394 - tf.where_10_loss: 0.0072 - pred_sparse_categorical_accuracy: 0.9006 - val_loss: 0.3797 - val_pred_loss: 0.3797 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8189 - lr: 1.0000e-04\n",
            "Epoch 278/500\n",
            "113/113 [==============================] - 2s 20ms/step - loss: 0.6105 - pred_loss: 0.2447 - tf.where_10_loss: 0.0073 - pred_sparse_categorical_accuracy: 0.8998 - val_loss: 0.3331 - val_pred_loss: 0.3331 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8470 - lr: 1.0000e-04\n",
            "Epoch 279/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.6084 - pred_loss: 0.2424 - tf.where_10_loss: 0.0073 - pred_sparse_categorical_accuracy: 0.8989 - val_loss: 0.4377 - val_pred_loss: 0.4377 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7894 - lr: 1.0000e-04\n",
            "Epoch 280/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.6215 - pred_loss: 0.2497 - tf.where_10_loss: 0.0074 - pred_sparse_categorical_accuracy: 0.8984 - val_loss: 0.2599 - val_pred_loss: 0.2599 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8932 - lr: 1.0000e-04\n",
            "Epoch 281/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.6130 - pred_loss: 0.2371 - tf.where_10_loss: 0.0075 - pred_sparse_categorical_accuracy: 0.9036 - val_loss: 0.4465 - val_pred_loss: 0.4465 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7826 - lr: 1.0000e-04\n",
            "Epoch 282/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.6134 - pred_loss: 0.2429 - tf.where_10_loss: 0.0074 - pred_sparse_categorical_accuracy: 0.8989 - val_loss: 0.2524 - val_pred_loss: 0.2524 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8932 - lr: 1.0000e-04\n",
            "Epoch 283/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.6020 - pred_loss: 0.2426 - tf.where_10_loss: 0.0072 - pred_sparse_categorical_accuracy: 0.9014 - val_loss: 0.6982 - val_pred_loss: 0.6982 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7242 - lr: 1.0000e-04\n",
            "Epoch 284/500\n",
            "113/113 [==============================] - 2s 21ms/step - loss: 0.5997 - pred_loss: 0.2443 - tf.where_10_loss: 0.0071 - pred_sparse_categorical_accuracy: 0.8975 - val_loss: 0.2985 - val_pred_loss: 0.2985 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8659 - lr: 1.0000e-04\n",
            "Epoch 285/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.6012 - pred_loss: 0.2445 - tf.where_10_loss: 0.0071 - pred_sparse_categorical_accuracy: 0.8934 - val_loss: 0.4420 - val_pred_loss: 0.4420 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7856 - lr: 1.0000e-04\n",
            "Epoch 286/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.5957 - pred_loss: 0.2379 - tf.where_10_loss: 0.0072 - pred_sparse_categorical_accuracy: 0.9034 - val_loss: 0.3880 - val_pred_loss: 0.3880 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8235 - lr: 1.0000e-04\n",
            "Epoch 287/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.6168 - pred_loss: 0.2415 - tf.where_10_loss: 0.0075 - pred_sparse_categorical_accuracy: 0.8967 - val_loss: 0.2623 - val_pred_loss: 0.2623 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8864 - lr: 1.0000e-04\n",
            "Epoch 288/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.6041 - pred_loss: 0.2446 - tf.where_10_loss: 0.0072 - pred_sparse_categorical_accuracy: 0.8967 - val_loss: 0.2782 - val_pred_loss: 0.2782 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8720 - lr: 1.0000e-04\n",
            "Epoch 289/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.6036 - pred_loss: 0.2419 - tf.where_10_loss: 0.0072 - pred_sparse_categorical_accuracy: 0.8925 - val_loss: 0.3031 - val_pred_loss: 0.3031 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8689 - lr: 1.0000e-04\n",
            "Epoch 290/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.6113 - pred_loss: 0.2430 - tf.where_10_loss: 0.0074 - pred_sparse_categorical_accuracy: 0.8964 - val_loss: 0.3409 - val_pred_loss: 0.3409 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8432 - lr: 1.0000e-04\n",
            "Epoch 291/500\n",
            "113/113 [==============================] - 2s 21ms/step - loss: 0.5934 - pred_loss: 0.2383 - tf.where_10_loss: 0.0071 - pred_sparse_categorical_accuracy: 0.8978 - val_loss: 0.2863 - val_pred_loss: 0.2863 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8682 - lr: 1.0000e-04\n",
            "Epoch 292/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.5949 - pred_loss: 0.2391 - tf.where_10_loss: 0.0071 - pred_sparse_categorical_accuracy: 0.9003 - val_loss: 0.2607 - val_pred_loss: 0.2607 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8879 - lr: 1.0000e-04\n",
            "Epoch 293/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.6026 - pred_loss: 0.2406 - tf.where_10_loss: 0.0072 - pred_sparse_categorical_accuracy: 0.8964 - val_loss: 0.5747 - val_pred_loss: 0.5747 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7439 - lr: 1.0000e-04\n",
            "Epoch 294/500\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 0.5937 - pred_loss: 0.2450 - tf.where_10_loss: 0.0070 - pred_sparse_categorical_accuracy: 0.9022 - val_loss: 0.4048 - val_pred_loss: 0.4048 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8083 - lr: 1.0000e-04\n",
            "Epoch 295/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.5932 - pred_loss: 0.2430 - tf.where_10_loss: 0.0070 - pred_sparse_categorical_accuracy: 0.8950 - val_loss: 0.4299 - val_pred_loss: 0.4299 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7977 - lr: 1.0000e-04\n",
            "Epoch 296/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.5965 - pred_loss: 0.2397 - tf.where_10_loss: 0.0071 - pred_sparse_categorical_accuracy: 0.8984 - val_loss: 0.4377 - val_pred_loss: 0.4377 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7886 - lr: 1.0000e-04\n",
            "Epoch 297/500\n",
            "113/113 [==============================] - 2s 19ms/step - loss: 0.5951 - pred_loss: 0.2412 - tf.where_10_loss: 0.0071 - pred_sparse_categorical_accuracy: 0.9003 - val_loss: 0.2648 - val_pred_loss: 0.2648 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8780 - lr: 1.0000e-04\n",
            "Epoch 298/500\n",
            "113/113 [==============================] - 2s 20ms/step - loss: 0.6029 - pred_loss: 0.2458 - tf.where_10_loss: 0.0071 - pred_sparse_categorical_accuracy: 0.8970 - val_loss: 0.3654 - val_pred_loss: 0.3654 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8265 - lr: 1.0000e-04\n",
            "Epoch 299/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.6124 - pred_loss: 0.2391 - tf.where_10_loss: 0.0075 - pred_sparse_categorical_accuracy: 0.8984 - val_loss: 0.2851 - val_pred_loss: 0.2851 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8742 - lr: 1.0000e-04\n",
            "Epoch 300/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.5983 - pred_loss: 0.2394 - tf.where_10_loss: 0.0072 - pred_sparse_categorical_accuracy: 0.9000 - val_loss: 0.2550 - val_pred_loss: 0.2550 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8924 - lr: 1.0000e-04\n",
            "Epoch 301/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.6078 - pred_loss: 0.2443 - tf.where_10_loss: 0.0073 - pred_sparse_categorical_accuracy: 0.8959 - val_loss: 0.3834 - val_pred_loss: 0.3834 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8144 - lr: 1.0000e-04\n",
            "Epoch 302/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.5980 - pred_loss: 0.2439 - tf.where_10_loss: 0.0071 - pred_sparse_categorical_accuracy: 0.9022 - val_loss: 0.6185 - val_pred_loss: 0.6185 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7265 - lr: 1.0000e-04\n",
            "Epoch 303/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.6073 - pred_loss: 0.2506 - tf.where_10_loss: 0.0071 - pred_sparse_categorical_accuracy: 0.8931 - val_loss: 0.3985 - val_pred_loss: 0.3985 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8098 - lr: 1.0000e-04\n",
            "Epoch 304/500\n",
            "113/113 [==============================] - 2s 20ms/step - loss: 0.5937 - pred_loss: 0.2360 - tf.where_10_loss: 0.0072 - pred_sparse_categorical_accuracy: 0.9025 - val_loss: 0.3713 - val_pred_loss: 0.3713 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8280 - lr: 1.0000e-04\n",
            "Epoch 305/500\n",
            "113/113 [==============================] - 2s 21ms/step - loss: 0.6078 - pred_loss: 0.2422 - tf.where_10_loss: 0.0073 - pred_sparse_categorical_accuracy: 0.9047 - val_loss: 0.4554 - val_pred_loss: 0.4554 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7833 - lr: 1.0000e-04\n",
            "Epoch 306/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.5807 - pred_loss: 0.2325 - tf.where_10_loss: 0.0070 - pred_sparse_categorical_accuracy: 0.9039 - val_loss: 0.3324 - val_pred_loss: 0.3324 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8432 - lr: 1.0000e-04\n",
            "Epoch 307/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.5961 - pred_loss: 0.2434 - tf.where_10_loss: 0.0071 - pred_sparse_categorical_accuracy: 0.8970 - val_loss: 0.3821 - val_pred_loss: 0.3821 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8152 - lr: 1.0000e-04\n",
            "Epoch 308/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.5778 - pred_loss: 0.2342 - tf.where_10_loss: 0.0069 - pred_sparse_categorical_accuracy: 0.9017 - val_loss: 0.2891 - val_pred_loss: 0.2891 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8780 - lr: 1.0000e-04\n",
            "Epoch 309/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.6128 - pred_loss: 0.2495 - tf.where_10_loss: 0.0073 - pred_sparse_categorical_accuracy: 0.8920 - val_loss: 0.3293 - val_pred_loss: 0.3293 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8553 - lr: 1.0000e-04\n",
            "Epoch 310/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.6090 - pred_loss: 0.2466 - tf.where_10_loss: 0.0072 - pred_sparse_categorical_accuracy: 0.8928 - val_loss: 1.5351 - val_pred_loss: 1.5351 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6303 - lr: 1.0000e-04\n",
            "Epoch 311/500\n",
            "113/113 [==============================] - 2s 20ms/step - loss: 0.6075 - pred_loss: 0.2423 - tf.where_10_loss: 0.0073 - pred_sparse_categorical_accuracy: 0.9009 - val_loss: 0.3431 - val_pred_loss: 0.3431 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8371 - lr: 1.0000e-04\n",
            "Epoch 312/500\n",
            "113/113 [==============================] - 2s 21ms/step - loss: 0.5846 - pred_loss: 0.2335 - tf.where_10_loss: 0.0070 - pred_sparse_categorical_accuracy: 0.9003 - val_loss: 0.4237 - val_pred_loss: 0.4237 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7939 - lr: 1.0000e-04\n",
            "Epoch 313/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.6073 - pred_loss: 0.2507 - tf.where_10_loss: 0.0071 - pred_sparse_categorical_accuracy: 0.8920 - val_loss: 0.2876 - val_pred_loss: 0.2876 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8742 - lr: 1.0000e-04\n",
            "Epoch 314/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.6035 - pred_loss: 0.2411 - tf.where_10_loss: 0.0072 - pred_sparse_categorical_accuracy: 0.9003 - val_loss: 0.3948 - val_pred_loss: 0.3948 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8136 - lr: 1.0000e-04\n",
            "Epoch 315/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.5905 - pred_loss: 0.2408 - tf.where_10_loss: 0.0070 - pred_sparse_categorical_accuracy: 0.8989 - val_loss: 0.4612 - val_pred_loss: 0.4612 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7750 - lr: 1.0000e-04\n",
            "Epoch 316/500\n",
            "113/113 [==============================] - 2s 19ms/step - loss: 0.5887 - pred_loss: 0.2378 - tf.where_10_loss: 0.0070 - pred_sparse_categorical_accuracy: 0.9022 - val_loss: 0.4496 - val_pred_loss: 0.4496 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7833 - lr: 1.0000e-04\n",
            "Epoch 317/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.5944 - pred_loss: 0.2477 - tf.where_10_loss: 0.0069 - pred_sparse_categorical_accuracy: 0.8928 - val_loss: 0.5708 - val_pred_loss: 0.5708 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7432 - lr: 1.0000e-04\n",
            "Epoch 318/500\n",
            "113/113 [==============================] - 2s 22ms/step - loss: 0.5877 - pred_loss: 0.2394 - tf.where_10_loss: 0.0070 - pred_sparse_categorical_accuracy: 0.9009 - val_loss: 0.3090 - val_pred_loss: 0.3090 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8614 - lr: 1.0000e-04\n",
            "Epoch 319/500\n",
            "113/113 [==============================] - 2s 22ms/step - loss: 0.5903 - pred_loss: 0.2399 - tf.where_10_loss: 0.0070 - pred_sparse_categorical_accuracy: 0.9039 - val_loss: 0.5716 - val_pred_loss: 0.5716 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7492 - lr: 1.0000e-04\n",
            "Epoch 320/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.5836 - pred_loss: 0.2365 - tf.where_10_loss: 0.0069 - pred_sparse_categorical_accuracy: 0.9022 - val_loss: 0.4742 - val_pred_loss: 0.4742 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7788 - lr: 1.0000e-04\n",
            "Epoch 321/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.6004 - pred_loss: 0.2470 - tf.where_10_loss: 0.0071 - pred_sparse_categorical_accuracy: 0.8956 - val_loss: 0.3432 - val_pred_loss: 0.3432 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8409 - lr: 1.0000e-04\n",
            "Epoch 322/500\n",
            "113/113 [==============================] - 2s 19ms/step - loss: 0.5955 - pred_loss: 0.2375 - tf.where_10_loss: 0.0072 - pred_sparse_categorical_accuracy: 0.9017 - val_loss: 0.5643 - val_pred_loss: 0.5643 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7508 - lr: 1.0000e-04\n",
            "Epoch 323/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.5928 - pred_loss: 0.2457 - tf.where_10_loss: 0.0069 - pred_sparse_categorical_accuracy: 0.8948 - val_loss: 0.3758 - val_pred_loss: 0.3758 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8174 - lr: 1.0000e-04\n",
            "Epoch 324/500\n",
            "113/113 [==============================] - 2s 19ms/step - loss: 0.5944 - pred_loss: 0.2380 - tf.where_10_loss: 0.0071 - pred_sparse_categorical_accuracy: 0.9028 - val_loss: 0.2470 - val_pred_loss: 0.2470 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.9008 - lr: 1.0000e-04\n",
            "Epoch 325/500\n",
            "113/113 [==============================] - 3s 23ms/step - loss: 0.5829 - pred_loss: 0.2403 - tf.where_10_loss: 0.0069 - pred_sparse_categorical_accuracy: 0.8928 - val_loss: 0.2974 - val_pred_loss: 0.2974 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8682 - lr: 1.0000e-04\n",
            "Epoch 326/500\n",
            "113/113 [==============================] - 2s 19ms/step - loss: 0.5873 - pred_loss: 0.2426 - tf.where_10_loss: 0.0069 - pred_sparse_categorical_accuracy: 0.9020 - val_loss: 0.2702 - val_pred_loss: 0.2702 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8856 - lr: 1.0000e-04\n",
            "Epoch 327/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.5853 - pred_loss: 0.2419 - tf.where_10_loss: 0.0069 - pred_sparse_categorical_accuracy: 0.8973 - val_loss: 0.5655 - val_pred_loss: 0.5655 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7523 - lr: 1.0000e-04\n",
            "Epoch 328/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.5940 - pred_loss: 0.2420 - tf.where_10_loss: 0.0070 - pred_sparse_categorical_accuracy: 0.8984 - val_loss: 0.2962 - val_pred_loss: 0.2962 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8697 - lr: 1.0000e-04\n",
            "Epoch 329/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.5751 - pred_loss: 0.2359 - tf.where_10_loss: 0.0068 - pred_sparse_categorical_accuracy: 0.9017 - val_loss: 0.2583 - val_pred_loss: 0.2583 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8856 - lr: 1.0000e-04\n",
            "Epoch 330/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.5913 - pred_loss: 0.2376 - tf.where_10_loss: 0.0071 - pred_sparse_categorical_accuracy: 0.9000 - val_loss: 0.5587 - val_pred_loss: 0.5587 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7568 - lr: 1.0000e-04\n",
            "Epoch 331/500\n",
            "113/113 [==============================] - 2s 21ms/step - loss: 0.5979 - pred_loss: 0.2446 - tf.where_10_loss: 0.0071 - pred_sparse_categorical_accuracy: 0.8945 - val_loss: 0.2745 - val_pred_loss: 0.2745 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8750 - lr: 1.0000e-04\n",
            "Epoch 332/500\n",
            "113/113 [==============================] - 2s 21ms/step - loss: 0.6003 - pred_loss: 0.2451 - tf.where_10_loss: 0.0071 - pred_sparse_categorical_accuracy: 0.8970 - val_loss: 0.3933 - val_pred_loss: 0.3933 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8076 - lr: 1.0000e-04\n",
            "Epoch 333/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.5926 - pred_loss: 0.2412 - tf.where_10_loss: 0.0070 - pred_sparse_categorical_accuracy: 0.9042 - val_loss: 0.5507 - val_pred_loss: 0.5507 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7523 - lr: 1.0000e-04\n",
            "Epoch 334/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.5906 - pred_loss: 0.2371 - tf.where_10_loss: 0.0071 - pred_sparse_categorical_accuracy: 0.8984 - val_loss: 0.3669 - val_pred_loss: 0.3669 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8258 - lr: 1.0000e-04\n",
            "Epoch 335/500\n",
            "113/113 [==============================] - 2s 19ms/step - loss: 0.5857 - pred_loss: 0.2427 - tf.where_10_loss: 0.0069 - pred_sparse_categorical_accuracy: 0.8998 - val_loss: 0.2927 - val_pred_loss: 0.2927 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8659 - lr: 1.0000e-04\n",
            "Epoch 336/500\n",
            "113/113 [==============================] - 2s 19ms/step - loss: 0.5944 - pred_loss: 0.2431 - tf.where_10_loss: 0.0070 - pred_sparse_categorical_accuracy: 0.8923 - val_loss: 0.5429 - val_pred_loss: 0.5429 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7568 - lr: 1.0000e-04\n",
            "Epoch 337/500\n",
            "113/113 [==============================] - 2s 19ms/step - loss: 0.5800 - pred_loss: 0.2385 - tf.where_10_loss: 0.0068 - pred_sparse_categorical_accuracy: 0.9064 - val_loss: 0.2588 - val_pred_loss: 0.2588 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8848 - lr: 1.0000e-04\n",
            "Epoch 338/500\n",
            "113/113 [==============================] - 3s 22ms/step - loss: 0.5724 - pred_loss: 0.2403 - tf.where_10_loss: 0.0066 - pred_sparse_categorical_accuracy: 0.9039 - val_loss: 0.5624 - val_pred_loss: 0.5624 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7500 - lr: 1.0000e-04\n",
            "Epoch 339/500\n",
            "113/113 [==============================] - 2s 19ms/step - loss: 0.5903 - pred_loss: 0.2483 - tf.where_10_loss: 0.0068 - pred_sparse_categorical_accuracy: 0.8948 - val_loss: 0.3491 - val_pred_loss: 0.3491 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8348 - lr: 1.0000e-04\n",
            "Epoch 340/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.5798 - pred_loss: 0.2377 - tf.where_10_loss: 0.0068 - pred_sparse_categorical_accuracy: 0.9025 - val_loss: 0.2825 - val_pred_loss: 0.2825 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8795 - lr: 1.0000e-04\n",
            "Epoch 341/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.5885 - pred_loss: 0.2465 - tf.where_10_loss: 0.0068 - pred_sparse_categorical_accuracy: 0.8964 - val_loss: 0.3568 - val_pred_loss: 0.3568 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8333 - lr: 1.0000e-04\n",
            "Epoch 342/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.5888 - pred_loss: 0.2417 - tf.where_10_loss: 0.0069 - pred_sparse_categorical_accuracy: 0.8967 - val_loss: 0.4282 - val_pred_loss: 0.4282 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7939 - lr: 1.0000e-04\n",
            "Epoch 343/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.5738 - pred_loss: 0.2363 - tf.where_10_loss: 0.0067 - pred_sparse_categorical_accuracy: 0.9031 - val_loss: 0.5283 - val_pred_loss: 0.5283 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7614 - lr: 1.0000e-04\n",
            "Epoch 344/500\n",
            "113/113 [==============================] - 2s 19ms/step - loss: 0.5719 - pred_loss: 0.2394 - tf.where_10_loss: 0.0066 - pred_sparse_categorical_accuracy: 0.9072 - val_loss: 0.4258 - val_pred_loss: 0.4258 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7992 - lr: 1.0000e-04\n",
            "Epoch 345/500\n",
            "113/113 [==============================] - 2s 20ms/step - loss: 0.5905 - pred_loss: 0.2433 - tf.where_10_loss: 0.0069 - pred_sparse_categorical_accuracy: 0.9022 - val_loss: 0.2713 - val_pred_loss: 0.2713 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8795 - lr: 1.0000e-04\n",
            "Epoch 346/500\n",
            "113/113 [==============================] - 2s 19ms/step - loss: 0.5902 - pred_loss: 0.2415 - tf.where_10_loss: 0.0070 - pred_sparse_categorical_accuracy: 0.8959 - val_loss: 0.9843 - val_pred_loss: 0.9843 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6818 - lr: 1.0000e-04\n",
            "Epoch 347/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.5985 - pred_loss: 0.2328 - tf.where_10_loss: 0.0073 - pred_sparse_categorical_accuracy: 0.9050 - val_loss: 0.2790 - val_pred_loss: 0.2790 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8735 - lr: 1.0000e-04\n",
            "Epoch 348/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.5872 - pred_loss: 0.2500 - tf.where_10_loss: 0.0067 - pred_sparse_categorical_accuracy: 0.8950 - val_loss: 0.3729 - val_pred_loss: 0.3729 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8242 - lr: 1.0000e-04\n",
            "Epoch 349/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.5698 - pred_loss: 0.2376 - tf.where_10_loss: 0.0066 - pred_sparse_categorical_accuracy: 0.9020 - val_loss: 0.2504 - val_pred_loss: 0.2504 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8932 - lr: 1.0000e-04\n",
            "Epoch 350/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.5799 - pred_loss: 0.2327 - tf.where_10_loss: 0.0069 - pred_sparse_categorical_accuracy: 0.9053 - val_loss: 0.9119 - val_pred_loss: 0.9119 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6833 - lr: 1.0000e-04\n",
            "Epoch 351/500\n",
            "113/113 [==============================] - 2s 21ms/step - loss: 0.5811 - pred_loss: 0.2391 - tf.where_10_loss: 0.0068 - pred_sparse_categorical_accuracy: 0.8992 - val_loss: 0.3796 - val_pred_loss: 0.3796 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8250 - lr: 1.0000e-04\n",
            "Epoch 352/500\n",
            "113/113 [==============================] - 2s 22ms/step - loss: 0.5916 - pred_loss: 0.2439 - tf.where_10_loss: 0.0070 - pred_sparse_categorical_accuracy: 0.9003 - val_loss: 0.5360 - val_pred_loss: 0.5360 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7530 - lr: 1.0000e-04\n",
            "Epoch 353/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.5947 - pred_loss: 0.2482 - tf.where_10_loss: 0.0069 - pred_sparse_categorical_accuracy: 0.9011 - val_loss: 0.2544 - val_pred_loss: 0.2544 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.9015 - lr: 1.0000e-04\n",
            "Epoch 354/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.5878 - pred_loss: 0.2366 - tf.where_10_loss: 0.0070 - pred_sparse_categorical_accuracy: 0.9047 - val_loss: 0.5272 - val_pred_loss: 0.5272 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7545 - lr: 1.0000e-04\n",
            "Epoch 355/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.5777 - pred_loss: 0.2341 - tf.where_10_loss: 0.0069 - pred_sparse_categorical_accuracy: 0.9061 - val_loss: 0.2835 - val_pred_loss: 0.2835 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8750 - lr: 1.0000e-04\n",
            "Epoch 356/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.5836 - pred_loss: 0.2421 - tf.where_10_loss: 0.0068 - pred_sparse_categorical_accuracy: 0.8981 - val_loss: 0.3310 - val_pred_loss: 0.3310 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8500 - lr: 1.0000e-04\n",
            "Epoch 357/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.5919 - pred_loss: 0.2409 - tf.where_10_loss: 0.0070 - pred_sparse_categorical_accuracy: 0.9003 - val_loss: 0.3782 - val_pred_loss: 0.3782 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8167 - lr: 1.0000e-04\n",
            "Epoch 358/500\n",
            "113/113 [==============================] - 2s 22ms/step - loss: 0.5722 - pred_loss: 0.2329 - tf.where_10_loss: 0.0068 - pred_sparse_categorical_accuracy: 0.8984 - val_loss: 0.2810 - val_pred_loss: 0.2810 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8712 - lr: 1.0000e-04\n",
            "Epoch 359/500\n",
            "113/113 [==============================] - 2s 20ms/step - loss: 0.5668 - pred_loss: 0.2293 - tf.where_10_loss: 0.0067 - pred_sparse_categorical_accuracy: 0.9084 - val_loss: 0.3480 - val_pred_loss: 0.3480 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8326 - lr: 1.0000e-04\n",
            "Epoch 360/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.5906 - pred_loss: 0.2399 - tf.where_10_loss: 0.0070 - pred_sparse_categorical_accuracy: 0.9028 - val_loss: 0.7131 - val_pred_loss: 0.7131 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7212 - lr: 1.0000e-04\n",
            "Epoch 361/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.5802 - pred_loss: 0.2390 - tf.where_10_loss: 0.0068 - pred_sparse_categorical_accuracy: 0.9000 - val_loss: 0.3504 - val_pred_loss: 0.3504 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8341 - lr: 1.0000e-04\n",
            "Epoch 362/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.5767 - pred_loss: 0.2400 - tf.where_10_loss: 0.0067 - pred_sparse_categorical_accuracy: 0.9014 - val_loss: 0.7320 - val_pred_loss: 0.7320 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7136 - lr: 1.0000e-04\n",
            "Epoch 363/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.5965 - pred_loss: 0.2425 - tf.where_10_loss: 0.0071 - pred_sparse_categorical_accuracy: 0.8967 - val_loss: 0.7144 - val_pred_loss: 0.7144 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7197 - lr: 1.0000e-04\n",
            "Epoch 364/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.5883 - pred_loss: 0.2441 - tf.where_10_loss: 0.0069 - pred_sparse_categorical_accuracy: 0.8956 - val_loss: 0.3746 - val_pred_loss: 0.3746 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8227 - lr: 1.0000e-04\n",
            "Epoch 365/500\n",
            "113/113 [==============================] - 2s 21ms/step - loss: 0.5865 - pred_loss: 0.2352 - tf.where_10_loss: 0.0070 - pred_sparse_categorical_accuracy: 0.9000 - val_loss: 0.2686 - val_pred_loss: 0.2686 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8765 - lr: 1.0000e-04\n",
            "Epoch 366/500\n",
            "113/113 [==============================] - 2s 20ms/step - loss: 0.5745 - pred_loss: 0.2363 - tf.where_10_loss: 0.0068 - pred_sparse_categorical_accuracy: 0.9056 - val_loss: 0.6621 - val_pred_loss: 0.6621 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7258 - lr: 1.0000e-04\n",
            "Epoch 367/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.5772 - pred_loss: 0.2345 - tf.where_10_loss: 0.0069 - pred_sparse_categorical_accuracy: 0.9056 - val_loss: 0.2461 - val_pred_loss: 0.2461 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8962 - lr: 1.0000e-04\n",
            "Epoch 368/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.5903 - pred_loss: 0.2516 - tf.where_10_loss: 0.0068 - pred_sparse_categorical_accuracy: 0.8942 - val_loss: 0.2899 - val_pred_loss: 0.2899 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8689 - lr: 1.0000e-04\n",
            "Epoch 369/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.5705 - pred_loss: 0.2332 - tf.where_10_loss: 0.0067 - pred_sparse_categorical_accuracy: 0.9047 - val_loss: 0.3424 - val_pred_loss: 0.3424 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8348 - lr: 1.0000e-04\n",
            "Epoch 370/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.5754 - pred_loss: 0.2359 - tf.where_10_loss: 0.0068 - pred_sparse_categorical_accuracy: 0.9017 - val_loss: 0.4078 - val_pred_loss: 0.4078 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8076 - lr: 1.0000e-04\n",
            "Epoch 371/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.5935 - pred_loss: 0.2383 - tf.where_10_loss: 0.0071 - pred_sparse_categorical_accuracy: 0.9028 - val_loss: 0.4179 - val_pred_loss: 0.4179 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8061 - lr: 1.0000e-04\n",
            "Epoch 372/500\n",
            "113/113 [==============================] - 2s 19ms/step - loss: 0.5691 - pred_loss: 0.2377 - tf.where_10_loss: 0.0066 - pred_sparse_categorical_accuracy: 0.9006 - val_loss: 0.2827 - val_pred_loss: 0.2827 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8727 - lr: 1.0000e-04\n",
            "Epoch 373/500\n",
            "113/113 [==============================] - 2s 20ms/step - loss: 0.5896 - pred_loss: 0.2455 - tf.where_10_loss: 0.0069 - pred_sparse_categorical_accuracy: 0.8978 - val_loss: 0.4132 - val_pred_loss: 0.4132 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 374/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.5790 - pred_loss: 0.2413 - tf.where_10_loss: 0.0068 - pred_sparse_categorical_accuracy: 0.9014 - val_loss: 0.4921 - val_pred_loss: 0.4921 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7697 - lr: 1.0000e-04\n",
            "Epoch 375/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.5828 - pred_loss: 0.2443 - tf.where_10_loss: 0.0068 - pred_sparse_categorical_accuracy: 0.8959 - val_loss: 0.4920 - val_pred_loss: 0.4920 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7773 - lr: 1.0000e-04\n",
            "Epoch 376/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.5622 - pred_loss: 0.2345 - tf.where_10_loss: 0.0066 - pred_sparse_categorical_accuracy: 0.9053 - val_loss: 0.6755 - val_pred_loss: 0.6755 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7295 - lr: 1.0000e-04\n",
            "Epoch 377/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.5757 - pred_loss: 0.2323 - tf.where_10_loss: 0.0069 - pred_sparse_categorical_accuracy: 0.9028 - val_loss: 1.2481 - val_pred_loss: 1.2481 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6644 - lr: 1.0000e-04\n",
            "Epoch 378/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.5675 - pred_loss: 0.2366 - tf.where_10_loss: 0.0066 - pred_sparse_categorical_accuracy: 0.9031 - val_loss: 0.3491 - val_pred_loss: 0.3491 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8394 - lr: 1.0000e-04\n",
            "Epoch 379/500\n",
            "113/113 [==============================] - 2s 20ms/step - loss: 0.5629 - pred_loss: 0.2378 - tf.where_10_loss: 0.0065 - pred_sparse_categorical_accuracy: 0.9020 - val_loss: 0.4135 - val_pred_loss: 0.4135 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8038 - lr: 1.0000e-04\n",
            "Epoch 380/500\n",
            "113/113 [==============================] - 2s 21ms/step - loss: 0.5595 - pred_loss: 0.2338 - tf.where_10_loss: 0.0065 - pred_sparse_categorical_accuracy: 0.9036 - val_loss: 0.5858 - val_pred_loss: 0.5858 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7530 - lr: 1.0000e-04\n",
            "Epoch 381/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.5660 - pred_loss: 0.2348 - tf.where_10_loss: 0.0066 - pred_sparse_categorical_accuracy: 0.8975 - val_loss: 0.2847 - val_pred_loss: 0.2847 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8742 - lr: 1.0000e-04\n",
            "Epoch 382/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.5822 - pred_loss: 0.2443 - tf.where_10_loss: 0.0068 - pred_sparse_categorical_accuracy: 0.8995 - val_loss: 0.3623 - val_pred_loss: 0.3623 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8333 - lr: 1.0000e-04\n",
            "Epoch 383/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.5607 - pred_loss: 0.2405 - tf.where_10_loss: 0.0064 - pred_sparse_categorical_accuracy: 0.9070 - val_loss: 0.3132 - val_pred_loss: 0.3132 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8591 - lr: 1.0000e-04\n",
            "Epoch 384/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.5702 - pred_loss: 0.2385 - tf.where_10_loss: 0.0066 - pred_sparse_categorical_accuracy: 0.9025 - val_loss: 0.4009 - val_pred_loss: 0.4009 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8159 - lr: 1.0000e-04\n",
            "Epoch 385/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.5775 - pred_loss: 0.2383 - tf.where_10_loss: 0.0068 - pred_sparse_categorical_accuracy: 0.9020 - val_loss: 0.3749 - val_pred_loss: 0.3749 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8295 - lr: 1.0000e-04\n",
            "Epoch 386/500\n",
            "113/113 [==============================] - 2s 20ms/step - loss: 0.5716 - pred_loss: 0.2402 - tf.where_10_loss: 0.0066 - pred_sparse_categorical_accuracy: 0.9017 - val_loss: 0.3548 - val_pred_loss: 0.3548 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8311 - lr: 1.0000e-04\n",
            "Epoch 387/500\n",
            "113/113 [==============================] - 2s 20ms/step - loss: 0.5645 - pred_loss: 0.2336 - tf.where_10_loss: 0.0066 - pred_sparse_categorical_accuracy: 0.9047 - val_loss: 0.4045 - val_pred_loss: 0.4045 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8129 - lr: 1.0000e-04\n",
            "Epoch 388/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.5685 - pred_loss: 0.2359 - tf.where_10_loss: 0.0067 - pred_sparse_categorical_accuracy: 0.9014 - val_loss: 0.5160 - val_pred_loss: 0.5160 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7682 - lr: 1.0000e-04\n",
            "Epoch 389/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.5823 - pred_loss: 0.2354 - tf.where_10_loss: 0.0069 - pred_sparse_categorical_accuracy: 0.9042 - val_loss: 0.8208 - val_pred_loss: 0.8208 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7083 - lr: 1.0000e-04\n",
            "Epoch 390/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.5470 - pred_loss: 0.2277 - tf.where_10_loss: 0.0064 - pred_sparse_categorical_accuracy: 0.9070 - val_loss: 0.3659 - val_pred_loss: 0.3659 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8348 - lr: 1.0000e-04\n",
            "Epoch 391/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.5593 - pred_loss: 0.2342 - tf.where_10_loss: 0.0065 - pred_sparse_categorical_accuracy: 0.9000 - val_loss: 0.4581 - val_pred_loss: 0.4581 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7848 - lr: 1.0000e-04\n",
            "Epoch 392/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.5797 - pred_loss: 0.2447 - tf.where_10_loss: 0.0067 - pred_sparse_categorical_accuracy: 0.8931 - val_loss: 0.5225 - val_pred_loss: 0.5225 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7682 - lr: 1.0000e-04\n",
            "Epoch 393/500\n",
            "113/113 [==============================] - 2s 20ms/step - loss: 0.5747 - pred_loss: 0.2365 - tf.where_10_loss: 0.0068 - pred_sparse_categorical_accuracy: 0.9042 - val_loss: 0.7973 - val_pred_loss: 0.7973 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7091 - lr: 1.0000e-04\n",
            "Epoch 394/500\n",
            "113/113 [==============================] - 2s 20ms/step - loss: 0.5675 - pred_loss: 0.2367 - tf.where_10_loss: 0.0066 - pred_sparse_categorical_accuracy: 0.8995 - val_loss: 0.3343 - val_pred_loss: 0.3343 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8492 - lr: 1.0000e-04\n",
            "Epoch 395/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.5672 - pred_loss: 0.2371 - tf.where_10_loss: 0.0066 - pred_sparse_categorical_accuracy: 0.8995 - val_loss: 0.3482 - val_pred_loss: 0.3482 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8348 - lr: 1.0000e-04\n",
            "Epoch 396/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.5741 - pred_loss: 0.2420 - tf.where_10_loss: 0.0066 - pred_sparse_categorical_accuracy: 0.8973 - val_loss: 0.4358 - val_pred_loss: 0.4358 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8023 - lr: 1.0000e-04\n",
            "Epoch 397/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.5633 - pred_loss: 0.2360 - tf.where_10_loss: 0.0065 - pred_sparse_categorical_accuracy: 0.9042 - val_loss: 0.2553 - val_pred_loss: 0.2553 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8955 - lr: 1.0000e-04\n",
            "Epoch 398/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.5625 - pred_loss: 0.2384 - tf.where_10_loss: 0.0065 - pred_sparse_categorical_accuracy: 0.9014 - val_loss: 0.5147 - val_pred_loss: 0.5147 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7667 - lr: 1.0000e-04\n",
            "Epoch 399/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.5586 - pred_loss: 0.2378 - tf.where_10_loss: 0.0064 - pred_sparse_categorical_accuracy: 0.9045 - val_loss: 0.2982 - val_pred_loss: 0.2982 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8667 - lr: 1.0000e-04\n",
            "Epoch 400/500\n",
            "113/113 [==============================] - 2s 20ms/step - loss: 0.5763 - pred_loss: 0.2397 - tf.where_10_loss: 0.0067 - pred_sparse_categorical_accuracy: 0.8975 - val_loss: 0.3114 - val_pred_loss: 0.3114 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8598 - lr: 1.0000e-04\n",
            "Epoch 401/500\n",
            "113/113 [==============================] - 2s 21ms/step - loss: 0.5724 - pred_loss: 0.2437 - tf.where_10_loss: 0.0066 - pred_sparse_categorical_accuracy: 0.8984 - val_loss: 0.7701 - val_pred_loss: 0.7701 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7098 - lr: 1.0000e-04\n",
            "Epoch 402/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.5755 - pred_loss: 0.2383 - tf.where_10_loss: 0.0067 - pred_sparse_categorical_accuracy: 0.9022 - val_loss: 0.7598 - val_pred_loss: 0.7598 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7091 - lr: 1.0000e-04\n",
            "Epoch 403/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.5615 - pred_loss: 0.2365 - tf.where_10_loss: 0.0065 - pred_sparse_categorical_accuracy: 0.8981 - val_loss: 0.5470 - val_pred_loss: 0.5470 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7576 - lr: 1.0000e-04\n",
            "Epoch 404/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.5551 - pred_loss: 0.2284 - tf.where_10_loss: 0.0065 - pred_sparse_categorical_accuracy: 0.9028 - val_loss: 0.3475 - val_pred_loss: 0.3475 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8394 - lr: 1.0000e-04\n",
            "Epoch 405/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.5562 - pred_loss: 0.2357 - tf.where_10_loss: 0.0064 - pred_sparse_categorical_accuracy: 0.8986 - val_loss: 0.2588 - val_pred_loss: 0.2588 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8864 - lr: 1.0000e-04\n",
            "Epoch 406/500\n",
            "113/113 [==============================] - 2s 19ms/step - loss: 0.5650 - pred_loss: 0.2432 - tf.where_10_loss: 0.0064 - pred_sparse_categorical_accuracy: 0.8975 - val_loss: 0.7963 - val_pred_loss: 0.7963 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7083 - lr: 1.0000e-04\n",
            "Epoch 407/500\n",
            "113/113 [==============================] - 2s 20ms/step - loss: 0.5551 - pred_loss: 0.2366 - tf.where_10_loss: 0.0064 - pred_sparse_categorical_accuracy: 0.9047 - val_loss: 0.2566 - val_pred_loss: 0.2566 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8902 - lr: 1.0000e-04\n",
            "Epoch 408/500\n",
            "113/113 [==============================] - 2s 19ms/step - loss: 0.5668 - pred_loss: 0.2320 - tf.where_10_loss: 0.0067 - pred_sparse_categorical_accuracy: 0.9039 - val_loss: 0.3223 - val_pred_loss: 0.3223 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8538 - lr: 1.0000e-04\n",
            "Epoch 409/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.5722 - pred_loss: 0.2419 - tf.where_10_loss: 0.0066 - pred_sparse_categorical_accuracy: 0.8973 - val_loss: 0.6453 - val_pred_loss: 0.6453 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7258 - lr: 1.0000e-04\n",
            "Epoch 410/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.5746 - pred_loss: 0.2429 - tf.where_10_loss: 0.0066 - pred_sparse_categorical_accuracy: 0.8992 - val_loss: 1.0728 - val_pred_loss: 1.0728 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6750 - lr: 1.0000e-04\n",
            "Epoch 411/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.5525 - pred_loss: 0.2341 - tf.where_10_loss: 0.0064 - pred_sparse_categorical_accuracy: 0.9031 - val_loss: 0.3228 - val_pred_loss: 0.3228 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8508 - lr: 1.0000e-04\n",
            "Epoch 412/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.5684 - pred_loss: 0.2397 - tf.where_10_loss: 0.0066 - pred_sparse_categorical_accuracy: 0.9000 - val_loss: 0.5814 - val_pred_loss: 0.5814 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7477 - lr: 1.0000e-04\n",
            "Epoch 413/500\n",
            "113/113 [==============================] - 2s 19ms/step - loss: 0.5476 - pred_loss: 0.2326 - tf.where_10_loss: 0.0063 - pred_sparse_categorical_accuracy: 0.9081 - val_loss: 0.3103 - val_pred_loss: 0.3103 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8621 - lr: 1.0000e-04\n",
            "Epoch 414/500\n",
            "113/113 [==============================] - 2s 21ms/step - loss: 0.5619 - pred_loss: 0.2320 - tf.where_10_loss: 0.0066 - pred_sparse_categorical_accuracy: 0.9039 - val_loss: 0.3309 - val_pred_loss: 0.3309 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8515 - lr: 1.0000e-04\n",
            "Epoch 415/500\n",
            "113/113 [==============================] - 2s 19ms/step - loss: 0.5743 - pred_loss: 0.2322 - tf.where_10_loss: 0.0068 - pred_sparse_categorical_accuracy: 0.9025 - val_loss: 1.0285 - val_pred_loss: 1.0285 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6818 - lr: 1.0000e-04\n",
            "Epoch 416/500\n",
            "113/113 [==============================] - 2s 19ms/step - loss: 0.5609 - pred_loss: 0.2301 - tf.where_10_loss: 0.0066 - pred_sparse_categorical_accuracy: 0.9097 - val_loss: 0.3282 - val_pred_loss: 0.3282 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8508 - lr: 1.0000e-04\n",
            "Epoch 417/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.5497 - pred_loss: 0.2310 - tf.where_10_loss: 0.0064 - pred_sparse_categorical_accuracy: 0.9089 - val_loss: 0.5036 - val_pred_loss: 0.5036 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7712 - lr: 1.0000e-04\n",
            "Epoch 418/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.5567 - pred_loss: 0.2375 - tf.where_10_loss: 0.0064 - pred_sparse_categorical_accuracy: 0.9011 - val_loss: 0.4912 - val_pred_loss: 0.4912 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7758 - lr: 1.0000e-04\n",
            "Epoch 419/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.5686 - pred_loss: 0.2387 - tf.where_10_loss: 0.0066 - pred_sparse_categorical_accuracy: 0.8973 - val_loss: 0.2722 - val_pred_loss: 0.2722 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8795 - lr: 1.0000e-04\n",
            "Epoch 420/500\n",
            "113/113 [==============================] - 2s 19ms/step - loss: 0.5567 - pred_loss: 0.2331 - tf.where_10_loss: 0.0065 - pred_sparse_categorical_accuracy: 0.9050 - val_loss: 0.5739 - val_pred_loss: 0.5739 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7439 - lr: 1.0000e-04\n",
            "Epoch 421/500\n",
            "113/113 [==============================] - 2s 22ms/step - loss: 0.5649 - pred_loss: 0.2361 - tf.where_10_loss: 0.0066 - pred_sparse_categorical_accuracy: 0.9017 - val_loss: 0.6376 - val_pred_loss: 0.6376 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7371 - lr: 1.0000e-04\n",
            "Epoch 422/500\n",
            "113/113 [==============================] - 2s 19ms/step - loss: 0.5625 - pred_loss: 0.2372 - tf.where_10_loss: 0.0065 - pred_sparse_categorical_accuracy: 0.9003 - val_loss: 0.6125 - val_pred_loss: 0.6125 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7341 - lr: 1.0000e-04\n",
            "Epoch 423/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.5524 - pred_loss: 0.2332 - tf.where_10_loss: 0.0064 - pred_sparse_categorical_accuracy: 0.8998 - val_loss: 0.6137 - val_pred_loss: 0.6137 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7424 - lr: 1.0000e-04\n",
            "Epoch 424/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.5438 - pred_loss: 0.2242 - tf.where_10_loss: 0.0064 - pred_sparse_categorical_accuracy: 0.9075 - val_loss: 0.5554 - val_pred_loss: 0.5554 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7614 - lr: 1.0000e-04\n",
            "Epoch 425/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.5698 - pred_loss: 0.2296 - tf.where_10_loss: 0.0068 - pred_sparse_categorical_accuracy: 0.9070 - val_loss: 0.5724 - val_pred_loss: 0.5724 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7583 - lr: 1.0000e-04\n",
            "Epoch 426/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.5536 - pred_loss: 0.2335 - tf.where_10_loss: 0.0064 - pred_sparse_categorical_accuracy: 0.9020 - val_loss: 0.3183 - val_pred_loss: 0.3183 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8583 - lr: 1.0000e-04\n",
            "Epoch 427/500\n",
            "113/113 [==============================] - 2s 19ms/step - loss: 0.5653 - pred_loss: 0.2413 - tf.where_10_loss: 0.0065 - pred_sparse_categorical_accuracy: 0.9006 - val_loss: 0.9155 - val_pred_loss: 0.9155 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6864 - lr: 1.0000e-04\n",
            "Epoch 428/500\n",
            "113/113 [==============================] - 2s 22ms/step - loss: 0.5707 - pred_loss: 0.2383 - tf.where_10_loss: 0.0066 - pred_sparse_categorical_accuracy: 0.8984 - val_loss: 0.3226 - val_pred_loss: 0.3226 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8545 - lr: 1.0000e-04\n",
            "Epoch 429/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.5675 - pred_loss: 0.2455 - tf.where_10_loss: 0.0064 - pred_sparse_categorical_accuracy: 0.8973 - val_loss: 0.2744 - val_pred_loss: 0.2744 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8765 - lr: 1.0000e-04\n",
            "Epoch 430/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.5435 - pred_loss: 0.2270 - tf.where_10_loss: 0.0063 - pred_sparse_categorical_accuracy: 0.9084 - val_loss: 0.5269 - val_pred_loss: 0.5269 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7598 - lr: 1.0000e-04\n",
            "Epoch 431/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.5437 - pred_loss: 0.2264 - tf.where_10_loss: 0.0063 - pred_sparse_categorical_accuracy: 0.9034 - val_loss: 0.4696 - val_pred_loss: 0.4696 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7894 - lr: 1.0000e-04\n",
            "Epoch 432/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.5458 - pred_loss: 0.2279 - tf.where_10_loss: 0.0064 - pred_sparse_categorical_accuracy: 0.9047 - val_loss: 0.3017 - val_pred_loss: 0.3017 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8659 - lr: 1.0000e-04\n",
            "Epoch 433/500\n",
            "113/113 [==============================] - 2s 19ms/step - loss: 0.5600 - pred_loss: 0.2341 - tf.where_10_loss: 0.0065 - pred_sparse_categorical_accuracy: 0.9025 - val_loss: 0.4541 - val_pred_loss: 0.4541 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7924 - lr: 1.0000e-04\n",
            "Epoch 434/500\n",
            "113/113 [==============================] - 2s 22ms/step - loss: 0.5644 - pred_loss: 0.2344 - tf.where_10_loss: 0.0066 - pred_sparse_categorical_accuracy: 0.9056 - val_loss: 0.3507 - val_pred_loss: 0.3507 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8364 - lr: 1.0000e-04\n",
            "Epoch 435/500\n",
            "113/113 [==============================] - 2s 22ms/step - loss: 0.5580 - pred_loss: 0.2348 - tf.where_10_loss: 0.0065 - pred_sparse_categorical_accuracy: 0.9009 - val_loss: 0.5037 - val_pred_loss: 0.5037 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7674 - lr: 1.0000e-04\n",
            "Epoch 436/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.5399 - pred_loss: 0.2269 - tf.where_10_loss: 0.0063 - pred_sparse_categorical_accuracy: 0.9097 - val_loss: 0.3491 - val_pred_loss: 0.3491 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8439 - lr: 1.0000e-04\n",
            "Epoch 437/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.5587 - pred_loss: 0.2392 - tf.where_10_loss: 0.0064 - pred_sparse_categorical_accuracy: 0.9011 - val_loss: 0.4420 - val_pred_loss: 0.4420 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7909 - lr: 1.0000e-04\n",
            "Epoch 438/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.5398 - pred_loss: 0.2240 - tf.where_10_loss: 0.0063 - pred_sparse_categorical_accuracy: 0.9084 - val_loss: 0.7500 - val_pred_loss: 0.7500 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7136 - lr: 1.0000e-04\n",
            "Epoch 439/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.5470 - pred_loss: 0.2295 - tf.where_10_loss: 0.0063 - pred_sparse_categorical_accuracy: 0.9067 - val_loss: 0.3120 - val_pred_loss: 0.3120 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8561 - lr: 1.0000e-04\n",
            "Epoch 440/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.5687 - pred_loss: 0.2436 - tf.where_10_loss: 0.0065 - pred_sparse_categorical_accuracy: 0.9000 - val_loss: 0.2653 - val_pred_loss: 0.2653 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8864 - lr: 1.0000e-04\n",
            "Epoch 441/500\n",
            "113/113 [==============================] - 2s 20ms/step - loss: 0.5518 - pred_loss: 0.2332 - tf.where_10_loss: 0.0064 - pred_sparse_categorical_accuracy: 0.9070 - val_loss: 1.3873 - val_pred_loss: 1.3873 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6659 - lr: 1.0000e-04\n",
            "Epoch 442/500\n",
            "113/113 [==============================] - 2s 21ms/step - loss: 0.5389 - pred_loss: 0.2282 - tf.where_10_loss: 0.0062 - pred_sparse_categorical_accuracy: 0.9053 - val_loss: 0.4216 - val_pred_loss: 0.4216 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8023 - lr: 1.0000e-04\n",
            "Epoch 443/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.5525 - pred_loss: 0.2437 - tf.where_10_loss: 0.0062 - pred_sparse_categorical_accuracy: 0.8948 - val_loss: 0.2523 - val_pred_loss: 0.2523 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8947 - lr: 1.0000e-04\n",
            "Epoch 444/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.5401 - pred_loss: 0.2283 - tf.where_10_loss: 0.0062 - pred_sparse_categorical_accuracy: 0.9072 - val_loss: 0.6099 - val_pred_loss: 0.6099 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7424 - lr: 1.0000e-04\n",
            "Epoch 445/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.5568 - pred_loss: 0.2303 - tf.where_10_loss: 0.0065 - pred_sparse_categorical_accuracy: 0.9020 - val_loss: 1.3917 - val_pred_loss: 1.3917 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6674 - lr: 1.0000e-04\n",
            "Epoch 446/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.5536 - pred_loss: 0.2324 - tf.where_10_loss: 0.0064 - pred_sparse_categorical_accuracy: 0.9059 - val_loss: 0.4772 - val_pred_loss: 0.4772 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7773 - lr: 1.0000e-04\n",
            "Epoch 447/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.5544 - pred_loss: 0.2313 - tf.where_10_loss: 0.0065 - pred_sparse_categorical_accuracy: 0.9075 - val_loss: 0.3814 - val_pred_loss: 0.3814 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8197 - lr: 1.0000e-04\n",
            "Epoch 448/500\n",
            "113/113 [==============================] - 2s 20ms/step - loss: 0.5499 - pred_loss: 0.2315 - tf.where_10_loss: 0.0064 - pred_sparse_categorical_accuracy: 0.9067 - val_loss: 0.3399 - val_pred_loss: 0.3399 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8455 - lr: 1.0000e-04\n",
            "Epoch 449/500\n",
            "113/113 [==============================] - 2s 20ms/step - loss: 0.5578 - pred_loss: 0.2363 - tf.where_10_loss: 0.0064 - pred_sparse_categorical_accuracy: 0.9000 - val_loss: 0.3837 - val_pred_loss: 0.3837 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8295 - lr: 1.0000e-04\n",
            "Epoch 450/500\n",
            "113/113 [==============================] - 2s 19ms/step - loss: 0.5518 - pred_loss: 0.2340 - tf.where_10_loss: 0.0064 - pred_sparse_categorical_accuracy: 0.9031 - val_loss: 0.3124 - val_pred_loss: 0.3124 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8606 - lr: 1.0000e-04\n",
            "Epoch 451/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.5536 - pred_loss: 0.2364 - tf.where_10_loss: 0.0063 - pred_sparse_categorical_accuracy: 0.8995 - val_loss: 0.6545 - val_pred_loss: 0.6545 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7326 - lr: 1.0000e-04\n",
            "Epoch 452/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.5718 - pred_loss: 0.2366 - tf.where_10_loss: 0.0067 - pred_sparse_categorical_accuracy: 0.9020 - val_loss: 0.5378 - val_pred_loss: 0.5378 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7636 - lr: 1.0000e-04\n",
            "Epoch 453/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.5422 - pred_loss: 0.2330 - tf.where_10_loss: 0.0062 - pred_sparse_categorical_accuracy: 0.9042 - val_loss: 0.5597 - val_pred_loss: 0.5597 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7545 - lr: 1.0000e-04\n",
            "Epoch 454/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.5568 - pred_loss: 0.2357 - tf.where_10_loss: 0.0064 - pred_sparse_categorical_accuracy: 0.9003 - val_loss: 0.4882 - val_pred_loss: 0.4882 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7742 - lr: 1.0000e-04\n",
            "Epoch 455/500\n",
            "113/113 [==============================] - 2s 20ms/step - loss: 0.5516 - pred_loss: 0.2334 - tf.where_10_loss: 0.0064 - pred_sparse_categorical_accuracy: 0.9031 - val_loss: 0.3773 - val_pred_loss: 0.3773 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8258 - lr: 1.0000e-04\n",
            "Epoch 456/500\n",
            "113/113 [==============================] - 2s 21ms/step - loss: 0.5412 - pred_loss: 0.2309 - tf.where_10_loss: 0.0062 - pred_sparse_categorical_accuracy: 0.9075 - val_loss: 0.3716 - val_pred_loss: 0.3716 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8318 - lr: 1.0000e-04\n",
            "Epoch 457/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.5417 - pred_loss: 0.2311 - tf.where_10_loss: 0.0062 - pred_sparse_categorical_accuracy: 0.9009 - val_loss: 0.3512 - val_pred_loss: 0.3512 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8371 - lr: 1.0000e-04\n",
            "Epoch 458/500\n",
            "113/113 [==============================] - 2s 19ms/step - loss: 0.5516 - pred_loss: 0.2337 - tf.where_10_loss: 0.0064 - pred_sparse_categorical_accuracy: 0.8998 - val_loss: 0.5492 - val_pred_loss: 0.5492 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7530 - lr: 1.0000e-04\n",
            "Epoch 459/500\n",
            "113/113 [==============================] - 2s 19ms/step - loss: 0.5509 - pred_loss: 0.2378 - tf.where_10_loss: 0.0063 - pred_sparse_categorical_accuracy: 0.9045 - val_loss: 0.6629 - val_pred_loss: 0.6629 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7273 - lr: 1.0000e-04\n",
            "Epoch 460/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.5470 - pred_loss: 0.2241 - tf.where_10_loss: 0.0065 - pred_sparse_categorical_accuracy: 0.9120 - val_loss: 0.8093 - val_pred_loss: 0.8093 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6962 - lr: 1.0000e-04\n",
            "Epoch 461/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.5388 - pred_loss: 0.2253 - tf.where_10_loss: 0.0063 - pred_sparse_categorical_accuracy: 0.9047 - val_loss: 0.9796 - val_pred_loss: 0.9796 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6871 - lr: 1.0000e-04\n",
            "Epoch 462/500\n",
            "113/113 [==============================] - 2s 20ms/step - loss: 0.5428 - pred_loss: 0.2320 - tf.where_10_loss: 0.0062 - pred_sparse_categorical_accuracy: 0.9050 - val_loss: 0.4976 - val_pred_loss: 0.4976 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7841 - lr: 1.0000e-04\n",
            "Epoch 463/500\n",
            "113/113 [==============================] - 2s 22ms/step - loss: 0.5321 - pred_loss: 0.2276 - tf.where_10_loss: 0.0061 - pred_sparse_categorical_accuracy: 0.9020 - val_loss: 0.3555 - val_pred_loss: 0.3555 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8402 - lr: 1.0000e-04\n",
            "Epoch 464/500\n",
            "113/113 [==============================] - 2s 19ms/step - loss: 0.5651 - pred_loss: 0.2399 - tf.where_10_loss: 0.0065 - pred_sparse_categorical_accuracy: 0.8950 - val_loss: 0.4474 - val_pred_loss: 0.4474 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7909 - lr: 1.0000e-04\n",
            "Epoch 465/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.5548 - pred_loss: 0.2346 - tf.where_10_loss: 0.0064 - pred_sparse_categorical_accuracy: 0.9047 - val_loss: 0.5516 - val_pred_loss: 0.5516 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7561 - lr: 1.0000e-04\n",
            "Epoch 466/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.5376 - pred_loss: 0.2265 - tf.where_10_loss: 0.0062 - pred_sparse_categorical_accuracy: 0.9097 - val_loss: 0.3659 - val_pred_loss: 0.3659 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8311 - lr: 1.0000e-04\n",
            "Epoch 467/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.5524 - pred_loss: 0.2315 - tf.where_10_loss: 0.0064 - pred_sparse_categorical_accuracy: 0.9011 - val_loss: 0.2676 - val_pred_loss: 0.2676 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8818 - lr: 1.0000e-04\n",
            "Epoch 468/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.5448 - pred_loss: 0.2302 - tf.where_10_loss: 0.0063 - pred_sparse_categorical_accuracy: 0.9036 - val_loss: 0.3356 - val_pred_loss: 0.3356 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8424 - lr: 1.0000e-04\n",
            "Epoch 469/500\n",
            "113/113 [==============================] - 2s 21ms/step - loss: 0.5683 - pred_loss: 0.2369 - tf.where_10_loss: 0.0066 - pred_sparse_categorical_accuracy: 0.9064 - val_loss: 0.4265 - val_pred_loss: 0.4265 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 470/500\n",
            "113/113 [==============================] - 2s 20ms/step - loss: 0.5488 - pred_loss: 0.2278 - tf.where_10_loss: 0.0064 - pred_sparse_categorical_accuracy: 0.9056 - val_loss: 0.3378 - val_pred_loss: 0.3378 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8455 - lr: 1.0000e-04\n",
            "Epoch 471/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.5425 - pred_loss: 0.2253 - tf.where_10_loss: 0.0063 - pred_sparse_categorical_accuracy: 0.9045 - val_loss: 0.9312 - val_pred_loss: 0.9312 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6879 - lr: 1.0000e-04\n",
            "Epoch 472/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.5450 - pred_loss: 0.2298 - tf.where_10_loss: 0.0063 - pred_sparse_categorical_accuracy: 0.9050 - val_loss: 0.2804 - val_pred_loss: 0.2804 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8773 - lr: 1.0000e-04\n",
            "Epoch 473/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.5390 - pred_loss: 0.2272 - tf.where_10_loss: 0.0062 - pred_sparse_categorical_accuracy: 0.9045 - val_loss: 0.3089 - val_pred_loss: 0.3089 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8606 - lr: 1.0000e-04\n",
            "Epoch 474/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.5385 - pred_loss: 0.2268 - tf.where_10_loss: 0.0062 - pred_sparse_categorical_accuracy: 0.9045 - val_loss: 0.2841 - val_pred_loss: 0.2841 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8720 - lr: 1.0000e-04\n",
            "Epoch 475/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.5390 - pred_loss: 0.2272 - tf.where_10_loss: 0.0062 - pred_sparse_categorical_accuracy: 0.9103 - val_loss: 0.8027 - val_pred_loss: 0.8027 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7038 - lr: 1.0000e-04\n",
            "Epoch 476/500\n",
            "113/113 [==============================] - 2s 22ms/step - loss: 0.5330 - pred_loss: 0.2234 - tf.where_10_loss: 0.0062 - pred_sparse_categorical_accuracy: 0.9103 - val_loss: 0.2884 - val_pred_loss: 0.2884 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8727 - lr: 1.0000e-04\n",
            "Epoch 477/500\n",
            "113/113 [==============================] - 2s 21ms/step - loss: 0.5340 - pred_loss: 0.2274 - tf.where_10_loss: 0.0061 - pred_sparse_categorical_accuracy: 0.9075 - val_loss: 0.2524 - val_pred_loss: 0.2524 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8955 - lr: 1.0000e-04\n",
            "Epoch 478/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.5392 - pred_loss: 0.2288 - tf.where_10_loss: 0.0062 - pred_sparse_categorical_accuracy: 0.9056 - val_loss: 0.3427 - val_pred_loss: 0.3427 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8402 - lr: 1.0000e-04\n",
            "Epoch 479/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.5435 - pred_loss: 0.2321 - tf.where_10_loss: 0.0062 - pred_sparse_categorical_accuracy: 0.9042 - val_loss: 0.4859 - val_pred_loss: 0.4859 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7848 - lr: 1.0000e-04\n",
            "Epoch 480/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.5391 - pred_loss: 0.2216 - tf.where_10_loss: 0.0063 - pred_sparse_categorical_accuracy: 0.9131 - val_loss: 0.3388 - val_pred_loss: 0.3388 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8477 - lr: 1.0000e-04\n",
            "Epoch 481/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.5339 - pred_loss: 0.2314 - tf.where_10_loss: 0.0061 - pred_sparse_categorical_accuracy: 0.9053 - val_loss: 0.2733 - val_pred_loss: 0.2733 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8841 - lr: 1.0000e-04\n",
            "Epoch 482/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.5448 - pred_loss: 0.2285 - tf.where_10_loss: 0.0063 - pred_sparse_categorical_accuracy: 0.9061 - val_loss: 0.6299 - val_pred_loss: 0.6299 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7417 - lr: 1.0000e-04\n",
            "Epoch 483/500\n",
            "113/113 [==============================] - 2s 22ms/step - loss: 0.5480 - pred_loss: 0.2353 - tf.where_10_loss: 0.0063 - pred_sparse_categorical_accuracy: 0.9031 - val_loss: 0.3170 - val_pred_loss: 0.3170 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8576 - lr: 1.0000e-04\n",
            "Epoch 484/500\n",
            "113/113 [==============================] - 2s 21ms/step - loss: 0.5467 - pred_loss: 0.2369 - tf.where_10_loss: 0.0062 - pred_sparse_categorical_accuracy: 0.9009 - val_loss: 1.0457 - val_pred_loss: 1.0457 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6750 - lr: 1.0000e-04\n",
            "Epoch 485/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.5442 - pred_loss: 0.2248 - tf.where_10_loss: 0.0064 - pred_sparse_categorical_accuracy: 0.9089 - val_loss: 0.3486 - val_pred_loss: 0.3486 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8394 - lr: 1.0000e-04\n",
            "Epoch 486/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.5419 - pred_loss: 0.2295 - tf.where_10_loss: 0.0062 - pred_sparse_categorical_accuracy: 0.9064 - val_loss: 0.7600 - val_pred_loss: 0.7600 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7167 - lr: 1.0000e-04\n",
            "Epoch 487/500\n",
            "113/113 [==============================] - 2s 19ms/step - loss: 0.5421 - pred_loss: 0.2227 - tf.where_10_loss: 0.0064 - pred_sparse_categorical_accuracy: 0.9081 - val_loss: 0.2701 - val_pred_loss: 0.2701 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8879 - lr: 1.0000e-04\n",
            "Epoch 488/500\n",
            "113/113 [==============================] - 2s 19ms/step - loss: 0.5339 - pred_loss: 0.2248 - tf.where_10_loss: 0.0062 - pred_sparse_categorical_accuracy: 0.9147 - val_loss: 0.3955 - val_pred_loss: 0.3955 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8121 - lr: 1.0000e-04\n",
            "Epoch 489/500\n",
            "113/113 [==============================] - 2s 19ms/step - loss: 0.5366 - pred_loss: 0.2350 - tf.where_10_loss: 0.0060 - pred_sparse_categorical_accuracy: 0.9042 - val_loss: 0.8120 - val_pred_loss: 0.8120 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7068 - lr: 1.0000e-04\n",
            "Epoch 490/500\n",
            "113/113 [==============================] - 3s 22ms/step - loss: 0.5508 - pred_loss: 0.2286 - tf.where_10_loss: 0.0064 - pred_sparse_categorical_accuracy: 0.9072 - val_loss: 0.4288 - val_pred_loss: 0.4288 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8076 - lr: 1.0000e-04\n",
            "Epoch 491/500\n",
            "113/113 [==============================] - 3s 24ms/step - loss: 0.5413 - pred_loss: 0.2321 - tf.where_10_loss: 0.0062 - pred_sparse_categorical_accuracy: 0.9025 - val_loss: 0.4106 - val_pred_loss: 0.4106 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8136 - lr: 1.0000e-04\n",
            "Epoch 492/500\n",
            "113/113 [==============================] - 2s 19ms/step - loss: 0.5315 - pred_loss: 0.2269 - tf.where_10_loss: 0.0061 - pred_sparse_categorical_accuracy: 0.9034 - val_loss: 0.2938 - val_pred_loss: 0.2938 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8614 - lr: 1.0000e-04\n",
            "Epoch 493/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.5556 - pred_loss: 0.2303 - tf.where_10_loss: 0.0065 - pred_sparse_categorical_accuracy: 0.9059 - val_loss: 0.4308 - val_pred_loss: 0.4308 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 494/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.5410 - pred_loss: 0.2261 - tf.where_10_loss: 0.0063 - pred_sparse_categorical_accuracy: 0.9106 - val_loss: 0.3472 - val_pred_loss: 0.3472 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8447 - lr: 1.0000e-04\n",
            "Epoch 495/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.5247 - pred_loss: 0.2214 - tf.where_10_loss: 0.0061 - pred_sparse_categorical_accuracy: 0.9103 - val_loss: 1.0817 - val_pred_loss: 1.0817 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6848 - lr: 1.0000e-04\n",
            "Epoch 496/500\n",
            "113/113 [==============================] - 4s 40ms/step - loss: 0.5442 - pred_loss: 0.2247 - tf.where_10_loss: 0.0064 - pred_sparse_categorical_accuracy: 0.9064 - val_loss: 0.2622 - val_pred_loss: 0.2622 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8879 - lr: 1.0000e-04\n",
            "Epoch 497/500\n",
            "113/113 [==============================] - 4s 35ms/step - loss: 0.5532 - pred_loss: 0.2360 - tf.where_10_loss: 0.0063 - pred_sparse_categorical_accuracy: 0.9014 - val_loss: 1.6030 - val_pred_loss: 1.6030 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6553 - lr: 1.0000e-04\n",
            "Epoch 498/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.5266 - pred_loss: 0.2273 - tf.where_10_loss: 0.0060 - pred_sparse_categorical_accuracy: 0.9017 - val_loss: 0.9193 - val_pred_loss: 0.9193 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6902 - lr: 1.0000e-04\n",
            "Epoch 499/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.5487 - pred_loss: 0.2362 - tf.where_10_loss: 0.0062 - pred_sparse_categorical_accuracy: 0.8953 - val_loss: 0.5904 - val_pred_loss: 0.5904 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7515 - lr: 1.0000e-04\n",
            "Epoch 500/500\n",
            "113/113 [==============================] - 3s 26ms/step - loss: 0.5503 - pred_loss: 0.2255 - tf.where_10_loss: 0.0065 - pred_sparse_categorical_accuracy: 0.9072 - val_loss: 0.3467 - val_pred_loss: 0.3467 - val_tf.where_10_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8417 - lr: 1.0000e-04\n"
          ]
        }
      ],
      "source": [
        "epochs = 500\n",
        "batch_size = 32\n",
        "\n",
        "callbacks = [keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", \n",
        "                                               factor=0.5, \n",
        "                                               patience=20, \n",
        "                                               min_lr=0.0001)]\n",
        "\n",
        "output1 = 'pred'\n",
        "output2 = 'tf.where_10'\n",
        "losses = {\n",
        "\toutput1:\"sparse_categorical_crossentropy\",\n",
        "\toutput2:\"mse\",\n",
        "}\n",
        "metrics = {\n",
        "    output1:\"sparse_categorical_accuracy\",\n",
        "}\n",
        "lossWeights = {output1: 1.0, output2: 50.0}\n",
        "\n",
        "model.compile(optimizer=\"adam\",\n",
        "              loss=losses, loss_weights=lossWeights,\n",
        "              metrics=metrics)\n",
        "\n",
        "history = model.fit(x=x_train_input,\n",
        "                    y={output1: y_train, output2: x_train_target},\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    callbacks=callbacks,\n",
        "                    validation_data=(x_test_input, {output1: y_test}),\n",
        "                    verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nWAapOSFYiVP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vOL_ndnmsOjp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 500\n",
        "batch_size = 32\n",
        "\n",
        "callbacks = [keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", \n",
        "                                               factor=0.5, \n",
        "                                               patience=20, \n",
        "                                               min_lr=0.0001)]\n",
        "\n",
        "output1 = 'pred'\n",
        "output2 = 'tf.where_13'\n",
        "losses = {\n",
        "\toutput1:\"sparse_categorical_crossentropy\",\n",
        "\toutput2:\"mse\",\n",
        "}\n",
        "metrics = {\n",
        "    output1:\"sparse_categorical_accuracy\",\n",
        "}\n",
        "lossWeights = {output1: 1.0, output2: 50.0}\n",
        "\n",
        "model.compile(optimizer=\"adam\",\n",
        "              loss=losses, loss_weights=lossWeights,\n",
        "              metrics=metrics)\n",
        "\n",
        "history = model.fit(x=x_train_input,\n",
        "                    y={output1: y_train, output2: x_train_target},\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    callbacks=callbacks,\n",
        "                    validation_data=(x_test_input, {output1: y_test}),\n",
        "                    verbose=1)"
      ],
      "metadata": {
        "id": "whHQEyVqDSYj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9edc151-8414-4e9d-81ea-59003a41134d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "113/113 [==============================] - 9s 21ms/step - loss: 18.8825 - pred_loss: 0.6747 - tf.where_13_loss: 0.3642 - pred_sparse_categorical_accuracy: 0.5607 - val_loss: 0.9828 - val_pred_loss: 0.9828 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.4841 - lr: 0.0010\n",
            "Epoch 2/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 11.9417 - pred_loss: 0.6403 - tf.where_13_loss: 0.2260 - pred_sparse_categorical_accuracy: 0.6026 - val_loss: 1.0042 - val_pred_loss: 1.0042 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.4841 - lr: 0.0010\n",
            "Epoch 3/500\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 10.3309 - pred_loss: 0.6146 - tf.where_13_loss: 0.1943 - pred_sparse_categorical_accuracy: 0.6532 - val_loss: 0.6692 - val_pred_loss: 0.6692 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.5909 - lr: 0.0010\n",
            "Epoch 4/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 9.4044 - pred_loss: 0.5852 - tf.where_13_loss: 0.1764 - pred_sparse_categorical_accuracy: 0.6862 - val_loss: 0.6026 - val_pred_loss: 0.6026 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7174 - lr: 0.0010\n",
            "Epoch 5/500\n",
            "113/113 [==============================] - 2s 22ms/step - loss: 8.8880 - pred_loss: 0.5660 - tf.where_13_loss: 0.1664 - pred_sparse_categorical_accuracy: 0.7015 - val_loss: 0.5340 - val_pred_loss: 0.5340 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7333 - lr: 0.0010\n",
            "Epoch 6/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 8.5762 - pred_loss: 0.5371 - tf.where_13_loss: 0.1608 - pred_sparse_categorical_accuracy: 0.7173 - val_loss: 0.5083 - val_pred_loss: 0.5083 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7508 - lr: 0.0010\n",
            "Epoch 7/500\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 8.3495 - pred_loss: 0.5239 - tf.where_13_loss: 0.1565 - pred_sparse_categorical_accuracy: 0.7201 - val_loss: 0.5176 - val_pred_loss: 0.5176 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7250 - lr: 0.0010\n",
            "Epoch 8/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 8.1772 - pred_loss: 0.5079 - tf.where_13_loss: 0.1534 - pred_sparse_categorical_accuracy: 0.7406 - val_loss: 0.5150 - val_pred_loss: 0.5150 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7364 - lr: 0.0010\n",
            "Epoch 9/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 7.9701 - pred_loss: 0.5005 - tf.where_13_loss: 0.1494 - pred_sparse_categorical_accuracy: 0.7345 - val_loss: 0.8370 - val_pred_loss: 0.8370 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.5886 - lr: 0.0010\n",
            "Epoch 10/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 7.7132 - pred_loss: 0.4907 - tf.where_13_loss: 0.1444 - pred_sparse_categorical_accuracy: 0.7365 - val_loss: 0.5373 - val_pred_loss: 0.5373 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7288 - lr: 0.0010\n",
            "Epoch 11/500\n",
            "113/113 [==============================] - 2s 19ms/step - loss: 7.1246 - pred_loss: 0.4771 - tf.where_13_loss: 0.1329 - pred_sparse_categorical_accuracy: 0.7448 - val_loss: 0.7325 - val_pred_loss: 0.7325 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6538 - lr: 0.0010\n",
            "Epoch 12/500\n",
            "113/113 [==============================] - 2s 20ms/step - loss: 6.4664 - pred_loss: 0.4727 - tf.where_13_loss: 0.1199 - pred_sparse_categorical_accuracy: 0.7570 - val_loss: 3.0874 - val_pred_loss: 3.0874 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.4848 - lr: 0.0010\n",
            "Epoch 13/500\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 5.5064 - pred_loss: 0.4569 - tf.where_13_loss: 0.1010 - pred_sparse_categorical_accuracy: 0.7662 - val_loss: 2.1943 - val_pred_loss: 2.1943 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.4886 - lr: 0.0010\n",
            "Epoch 14/500\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 5.0250 - pred_loss: 0.4612 - tf.where_13_loss: 0.0913 - pred_sparse_categorical_accuracy: 0.7623 - val_loss: 2.0255 - val_pred_loss: 2.0255 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.4917 - lr: 0.0010\n",
            "Epoch 15/500\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 4.4288 - pred_loss: 0.4587 - tf.where_13_loss: 0.0794 - pred_sparse_categorical_accuracy: 0.7667 - val_loss: 1.7061 - val_pred_loss: 1.7061 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.4886 - lr: 0.0010\n",
            "Epoch 16/500\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 4.0089 - pred_loss: 0.4427 - tf.where_13_loss: 0.0713 - pred_sparse_categorical_accuracy: 0.7762 - val_loss: 1.1309 - val_pred_loss: 1.1309 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.5311 - lr: 0.0010\n",
            "Epoch 17/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 3.6356 - pred_loss: 0.4397 - tf.where_13_loss: 0.0639 - pred_sparse_categorical_accuracy: 0.7723 - val_loss: 0.8165 - val_pred_loss: 0.8165 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6644 - lr: 0.0010\n",
            "Epoch 18/500\n",
            "113/113 [==============================] - 2s 21ms/step - loss: 3.5868 - pred_loss: 0.4420 - tf.where_13_loss: 0.0629 - pred_sparse_categorical_accuracy: 0.7703 - val_loss: 1.2435 - val_pred_loss: 1.2435 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.5788 - lr: 0.0010\n",
            "Epoch 19/500\n",
            "113/113 [==============================] - 2s 21ms/step - loss: 3.5545 - pred_loss: 0.4435 - tf.where_13_loss: 0.0622 - pred_sparse_categorical_accuracy: 0.7767 - val_loss: 0.4471 - val_pred_loss: 0.4471 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7818 - lr: 0.0010\n",
            "Epoch 20/500\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 3.3160 - pred_loss: 0.4339 - tf.where_13_loss: 0.0576 - pred_sparse_categorical_accuracy: 0.7773 - val_loss: 0.4644 - val_pred_loss: 0.4644 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7636 - lr: 0.0010\n",
            "Epoch 21/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 3.3063 - pred_loss: 0.4361 - tf.where_13_loss: 0.0574 - pred_sparse_categorical_accuracy: 0.7801 - val_loss: 0.4448 - val_pred_loss: 0.4448 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7439 - lr: 0.0010\n",
            "Epoch 22/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 3.1458 - pred_loss: 0.4381 - tf.where_13_loss: 0.0542 - pred_sparse_categorical_accuracy: 0.7770 - val_loss: 0.5476 - val_pred_loss: 0.5476 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6917 - lr: 0.0010\n",
            "Epoch 23/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 3.0401 - pred_loss: 0.4291 - tf.where_13_loss: 0.0522 - pred_sparse_categorical_accuracy: 0.7848 - val_loss: 0.4693 - val_pred_loss: 0.4693 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7250 - lr: 0.0010\n",
            "Epoch 24/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 2.9898 - pred_loss: 0.4409 - tf.where_13_loss: 0.0510 - pred_sparse_categorical_accuracy: 0.7759 - val_loss: 0.4862 - val_pred_loss: 0.4862 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7242 - lr: 0.0010\n",
            "Epoch 25/500\n",
            "113/113 [==============================] - 3s 23ms/step - loss: 2.6026 - pred_loss: 0.4251 - tf.where_13_loss: 0.0435 - pred_sparse_categorical_accuracy: 0.7848 - val_loss: 0.4120 - val_pred_loss: 0.4120 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7803 - lr: 0.0010\n",
            "Epoch 26/500\n",
            "113/113 [==============================] - 2s 19ms/step - loss: 2.7360 - pred_loss: 0.4269 - tf.where_13_loss: 0.0462 - pred_sparse_categorical_accuracy: 0.7873 - val_loss: 0.4091 - val_pred_loss: 0.4091 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7848 - lr: 0.0010\n",
            "Epoch 27/500\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 2.6423 - pred_loss: 0.4290 - tf.where_13_loss: 0.0443 - pred_sparse_categorical_accuracy: 0.7851 - val_loss: 0.4544 - val_pred_loss: 0.4544 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7273 - lr: 0.0010\n",
            "Epoch 28/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 2.6631 - pred_loss: 0.4273 - tf.where_13_loss: 0.0447 - pred_sparse_categorical_accuracy: 0.7817 - val_loss: 0.4641 - val_pred_loss: 0.4641 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7250 - lr: 0.0010\n",
            "Epoch 29/500\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 2.4995 - pred_loss: 0.4168 - tf.where_13_loss: 0.0417 - pred_sparse_categorical_accuracy: 0.7917 - val_loss: 0.3851 - val_pred_loss: 0.3851 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8152 - lr: 0.0010\n",
            "Epoch 30/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 2.5099 - pred_loss: 0.4219 - tf.where_13_loss: 0.0418 - pred_sparse_categorical_accuracy: 0.7873 - val_loss: 0.4027 - val_pred_loss: 0.4027 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8030 - lr: 0.0010\n",
            "Epoch 31/500\n",
            "113/113 [==============================] - 2s 20ms/step - loss: 2.3547 - pred_loss: 0.4180 - tf.where_13_loss: 0.0387 - pred_sparse_categorical_accuracy: 0.7878 - val_loss: 0.9626 - val_pred_loss: 0.9626 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6038 - lr: 0.0010\n",
            "Epoch 32/500\n",
            "113/113 [==============================] - 2s 21ms/step - loss: 2.3526 - pred_loss: 0.4149 - tf.where_13_loss: 0.0388 - pred_sparse_categorical_accuracy: 0.7876 - val_loss: 0.4392 - val_pred_loss: 0.4392 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7371 - lr: 0.0010\n",
            "Epoch 33/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 2.3451 - pred_loss: 0.4195 - tf.where_13_loss: 0.0385 - pred_sparse_categorical_accuracy: 0.7853 - val_loss: 0.3746 - val_pred_loss: 0.3746 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8227 - lr: 0.0010\n",
            "Epoch 34/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 2.1467 - pred_loss: 0.4093 - tf.where_13_loss: 0.0347 - pred_sparse_categorical_accuracy: 0.7995 - val_loss: 0.4572 - val_pred_loss: 0.4572 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7432 - lr: 0.0010\n",
            "Epoch 35/500\n",
            "113/113 [==============================] - 2s 20ms/step - loss: 2.0445 - pred_loss: 0.4101 - tf.where_13_loss: 0.0327 - pred_sparse_categorical_accuracy: 0.8095 - val_loss: 0.4107 - val_pred_loss: 0.4107 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7947 - lr: 0.0010\n",
            "Epoch 36/500\n",
            "113/113 [==============================] - 3s 24ms/step - loss: 1.9713 - pred_loss: 0.4000 - tf.where_13_loss: 0.0314 - pred_sparse_categorical_accuracy: 0.8059 - val_loss: 0.4036 - val_pred_loss: 0.4036 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8053 - lr: 0.0010\n",
            "Epoch 37/500\n",
            "113/113 [==============================] - 2s 20ms/step - loss: 2.0689 - pred_loss: 0.4053 - tf.where_13_loss: 0.0333 - pred_sparse_categorical_accuracy: 0.7937 - val_loss: 0.4224 - val_pred_loss: 0.4224 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7561 - lr: 0.0010\n",
            "Epoch 38/500\n",
            "113/113 [==============================] - 2s 21ms/step - loss: 1.9157 - pred_loss: 0.4136 - tf.where_13_loss: 0.0300 - pred_sparse_categorical_accuracy: 0.7995 - val_loss: 0.5852 - val_pred_loss: 0.5852 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6977 - lr: 0.0010\n",
            "Epoch 39/500\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 1.8388 - pred_loss: 0.4040 - tf.where_13_loss: 0.0287 - pred_sparse_categorical_accuracy: 0.8001 - val_loss: 2.0370 - val_pred_loss: 2.0370 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.4970 - lr: 0.0010\n",
            "Epoch 40/500\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 1.8557 - pred_loss: 0.4022 - tf.where_13_loss: 0.0291 - pred_sparse_categorical_accuracy: 0.7995 - val_loss: 0.4193 - val_pred_loss: 0.4193 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7871 - lr: 0.0010\n",
            "Epoch 41/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 1.9051 - pred_loss: 0.4036 - tf.where_13_loss: 0.0300 - pred_sparse_categorical_accuracy: 0.7978 - val_loss: 0.3691 - val_pred_loss: 0.3691 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8227 - lr: 0.0010\n",
            "Epoch 42/500\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 1.6993 - pred_loss: 0.3924 - tf.where_13_loss: 0.0261 - pred_sparse_categorical_accuracy: 0.8045 - val_loss: 0.5778 - val_pred_loss: 0.5778 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7311 - lr: 0.0010\n",
            "Epoch 43/500\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 1.7577 - pred_loss: 0.3982 - tf.where_13_loss: 0.0272 - pred_sparse_categorical_accuracy: 0.8020 - val_loss: 0.6358 - val_pred_loss: 0.6358 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6515 - lr: 0.0010\n",
            "Epoch 44/500\n",
            "113/113 [==============================] - 2s 21ms/step - loss: 1.6462 - pred_loss: 0.3950 - tf.where_13_loss: 0.0250 - pred_sparse_categorical_accuracy: 0.7973 - val_loss: 0.3900 - val_pred_loss: 0.3900 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8008 - lr: 0.0010\n",
            "Epoch 45/500\n",
            "113/113 [==============================] - 2s 21ms/step - loss: 1.5282 - pred_loss: 0.3970 - tf.where_13_loss: 0.0226 - pred_sparse_categorical_accuracy: 0.7987 - val_loss: 0.8018 - val_pred_loss: 0.8018 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6235 - lr: 0.0010\n",
            "Epoch 46/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 1.8113 - pred_loss: 0.4011 - tf.where_13_loss: 0.0282 - pred_sparse_categorical_accuracy: 0.8003 - val_loss: 0.4319 - val_pred_loss: 0.4319 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7788 - lr: 0.0010\n",
            "Epoch 47/500\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 1.5514 - pred_loss: 0.3884 - tf.where_13_loss: 0.0233 - pred_sparse_categorical_accuracy: 0.8078 - val_loss: 0.3826 - val_pred_loss: 0.3826 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7924 - lr: 0.0010\n",
            "Epoch 48/500\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 1.5734 - pred_loss: 0.3863 - tf.where_13_loss: 0.0237 - pred_sparse_categorical_accuracy: 0.8064 - val_loss: 0.4205 - val_pred_loss: 0.4205 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7879 - lr: 0.0010\n",
            "Epoch 49/500\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 1.3941 - pred_loss: 0.3976 - tf.where_13_loss: 0.0199 - pred_sparse_categorical_accuracy: 0.8017 - val_loss: 0.5735 - val_pred_loss: 0.5735 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7220 - lr: 0.0010\n",
            "Epoch 50/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 1.4612 - pred_loss: 0.3908 - tf.where_13_loss: 0.0214 - pred_sparse_categorical_accuracy: 0.8112 - val_loss: 0.4191 - val_pred_loss: 0.4191 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7803 - lr: 0.0010\n",
            "Epoch 51/500\n",
            "113/113 [==============================] - 3s 23ms/step - loss: 1.5714 - pred_loss: 0.3883 - tf.where_13_loss: 0.0237 - pred_sparse_categorical_accuracy: 0.8092 - val_loss: 0.4763 - val_pred_loss: 0.4763 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7515 - lr: 0.0010\n",
            "Epoch 52/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 1.4705 - pred_loss: 0.3847 - tf.where_13_loss: 0.0217 - pred_sparse_categorical_accuracy: 0.8134 - val_loss: 0.4490 - val_pred_loss: 0.4490 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7394 - lr: 0.0010\n",
            "Epoch 53/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 1.5254 - pred_loss: 0.3854 - tf.where_13_loss: 0.0228 - pred_sparse_categorical_accuracy: 0.8056 - val_loss: 0.6478 - val_pred_loss: 0.6478 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6523 - lr: 0.0010\n",
            "Epoch 54/500\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 1.3543 - pred_loss: 0.3791 - tf.where_13_loss: 0.0195 - pred_sparse_categorical_accuracy: 0.8214 - val_loss: 0.4635 - val_pred_loss: 0.4635 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7902 - lr: 0.0010\n",
            "Epoch 55/500\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 1.3432 - pred_loss: 0.3822 - tf.where_13_loss: 0.0192 - pred_sparse_categorical_accuracy: 0.8167 - val_loss: 0.3916 - val_pred_loss: 0.3916 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8030 - lr: 0.0010\n",
            "Epoch 56/500\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 1.3309 - pred_loss: 0.3738 - tf.where_13_loss: 0.0191 - pred_sparse_categorical_accuracy: 0.8112 - val_loss: 0.3870 - val_pred_loss: 0.3870 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7742 - lr: 0.0010\n",
            "Epoch 57/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 1.3437 - pred_loss: 0.3747 - tf.where_13_loss: 0.0194 - pred_sparse_categorical_accuracy: 0.8198 - val_loss: 0.5039 - val_pred_loss: 0.5039 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7242 - lr: 0.0010\n",
            "Epoch 58/500\n",
            "113/113 [==============================] - 3s 22ms/step - loss: 1.2761 - pred_loss: 0.3763 - tf.where_13_loss: 0.0180 - pred_sparse_categorical_accuracy: 0.8173 - val_loss: 0.4615 - val_pred_loss: 0.4615 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7462 - lr: 0.0010\n",
            "Epoch 59/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 1.2796 - pred_loss: 0.3728 - tf.where_13_loss: 0.0181 - pred_sparse_categorical_accuracy: 0.8231 - val_loss: 0.5808 - val_pred_loss: 0.5808 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7129 - lr: 0.0010\n",
            "Epoch 60/500\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 1.3624 - pred_loss: 0.3827 - tf.where_13_loss: 0.0196 - pred_sparse_categorical_accuracy: 0.8134 - val_loss: 0.3695 - val_pred_loss: 0.3695 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7962 - lr: 0.0010\n",
            "Epoch 61/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 1.3007 - pred_loss: 0.3702 - tf.where_13_loss: 0.0186 - pred_sparse_categorical_accuracy: 0.8273 - val_loss: 0.4211 - val_pred_loss: 0.4211 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7939 - lr: 0.0010\n",
            "Epoch 62/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 1.0172 - pred_loss: 0.3527 - tf.where_13_loss: 0.0133 - pred_sparse_categorical_accuracy: 0.8317 - val_loss: 0.5043 - val_pred_loss: 0.5043 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7250 - lr: 5.0000e-04\n",
            "Epoch 63/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 1.0001 - pred_loss: 0.3589 - tf.where_13_loss: 0.0128 - pred_sparse_categorical_accuracy: 0.8334 - val_loss: 0.3694 - val_pred_loss: 0.3694 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7826 - lr: 5.0000e-04\n",
            "Epoch 64/500\n",
            "113/113 [==============================] - 2s 21ms/step - loss: 0.9981 - pred_loss: 0.3553 - tf.where_13_loss: 0.0129 - pred_sparse_categorical_accuracy: 0.8320 - val_loss: 0.4987 - val_pred_loss: 0.4987 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7227 - lr: 5.0000e-04\n",
            "Epoch 65/500\n",
            "113/113 [==============================] - 2s 21ms/step - loss: 1.0033 - pred_loss: 0.3497 - tf.where_13_loss: 0.0131 - pred_sparse_categorical_accuracy: 0.8323 - val_loss: 0.3964 - val_pred_loss: 0.3964 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8000 - lr: 5.0000e-04\n",
            "Epoch 66/500\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 0.9808 - pred_loss: 0.3586 - tf.where_13_loss: 0.0124 - pred_sparse_categorical_accuracy: 0.8339 - val_loss: 0.4663 - val_pred_loss: 0.4663 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7348 - lr: 5.0000e-04\n",
            "Epoch 67/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.9585 - pred_loss: 0.3512 - tf.where_13_loss: 0.0121 - pred_sparse_categorical_accuracy: 0.8384 - val_loss: 0.5303 - val_pred_loss: 0.5303 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7159 - lr: 5.0000e-04\n",
            "Epoch 68/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.9965 - pred_loss: 0.3632 - tf.where_13_loss: 0.0127 - pred_sparse_categorical_accuracy: 0.8306 - val_loss: 0.4938 - val_pred_loss: 0.4938 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7311 - lr: 5.0000e-04\n",
            "Epoch 69/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.9793 - pred_loss: 0.3551 - tf.where_13_loss: 0.0125 - pred_sparse_categorical_accuracy: 0.8295 - val_loss: 0.4638 - val_pred_loss: 0.4638 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7371 - lr: 5.0000e-04\n",
            "Epoch 70/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.9530 - pred_loss: 0.3492 - tf.where_13_loss: 0.0121 - pred_sparse_categorical_accuracy: 0.8395 - val_loss: 0.3663 - val_pred_loss: 0.3663 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7894 - lr: 5.0000e-04\n",
            "Epoch 71/500\n",
            "113/113 [==============================] - 2s 20ms/step - loss: 1.0650 - pred_loss: 0.3556 - tf.where_13_loss: 0.0142 - pred_sparse_categorical_accuracy: 0.8314 - val_loss: 0.4976 - val_pred_loss: 0.4976 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7333 - lr: 5.0000e-04\n",
            "Epoch 72/500\n",
            "113/113 [==============================] - 2s 19ms/step - loss: 0.9315 - pred_loss: 0.3477 - tf.where_13_loss: 0.0117 - pred_sparse_categorical_accuracy: 0.8409 - val_loss: 0.5391 - val_pred_loss: 0.5391 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7205 - lr: 5.0000e-04\n",
            "Epoch 73/500\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 0.9236 - pred_loss: 0.3379 - tf.where_13_loss: 0.0117 - pred_sparse_categorical_accuracy: 0.8500 - val_loss: 0.3485 - val_pred_loss: 0.3485 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8311 - lr: 5.0000e-04\n",
            "Epoch 74/500\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 0.9368 - pred_loss: 0.3442 - tf.where_13_loss: 0.0119 - pred_sparse_categorical_accuracy: 0.8434 - val_loss: 0.4726 - val_pred_loss: 0.4726 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7470 - lr: 5.0000e-04\n",
            "Epoch 75/500\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 0.9055 - pred_loss: 0.3472 - tf.where_13_loss: 0.0112 - pred_sparse_categorical_accuracy: 0.8412 - val_loss: 0.5897 - val_pred_loss: 0.5897 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7030 - lr: 5.0000e-04\n",
            "Epoch 76/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.9051 - pred_loss: 0.3473 - tf.where_13_loss: 0.0112 - pred_sparse_categorical_accuracy: 0.8414 - val_loss: 0.3697 - val_pred_loss: 0.3697 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8023 - lr: 5.0000e-04\n",
            "Epoch 77/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.9334 - pred_loss: 0.3471 - tf.where_13_loss: 0.0117 - pred_sparse_categorical_accuracy: 0.8325 - val_loss: 0.3606 - val_pred_loss: 0.3606 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8356 - lr: 5.0000e-04\n",
            "Epoch 78/500\n",
            "113/113 [==============================] - 2s 21ms/step - loss: 0.9647 - pred_loss: 0.3607 - tf.where_13_loss: 0.0121 - pred_sparse_categorical_accuracy: 0.8287 - val_loss: 0.3726 - val_pred_loss: 0.3726 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7811 - lr: 5.0000e-04\n",
            "Epoch 79/500\n",
            "113/113 [==============================] - 2s 19ms/step - loss: 0.8820 - pred_loss: 0.3399 - tf.where_13_loss: 0.0108 - pred_sparse_categorical_accuracy: 0.8423 - val_loss: 0.7168 - val_pred_loss: 0.7168 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6939 - lr: 5.0000e-04\n",
            "Epoch 80/500\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 0.8475 - pred_loss: 0.3447 - tf.where_13_loss: 0.0101 - pred_sparse_categorical_accuracy: 0.8403 - val_loss: 0.7257 - val_pred_loss: 0.7257 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6992 - lr: 5.0000e-04\n",
            "Epoch 81/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.9055 - pred_loss: 0.3355 - tf.where_13_loss: 0.0114 - pred_sparse_categorical_accuracy: 0.8484 - val_loss: 0.3625 - val_pred_loss: 0.3625 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8174 - lr: 5.0000e-04\n",
            "Epoch 82/500\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 0.8813 - pred_loss: 0.3275 - tf.where_13_loss: 0.0111 - pred_sparse_categorical_accuracy: 0.8548 - val_loss: 0.5401 - val_pred_loss: 0.5401 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7220 - lr: 5.0000e-04\n",
            "Epoch 83/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.9342 - pred_loss: 0.3432 - tf.where_13_loss: 0.0118 - pred_sparse_categorical_accuracy: 0.8423 - val_loss: 0.6072 - val_pred_loss: 0.6072 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6955 - lr: 5.0000e-04\n",
            "Epoch 84/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.8661 - pred_loss: 0.3349 - tf.where_13_loss: 0.0106 - pred_sparse_categorical_accuracy: 0.8503 - val_loss: 1.0959 - val_pred_loss: 1.0959 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6114 - lr: 5.0000e-04\n",
            "Epoch 85/500\n",
            "113/113 [==============================] - 2s 21ms/step - loss: 0.8171 - pred_loss: 0.3267 - tf.where_13_loss: 0.0098 - pred_sparse_categorical_accuracy: 0.8498 - val_loss: 0.5810 - val_pred_loss: 0.5810 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7136 - lr: 5.0000e-04\n",
            "Epoch 86/500\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 0.8519 - pred_loss: 0.3306 - tf.where_13_loss: 0.0104 - pred_sparse_categorical_accuracy: 0.8525 - val_loss: 0.7033 - val_pred_loss: 0.7033 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7076 - lr: 5.0000e-04\n",
            "Epoch 87/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.9161 - pred_loss: 0.3351 - tf.where_13_loss: 0.0116 - pred_sparse_categorical_accuracy: 0.8478 - val_loss: 0.3145 - val_pred_loss: 0.3145 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8614 - lr: 5.0000e-04\n",
            "Epoch 88/500\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 0.8395 - pred_loss: 0.3281 - tf.where_13_loss: 0.0102 - pred_sparse_categorical_accuracy: 0.8611 - val_loss: 1.4719 - val_pred_loss: 1.4719 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.5712 - lr: 5.0000e-04\n",
            "Epoch 89/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.8532 - pred_loss: 0.3273 - tf.where_13_loss: 0.0105 - pred_sparse_categorical_accuracy: 0.8548 - val_loss: 0.8243 - val_pred_loss: 0.8243 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6818 - lr: 5.0000e-04\n",
            "Epoch 90/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.8003 - pred_loss: 0.3278 - tf.where_13_loss: 0.0094 - pred_sparse_categorical_accuracy: 0.8578 - val_loss: 0.3860 - val_pred_loss: 0.3860 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7924 - lr: 5.0000e-04\n",
            "Epoch 91/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.8313 - pred_loss: 0.3186 - tf.where_13_loss: 0.0103 - pred_sparse_categorical_accuracy: 0.8656 - val_loss: 0.6114 - val_pred_loss: 0.6114 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7182 - lr: 5.0000e-04\n",
            "Epoch 92/500\n",
            "113/113 [==============================] - 2s 20ms/step - loss: 0.7810 - pred_loss: 0.3255 - tf.where_13_loss: 0.0091 - pred_sparse_categorical_accuracy: 0.8453 - val_loss: 0.8259 - val_pred_loss: 0.8259 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6992 - lr: 5.0000e-04\n",
            "Epoch 93/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.7619 - pred_loss: 0.3137 - tf.where_13_loss: 0.0090 - pred_sparse_categorical_accuracy: 0.8670 - val_loss: 0.9991 - val_pred_loss: 0.9991 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6659 - lr: 5.0000e-04\n",
            "Epoch 94/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.7910 - pred_loss: 0.3221 - tf.where_13_loss: 0.0094 - pred_sparse_categorical_accuracy: 0.8578 - val_loss: 0.4006 - val_pred_loss: 0.4006 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7818 - lr: 5.0000e-04\n",
            "Epoch 95/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.7763 - pred_loss: 0.3160 - tf.where_13_loss: 0.0092 - pred_sparse_categorical_accuracy: 0.8648 - val_loss: 1.1998 - val_pred_loss: 1.1998 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6477 - lr: 5.0000e-04\n",
            "Epoch 96/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.7440 - pred_loss: 0.3185 - tf.where_13_loss: 0.0085 - pred_sparse_categorical_accuracy: 0.8639 - val_loss: 0.3238 - val_pred_loss: 0.3238 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8364 - lr: 5.0000e-04\n",
            "Epoch 97/500\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 0.8603 - pred_loss: 0.3200 - tf.where_13_loss: 0.0108 - pred_sparse_categorical_accuracy: 0.8592 - val_loss: 0.3689 - val_pred_loss: 0.3689 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8106 - lr: 5.0000e-04\n",
            "Epoch 98/500\n",
            "113/113 [==============================] - 2s 19ms/step - loss: 0.8359 - pred_loss: 0.3185 - tf.where_13_loss: 0.0103 - pred_sparse_categorical_accuracy: 0.8575 - val_loss: 0.4983 - val_pred_loss: 0.4983 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7379 - lr: 5.0000e-04\n",
            "Epoch 99/500\n",
            "113/113 [==============================] - 2s 21ms/step - loss: 0.7888 - pred_loss: 0.3061 - tf.where_13_loss: 0.0097 - pred_sparse_categorical_accuracy: 0.8700 - val_loss: 0.3220 - val_pred_loss: 0.3220 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8515 - lr: 5.0000e-04\n",
            "Epoch 100/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.7312 - pred_loss: 0.3052 - tf.where_13_loss: 0.0085 - pred_sparse_categorical_accuracy: 0.8631 - val_loss: 1.9452 - val_pred_loss: 1.9452 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6174 - lr: 5.0000e-04\n",
            "Epoch 101/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.7765 - pred_loss: 0.3162 - tf.where_13_loss: 0.0092 - pred_sparse_categorical_accuracy: 0.8575 - val_loss: 0.3324 - val_pred_loss: 0.3324 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8258 - lr: 5.0000e-04\n",
            "Epoch 102/500\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 0.7154 - pred_loss: 0.3032 - tf.where_13_loss: 0.0082 - pred_sparse_categorical_accuracy: 0.8656 - val_loss: 0.5055 - val_pred_loss: 0.5055 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7386 - lr: 5.0000e-04\n",
            "Epoch 103/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.7320 - pred_loss: 0.3002 - tf.where_13_loss: 0.0086 - pred_sparse_categorical_accuracy: 0.8706 - val_loss: 0.3032 - val_pred_loss: 0.3032 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8674 - lr: 5.0000e-04\n",
            "Epoch 104/500\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 0.7309 - pred_loss: 0.3079 - tf.where_13_loss: 0.0085 - pred_sparse_categorical_accuracy: 0.8650 - val_loss: 1.0095 - val_pred_loss: 1.0095 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6583 - lr: 5.0000e-04\n",
            "Epoch 105/500\n",
            "113/113 [==============================] - 2s 19ms/step - loss: 0.7008 - pred_loss: 0.3080 - tf.where_13_loss: 0.0079 - pred_sparse_categorical_accuracy: 0.8620 - val_loss: 0.3045 - val_pred_loss: 0.3045 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8576 - lr: 5.0000e-04\n",
            "Epoch 106/500\n",
            "113/113 [==============================] - 2s 20ms/step - loss: 0.7794 - pred_loss: 0.3079 - tf.where_13_loss: 0.0094 - pred_sparse_categorical_accuracy: 0.8636 - val_loss: 0.7665 - val_pred_loss: 0.7665 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7068 - lr: 5.0000e-04\n",
            "Epoch 107/500\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 0.7071 - pred_loss: 0.3004 - tf.where_13_loss: 0.0081 - pred_sparse_categorical_accuracy: 0.8656 - val_loss: 1.5727 - val_pred_loss: 1.5727 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6273 - lr: 5.0000e-04\n",
            "Epoch 108/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.7133 - pred_loss: 0.3143 - tf.where_13_loss: 0.0080 - pred_sparse_categorical_accuracy: 0.8567 - val_loss: 1.7760 - val_pred_loss: 1.7760 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6462 - lr: 5.0000e-04\n",
            "Epoch 109/500\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 0.7191 - pred_loss: 0.3026 - tf.where_13_loss: 0.0083 - pred_sparse_categorical_accuracy: 0.8681 - val_loss: 0.3405 - val_pred_loss: 0.3405 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8212 - lr: 5.0000e-04\n",
            "Epoch 110/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.6952 - pred_loss: 0.2980 - tf.where_13_loss: 0.0079 - pred_sparse_categorical_accuracy: 0.8750 - val_loss: 0.3126 - val_pred_loss: 0.3126 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8644 - lr: 5.0000e-04\n",
            "Epoch 111/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.7113 - pred_loss: 0.3033 - tf.where_13_loss: 0.0082 - pred_sparse_categorical_accuracy: 0.8631 - val_loss: 1.9557 - val_pred_loss: 1.9557 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.5758 - lr: 5.0000e-04\n",
            "Epoch 112/500\n",
            "113/113 [==============================] - 2s 22ms/step - loss: 0.7431 - pred_loss: 0.3007 - tf.where_13_loss: 0.0088 - pred_sparse_categorical_accuracy: 0.8653 - val_loss: 0.4630 - val_pred_loss: 0.4630 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7606 - lr: 5.0000e-04\n",
            "Epoch 113/500\n",
            "113/113 [==============================] - 2s 19ms/step - loss: 0.7203 - pred_loss: 0.3069 - tf.where_13_loss: 0.0083 - pred_sparse_categorical_accuracy: 0.8675 - val_loss: 2.4388 - val_pred_loss: 2.4388 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.5235 - lr: 5.0000e-04\n",
            "Epoch 114/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.6963 - pred_loss: 0.2982 - tf.where_13_loss: 0.0080 - pred_sparse_categorical_accuracy: 0.8731 - val_loss: 0.4312 - val_pred_loss: 0.4312 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7689 - lr: 5.0000e-04\n",
            "Epoch 115/500\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 0.6960 - pred_loss: 0.2971 - tf.where_13_loss: 0.0080 - pred_sparse_categorical_accuracy: 0.8689 - val_loss: 0.4734 - val_pred_loss: 0.4734 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7470 - lr: 5.0000e-04\n",
            "Epoch 116/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.6694 - pred_loss: 0.2957 - tf.where_13_loss: 0.0075 - pred_sparse_categorical_accuracy: 0.8731 - val_loss: 1.5732 - val_pred_loss: 1.5732 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.5992 - lr: 5.0000e-04\n",
            "Epoch 117/500\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 0.7245 - pred_loss: 0.3005 - tf.where_13_loss: 0.0085 - pred_sparse_categorical_accuracy: 0.8667 - val_loss: 2.4644 - val_pred_loss: 2.4644 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.5758 - lr: 5.0000e-04\n",
            "Epoch 118/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.7803 - pred_loss: 0.3042 - tf.where_13_loss: 0.0095 - pred_sparse_categorical_accuracy: 0.8703 - val_loss: 0.3514 - val_pred_loss: 0.3514 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8265 - lr: 5.0000e-04\n",
            "Epoch 119/500\n",
            "113/113 [==============================] - 3s 22ms/step - loss: 0.6692 - pred_loss: 0.2864 - tf.where_13_loss: 0.0077 - pred_sparse_categorical_accuracy: 0.8775 - val_loss: 1.0751 - val_pred_loss: 1.0751 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6735 - lr: 5.0000e-04\n",
            "Epoch 120/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.7091 - pred_loss: 0.3008 - tf.where_13_loss: 0.0082 - pred_sparse_categorical_accuracy: 0.8686 - val_loss: 1.1807 - val_pred_loss: 1.1807 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6818 - lr: 5.0000e-04\n",
            "Epoch 121/500\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 0.6800 - pred_loss: 0.2984 - tf.where_13_loss: 0.0076 - pred_sparse_categorical_accuracy: 0.8736 - val_loss: 0.7040 - val_pred_loss: 0.7040 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6924 - lr: 5.0000e-04\n",
            "Epoch 122/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.6532 - pred_loss: 0.2913 - tf.where_13_loss: 0.0072 - pred_sparse_categorical_accuracy: 0.8728 - val_loss: 0.8855 - val_pred_loss: 0.8855 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6894 - lr: 5.0000e-04\n",
            "Epoch 123/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.6767 - pred_loss: 0.2911 - tf.where_13_loss: 0.0077 - pred_sparse_categorical_accuracy: 0.8773 - val_loss: 3.9815 - val_pred_loss: 3.9815 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.5068 - lr: 5.0000e-04\n",
            "Epoch 124/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.6285 - pred_loss: 0.2816 - tf.where_13_loss: 0.0069 - pred_sparse_categorical_accuracy: 0.8814 - val_loss: 0.2989 - val_pred_loss: 0.2989 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8614 - lr: 2.5000e-04\n",
            "Epoch 125/500\n",
            "113/113 [==============================] - 2s 20ms/step - loss: 0.6017 - pred_loss: 0.2792 - tf.where_13_loss: 0.0065 - pred_sparse_categorical_accuracy: 0.8828 - val_loss: 1.0286 - val_pred_loss: 1.0286 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6803 - lr: 2.5000e-04\n",
            "Epoch 126/500\n",
            "113/113 [==============================] - 2s 21ms/step - loss: 0.5923 - pred_loss: 0.2739 - tf.where_13_loss: 0.0064 - pred_sparse_categorical_accuracy: 0.8850 - val_loss: 1.0606 - val_pred_loss: 1.0606 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6705 - lr: 2.5000e-04\n",
            "Epoch 127/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.5873 - pred_loss: 0.2719 - tf.where_13_loss: 0.0063 - pred_sparse_categorical_accuracy: 0.8856 - val_loss: 1.0749 - val_pred_loss: 1.0749 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6765 - lr: 2.5000e-04\n",
            "Epoch 128/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.6235 - pred_loss: 0.2746 - tf.where_13_loss: 0.0070 - pred_sparse_categorical_accuracy: 0.8848 - val_loss: 0.8619 - val_pred_loss: 0.8619 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6977 - lr: 2.5000e-04\n",
            "Epoch 129/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.5962 - pred_loss: 0.2748 - tf.where_13_loss: 0.0064 - pred_sparse_categorical_accuracy: 0.8836 - val_loss: 4.4551 - val_pred_loss: 4.4551 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.5083 - lr: 2.5000e-04\n",
            "Epoch 130/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.5890 - pred_loss: 0.2683 - tf.where_13_loss: 0.0064 - pred_sparse_categorical_accuracy: 0.8864 - val_loss: 0.6808 - val_pred_loss: 0.6808 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7197 - lr: 2.5000e-04\n",
            "Epoch 131/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.5791 - pred_loss: 0.2719 - tf.where_13_loss: 0.0061 - pred_sparse_categorical_accuracy: 0.8875 - val_loss: 1.8512 - val_pred_loss: 1.8512 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6242 - lr: 2.5000e-04\n",
            "Epoch 132/500\n",
            "113/113 [==============================] - 2s 21ms/step - loss: 0.5860 - pred_loss: 0.2727 - tf.where_13_loss: 0.0063 - pred_sparse_categorical_accuracy: 0.8873 - val_loss: 2.2496 - val_pred_loss: 2.2496 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6250 - lr: 2.5000e-04\n",
            "Epoch 133/500\n",
            "113/113 [==============================] - 2s 19ms/step - loss: 0.6117 - pred_loss: 0.2802 - tf.where_13_loss: 0.0066 - pred_sparse_categorical_accuracy: 0.8814 - val_loss: 0.5609 - val_pred_loss: 0.5609 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7280 - lr: 2.5000e-04\n",
            "Epoch 134/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.6044 - pred_loss: 0.2816 - tf.where_13_loss: 0.0065 - pred_sparse_categorical_accuracy: 0.8748 - val_loss: 0.2773 - val_pred_loss: 0.2773 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8833 - lr: 2.5000e-04\n",
            "Epoch 135/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.5789 - pred_loss: 0.2626 - tf.where_13_loss: 0.0063 - pred_sparse_categorical_accuracy: 0.8903 - val_loss: 1.2531 - val_pred_loss: 1.2531 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6750 - lr: 2.5000e-04\n",
            "Epoch 136/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.5774 - pred_loss: 0.2705 - tf.where_13_loss: 0.0061 - pred_sparse_categorical_accuracy: 0.8884 - val_loss: 0.3991 - val_pred_loss: 0.3991 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7977 - lr: 2.5000e-04\n",
            "Epoch 137/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.5834 - pred_loss: 0.2679 - tf.where_13_loss: 0.0063 - pred_sparse_categorical_accuracy: 0.8909 - val_loss: 0.8848 - val_pred_loss: 0.8848 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6856 - lr: 2.5000e-04\n",
            "Epoch 138/500\n",
            "113/113 [==============================] - 2s 19ms/step - loss: 0.6006 - pred_loss: 0.2721 - tf.where_13_loss: 0.0066 - pred_sparse_categorical_accuracy: 0.8917 - val_loss: 1.2384 - val_pred_loss: 1.2384 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6697 - lr: 2.5000e-04\n",
            "Epoch 139/500\n",
            "113/113 [==============================] - 2s 22ms/step - loss: 0.5868 - pred_loss: 0.2689 - tf.where_13_loss: 0.0064 - pred_sparse_categorical_accuracy: 0.8948 - val_loss: 0.5217 - val_pred_loss: 0.5217 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7402 - lr: 2.5000e-04\n",
            "Epoch 140/500\n",
            "113/113 [==============================] - 2s 19ms/step - loss: 0.5794 - pred_loss: 0.2651 - tf.where_13_loss: 0.0063 - pred_sparse_categorical_accuracy: 0.8970 - val_loss: 0.6081 - val_pred_loss: 0.6081 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7273 - lr: 2.5000e-04\n",
            "Epoch 141/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.5652 - pred_loss: 0.2624 - tf.where_13_loss: 0.0061 - pred_sparse_categorical_accuracy: 0.8884 - val_loss: 1.3485 - val_pred_loss: 1.3485 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6773 - lr: 2.5000e-04\n",
            "Epoch 142/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.6153 - pred_loss: 0.2674 - tf.where_13_loss: 0.0070 - pred_sparse_categorical_accuracy: 0.8906 - val_loss: 0.7339 - val_pred_loss: 0.7339 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7152 - lr: 2.5000e-04\n",
            "Epoch 143/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.6147 - pred_loss: 0.2648 - tf.where_13_loss: 0.0070 - pred_sparse_categorical_accuracy: 0.8895 - val_loss: 0.3259 - val_pred_loss: 0.3259 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8333 - lr: 2.5000e-04\n",
            "Epoch 144/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.5706 - pred_loss: 0.2558 - tf.where_13_loss: 0.0063 - pred_sparse_categorical_accuracy: 0.9009 - val_loss: 1.6041 - val_pred_loss: 1.6041 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6326 - lr: 2.5000e-04\n",
            "Epoch 145/500\n",
            "113/113 [==============================] - 2s 20ms/step - loss: 0.5728 - pred_loss: 0.2632 - tf.where_13_loss: 0.0062 - pred_sparse_categorical_accuracy: 0.8923 - val_loss: 1.8952 - val_pred_loss: 1.8952 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6189 - lr: 2.5000e-04\n",
            "Epoch 146/500\n",
            "113/113 [==============================] - 3s 23ms/step - loss: 0.5737 - pred_loss: 0.2625 - tf.where_13_loss: 0.0062 - pred_sparse_categorical_accuracy: 0.8925 - val_loss: 0.4109 - val_pred_loss: 0.4109 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7864 - lr: 2.5000e-04\n",
            "Epoch 147/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.5780 - pred_loss: 0.2595 - tf.where_13_loss: 0.0064 - pred_sparse_categorical_accuracy: 0.8973 - val_loss: 9.4444 - val_pred_loss: 9.4444 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.4841 - lr: 2.5000e-04\n",
            "Epoch 148/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.5625 - pred_loss: 0.2509 - tf.where_13_loss: 0.0062 - pred_sparse_categorical_accuracy: 0.8956 - val_loss: 0.3069 - val_pred_loss: 0.3069 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8515 - lr: 2.5000e-04\n",
            "Epoch 149/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.5607 - pred_loss: 0.2564 - tf.where_13_loss: 0.0061 - pred_sparse_categorical_accuracy: 0.8948 - val_loss: 0.8919 - val_pred_loss: 0.8919 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6841 - lr: 2.5000e-04\n",
            "Epoch 150/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.5563 - pred_loss: 0.2540 - tf.where_13_loss: 0.0060 - pred_sparse_categorical_accuracy: 0.8998 - val_loss: 0.5712 - val_pred_loss: 0.5712 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7348 - lr: 2.5000e-04\n",
            "Epoch 151/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.5817 - pred_loss: 0.2700 - tf.where_13_loss: 0.0062 - pred_sparse_categorical_accuracy: 0.8853 - val_loss: 1.1621 - val_pred_loss: 1.1621 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6606 - lr: 2.5000e-04\n",
            "Epoch 152/500\n",
            "113/113 [==============================] - 3s 23ms/step - loss: 0.5804 - pred_loss: 0.2650 - tf.where_13_loss: 0.0063 - pred_sparse_categorical_accuracy: 0.8923 - val_loss: 0.3248 - val_pred_loss: 0.3248 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8500 - lr: 2.5000e-04\n",
            "Epoch 153/500\n",
            "113/113 [==============================] - 2s 19ms/step - loss: 0.5817 - pred_loss: 0.2583 - tf.where_13_loss: 0.0065 - pred_sparse_categorical_accuracy: 0.8939 - val_loss: 0.3036 - val_pred_loss: 0.3036 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8576 - lr: 2.5000e-04\n",
            "Epoch 154/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.5718 - pred_loss: 0.2535 - tf.where_13_loss: 0.0064 - pred_sparse_categorical_accuracy: 0.8959 - val_loss: 0.3207 - val_pred_loss: 0.3207 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8492 - lr: 2.5000e-04\n",
            "Epoch 155/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.5392 - pred_loss: 0.2481 - tf.where_13_loss: 0.0058 - pred_sparse_categorical_accuracy: 0.8906 - val_loss: 0.9745 - val_pred_loss: 0.9745 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6727 - lr: 1.2500e-04\n",
            "Epoch 156/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.5257 - pred_loss: 0.2419 - tf.where_13_loss: 0.0057 - pred_sparse_categorical_accuracy: 0.9053 - val_loss: 3.6852 - val_pred_loss: 3.6852 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.5295 - lr: 1.2500e-04\n",
            "Epoch 157/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.5119 - pred_loss: 0.2444 - tf.where_13_loss: 0.0053 - pred_sparse_categorical_accuracy: 0.9020 - val_loss: 0.9123 - val_pred_loss: 0.9123 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6970 - lr: 1.2500e-04\n",
            "Epoch 158/500\n",
            "113/113 [==============================] - 2s 19ms/step - loss: 0.5219 - pred_loss: 0.2438 - tf.where_13_loss: 0.0056 - pred_sparse_categorical_accuracy: 0.8998 - val_loss: 0.2867 - val_pred_loss: 0.2867 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8735 - lr: 1.2500e-04\n",
            "Epoch 159/500\n",
            "113/113 [==============================] - 2s 21ms/step - loss: 0.5248 - pred_loss: 0.2429 - tf.where_13_loss: 0.0056 - pred_sparse_categorical_accuracy: 0.8986 - val_loss: 0.9395 - val_pred_loss: 0.9395 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6902 - lr: 1.2500e-04\n",
            "Epoch 160/500\n",
            "113/113 [==============================] - 2s 19ms/step - loss: 0.5158 - pred_loss: 0.2429 - tf.where_13_loss: 0.0055 - pred_sparse_categorical_accuracy: 0.9061 - val_loss: 1.0395 - val_pred_loss: 1.0395 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6811 - lr: 1.2500e-04\n",
            "Epoch 161/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.5182 - pred_loss: 0.2416 - tf.where_13_loss: 0.0055 - pred_sparse_categorical_accuracy: 0.9050 - val_loss: 0.8991 - val_pred_loss: 0.8991 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6970 - lr: 1.2500e-04\n",
            "Epoch 162/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.5172 - pred_loss: 0.2419 - tf.where_13_loss: 0.0055 - pred_sparse_categorical_accuracy: 0.9050 - val_loss: 3.1557 - val_pred_loss: 3.1557 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.5674 - lr: 1.2500e-04\n",
            "Epoch 163/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.5088 - pred_loss: 0.2333 - tf.where_13_loss: 0.0055 - pred_sparse_categorical_accuracy: 0.9067 - val_loss: 2.9794 - val_pred_loss: 2.9794 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6008 - lr: 1.2500e-04\n",
            "Epoch 164/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.5132 - pred_loss: 0.2357 - tf.where_13_loss: 0.0056 - pred_sparse_categorical_accuracy: 0.9031 - val_loss: 2.6234 - val_pred_loss: 2.6234 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.5864 - lr: 1.2500e-04\n",
            "Epoch 165/500\n",
            "113/113 [==============================] - 2s 22ms/step - loss: 0.5177 - pred_loss: 0.2380 - tf.where_13_loss: 0.0056 - pred_sparse_categorical_accuracy: 0.9100 - val_loss: 0.5013 - val_pred_loss: 0.5013 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7636 - lr: 1.2500e-04\n",
            "Epoch 166/500\n",
            "113/113 [==============================] - 2s 21ms/step - loss: 0.5068 - pred_loss: 0.2403 - tf.where_13_loss: 0.0053 - pred_sparse_categorical_accuracy: 0.9020 - val_loss: 1.2790 - val_pred_loss: 1.2790 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6682 - lr: 1.2500e-04\n",
            "Epoch 167/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.5176 - pred_loss: 0.2458 - tf.where_13_loss: 0.0054 - pred_sparse_categorical_accuracy: 0.9028 - val_loss: 0.9341 - val_pred_loss: 0.9341 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6742 - lr: 1.2500e-04\n",
            "Epoch 168/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.5063 - pred_loss: 0.2347 - tf.where_13_loss: 0.0054 - pred_sparse_categorical_accuracy: 0.9056 - val_loss: 2.7455 - val_pred_loss: 2.7455 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.5720 - lr: 1.2500e-04\n",
            "Epoch 169/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.5112 - pred_loss: 0.2300 - tf.where_13_loss: 0.0056 - pred_sparse_categorical_accuracy: 0.9114 - val_loss: 1.0313 - val_pred_loss: 1.0313 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6712 - lr: 1.2500e-04\n",
            "Epoch 170/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.5101 - pred_loss: 0.2416 - tf.where_13_loss: 0.0054 - pred_sparse_categorical_accuracy: 0.9017 - val_loss: 0.6799 - val_pred_loss: 0.6799 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7144 - lr: 1.2500e-04\n",
            "Epoch 171/500\n",
            "113/113 [==============================] - 2s 20ms/step - loss: 0.5024 - pred_loss: 0.2377 - tf.where_13_loss: 0.0053 - pred_sparse_categorical_accuracy: 0.9059 - val_loss: 0.3991 - val_pred_loss: 0.3991 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8053 - lr: 1.2500e-04\n",
            "Epoch 172/500\n",
            "113/113 [==============================] - 2s 21ms/step - loss: 0.4946 - pred_loss: 0.2290 - tf.where_13_loss: 0.0053 - pred_sparse_categorical_accuracy: 0.9050 - val_loss: 0.9250 - val_pred_loss: 0.9250 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6886 - lr: 1.2500e-04\n",
            "Epoch 173/500\n",
            "113/113 [==============================] - 2s 19ms/step - loss: 0.5030 - pred_loss: 0.2273 - tf.where_13_loss: 0.0055 - pred_sparse_categorical_accuracy: 0.9153 - val_loss: 1.2210 - val_pred_loss: 1.2210 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6773 - lr: 1.2500e-04\n",
            "Epoch 174/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.4991 - pred_loss: 0.2319 - tf.where_13_loss: 0.0053 - pred_sparse_categorical_accuracy: 0.9092 - val_loss: 0.3014 - val_pred_loss: 0.3014 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8659 - lr: 1.2500e-04\n",
            "Epoch 175/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.4992 - pred_loss: 0.2313 - tf.where_13_loss: 0.0054 - pred_sparse_categorical_accuracy: 0.9078 - val_loss: 0.7924 - val_pred_loss: 0.7924 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7076 - lr: 1.0000e-04\n",
            "Epoch 176/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.4995 - pred_loss: 0.2331 - tf.where_13_loss: 0.0053 - pred_sparse_categorical_accuracy: 0.9067 - val_loss: 1.1576 - val_pred_loss: 1.1576 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6735 - lr: 1.0000e-04\n",
            "Epoch 177/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.5080 - pred_loss: 0.2311 - tf.where_13_loss: 0.0055 - pred_sparse_categorical_accuracy: 0.9095 - val_loss: 0.3639 - val_pred_loss: 0.3639 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8303 - lr: 1.0000e-04\n",
            "Epoch 178/500\n",
            "113/113 [==============================] - 2s 21ms/step - loss: 0.4827 - pred_loss: 0.2253 - tf.where_13_loss: 0.0051 - pred_sparse_categorical_accuracy: 0.9170 - val_loss: 4.9084 - val_pred_loss: 4.9084 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.5008 - lr: 1.0000e-04\n",
            "Epoch 179/500\n",
            "113/113 [==============================] - 2s 22ms/step - loss: 0.4951 - pred_loss: 0.2325 - tf.where_13_loss: 0.0053 - pred_sparse_categorical_accuracy: 0.9067 - val_loss: 1.1745 - val_pred_loss: 1.1745 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6788 - lr: 1.0000e-04\n",
            "Epoch 180/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.5077 - pred_loss: 0.2363 - tf.where_13_loss: 0.0054 - pred_sparse_categorical_accuracy: 0.9014 - val_loss: 0.5142 - val_pred_loss: 0.5142 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7727 - lr: 1.0000e-04\n",
            "Epoch 181/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.4748 - pred_loss: 0.2199 - tf.where_13_loss: 0.0051 - pred_sparse_categorical_accuracy: 0.9150 - val_loss: 1.2263 - val_pred_loss: 1.2263 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6705 - lr: 1.0000e-04\n",
            "Epoch 182/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.4821 - pred_loss: 0.2291 - tf.where_13_loss: 0.0051 - pred_sparse_categorical_accuracy: 0.9064 - val_loss: 4.5422 - val_pred_loss: 4.5422 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.5083 - lr: 1.0000e-04\n",
            "Epoch 183/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.4965 - pred_loss: 0.2303 - tf.where_13_loss: 0.0053 - pred_sparse_categorical_accuracy: 0.9109 - val_loss: 0.5201 - val_pred_loss: 0.5201 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7667 - lr: 1.0000e-04\n",
            "Epoch 184/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.4987 - pred_loss: 0.2310 - tf.where_13_loss: 0.0054 - pred_sparse_categorical_accuracy: 0.9072 - val_loss: 2.8850 - val_pred_loss: 2.8850 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.5712 - lr: 1.0000e-04\n",
            "Epoch 185/500\n",
            "113/113 [==============================] - 2s 20ms/step - loss: 0.4872 - pred_loss: 0.2242 - tf.where_13_loss: 0.0053 - pred_sparse_categorical_accuracy: 0.9164 - val_loss: 1.3149 - val_pred_loss: 1.3149 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6720 - lr: 1.0000e-04\n",
            "Epoch 186/500\n",
            "113/113 [==============================] - 2s 21ms/step - loss: 0.4797 - pred_loss: 0.2224 - tf.where_13_loss: 0.0051 - pred_sparse_categorical_accuracy: 0.9170 - val_loss: 1.1300 - val_pred_loss: 1.1300 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6788 - lr: 1.0000e-04\n",
            "Epoch 187/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.5198 - pred_loss: 0.2392 - tf.where_13_loss: 0.0056 - pred_sparse_categorical_accuracy: 0.9059 - val_loss: 0.9609 - val_pred_loss: 0.9609 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6886 - lr: 1.0000e-04\n",
            "Epoch 188/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.5051 - pred_loss: 0.2278 - tf.where_13_loss: 0.0055 - pred_sparse_categorical_accuracy: 0.9103 - val_loss: 1.1148 - val_pred_loss: 1.1148 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6818 - lr: 1.0000e-04\n",
            "Epoch 189/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.4932 - pred_loss: 0.2307 - tf.where_13_loss: 0.0052 - pred_sparse_categorical_accuracy: 0.9034 - val_loss: 0.7776 - val_pred_loss: 0.7776 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7083 - lr: 1.0000e-04\n",
            "Epoch 190/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.4789 - pred_loss: 0.2240 - tf.where_13_loss: 0.0051 - pred_sparse_categorical_accuracy: 0.9122 - val_loss: 0.9575 - val_pred_loss: 0.9575 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6970 - lr: 1.0000e-04\n",
            "Epoch 191/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.4881 - pred_loss: 0.2271 - tf.where_13_loss: 0.0052 - pred_sparse_categorical_accuracy: 0.9064 - val_loss: 1.3628 - val_pred_loss: 1.3628 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6689 - lr: 1.0000e-04\n",
            "Epoch 192/500\n",
            "113/113 [==============================] - 2s 21ms/step - loss: 0.4800 - pred_loss: 0.2199 - tf.where_13_loss: 0.0052 - pred_sparse_categorical_accuracy: 0.9175 - val_loss: 1.0671 - val_pred_loss: 1.0671 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6856 - lr: 1.0000e-04\n",
            "Epoch 193/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.5038 - pred_loss: 0.2348 - tf.where_13_loss: 0.0054 - pred_sparse_categorical_accuracy: 0.9014 - val_loss: 1.3621 - val_pred_loss: 1.3621 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6553 - lr: 1.0000e-04\n",
            "Epoch 194/500\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 0.4820 - pred_loss: 0.2224 - tf.where_13_loss: 0.0052 - pred_sparse_categorical_accuracy: 0.9084 - val_loss: 1.6079 - val_pred_loss: 1.6079 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6439 - lr: 1.0000e-04\n",
            "Epoch 195/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.4692 - pred_loss: 0.2105 - tf.where_13_loss: 0.0052 - pred_sparse_categorical_accuracy: 0.9178 - val_loss: 1.4384 - val_pred_loss: 1.4384 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6561 - lr: 1.0000e-04\n",
            "Epoch 196/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.4957 - pred_loss: 0.2241 - tf.where_13_loss: 0.0054 - pred_sparse_categorical_accuracy: 0.9103 - val_loss: 2.2579 - val_pred_loss: 2.2579 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6129 - lr: 1.0000e-04\n",
            "Epoch 197/500\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 0.4888 - pred_loss: 0.2241 - tf.where_13_loss: 0.0053 - pred_sparse_categorical_accuracy: 0.9106 - val_loss: 0.3296 - val_pred_loss: 0.3296 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8439 - lr: 1.0000e-04\n",
            "Epoch 198/500\n",
            "113/113 [==============================] - 2s 19ms/step - loss: 0.4803 - pred_loss: 0.2174 - tf.where_13_loss: 0.0053 - pred_sparse_categorical_accuracy: 0.9145 - val_loss: 2.4507 - val_pred_loss: 2.4507 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6189 - lr: 1.0000e-04\n",
            "Epoch 199/500\n",
            "113/113 [==============================] - 2s 20ms/step - loss: 0.4865 - pred_loss: 0.2187 - tf.where_13_loss: 0.0054 - pred_sparse_categorical_accuracy: 0.9209 - val_loss: 0.6157 - val_pred_loss: 0.6157 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7417 - lr: 1.0000e-04\n",
            "Epoch 200/500\n",
            "113/113 [==============================] - 2s 19ms/step - loss: 0.4592 - pred_loss: 0.2073 - tf.where_13_loss: 0.0050 - pred_sparse_categorical_accuracy: 0.9184 - val_loss: 2.1545 - val_pred_loss: 2.1545 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6273 - lr: 1.0000e-04\n",
            "Epoch 201/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.4623 - pred_loss: 0.2107 - tf.where_13_loss: 0.0050 - pred_sparse_categorical_accuracy: 0.9184 - val_loss: 2.6495 - val_pred_loss: 2.6495 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6121 - lr: 1.0000e-04\n",
            "Epoch 202/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.4762 - pred_loss: 0.2169 - tf.where_13_loss: 0.0052 - pred_sparse_categorical_accuracy: 0.9145 - val_loss: 0.5404 - val_pred_loss: 0.5404 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7705 - lr: 1.0000e-04\n",
            "Epoch 203/500\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 0.4754 - pred_loss: 0.2143 - tf.where_13_loss: 0.0052 - pred_sparse_categorical_accuracy: 0.9145 - val_loss: 1.7406 - val_pred_loss: 1.7406 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6318 - lr: 1.0000e-04\n",
            "Epoch 204/500\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 0.4952 - pred_loss: 0.2183 - tf.where_13_loss: 0.0055 - pred_sparse_categorical_accuracy: 0.9134 - val_loss: 0.8905 - val_pred_loss: 0.8905 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7008 - lr: 1.0000e-04\n",
            "Epoch 205/500\n",
            "113/113 [==============================] - 2s 20ms/step - loss: 0.4750 - pred_loss: 0.2154 - tf.where_13_loss: 0.0052 - pred_sparse_categorical_accuracy: 0.9167 - val_loss: 1.6111 - val_pred_loss: 1.6111 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6583 - lr: 1.0000e-04\n",
            "Epoch 206/500\n",
            "113/113 [==============================] - 2s 20ms/step - loss: 0.4698 - pred_loss: 0.2206 - tf.where_13_loss: 0.0050 - pred_sparse_categorical_accuracy: 0.9109 - val_loss: 1.8797 - val_pred_loss: 1.8797 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6500 - lr: 1.0000e-04\n",
            "Epoch 207/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.4743 - pred_loss: 0.2151 - tf.where_13_loss: 0.0052 - pred_sparse_categorical_accuracy: 0.9120 - val_loss: 3.4795 - val_pred_loss: 3.4795 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.5674 - lr: 1.0000e-04\n",
            "Epoch 208/500\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 0.4613 - pred_loss: 0.2092 - tf.where_13_loss: 0.0050 - pred_sparse_categorical_accuracy: 0.9214 - val_loss: 3.5278 - val_pred_loss: 3.5278 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.5508 - lr: 1.0000e-04\n",
            "Epoch 209/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.4752 - pred_loss: 0.2137 - tf.where_13_loss: 0.0052 - pred_sparse_categorical_accuracy: 0.9164 - val_loss: 0.6568 - val_pred_loss: 0.6568 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7379 - lr: 1.0000e-04\n",
            "Epoch 210/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.4791 - pred_loss: 0.2110 - tf.where_13_loss: 0.0054 - pred_sparse_categorical_accuracy: 0.9178 - val_loss: 3.9054 - val_pred_loss: 3.9054 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.5250 - lr: 1.0000e-04\n",
            "Epoch 211/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.4684 - pred_loss: 0.2064 - tf.where_13_loss: 0.0052 - pred_sparse_categorical_accuracy: 0.9239 - val_loss: 0.8109 - val_pred_loss: 0.8109 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7144 - lr: 1.0000e-04\n",
            "Epoch 212/500\n",
            "113/113 [==============================] - 2s 20ms/step - loss: 0.4752 - pred_loss: 0.2150 - tf.where_13_loss: 0.0052 - pred_sparse_categorical_accuracy: 0.9175 - val_loss: 2.9622 - val_pred_loss: 2.9622 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.5795 - lr: 1.0000e-04\n",
            "Epoch 213/500\n",
            "113/113 [==============================] - 2s 20ms/step - loss: 0.4660 - pred_loss: 0.2110 - tf.where_13_loss: 0.0051 - pred_sparse_categorical_accuracy: 0.9167 - val_loss: 0.4978 - val_pred_loss: 0.4978 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7818 - lr: 1.0000e-04\n",
            "Epoch 214/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.4564 - pred_loss: 0.2071 - tf.where_13_loss: 0.0050 - pred_sparse_categorical_accuracy: 0.9156 - val_loss: 2.0440 - val_pred_loss: 2.0440 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6197 - lr: 1.0000e-04\n",
            "Epoch 215/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.4731 - pred_loss: 0.2098 - tf.where_13_loss: 0.0053 - pred_sparse_categorical_accuracy: 0.9153 - val_loss: 0.7317 - val_pred_loss: 0.7317 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7311 - lr: 1.0000e-04\n",
            "Epoch 216/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.4862 - pred_loss: 0.2164 - tf.where_13_loss: 0.0054 - pred_sparse_categorical_accuracy: 0.9184 - val_loss: 0.3445 - val_pred_loss: 0.3445 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8455 - lr: 1.0000e-04\n",
            "Epoch 217/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.4636 - pred_loss: 0.2052 - tf.where_13_loss: 0.0052 - pred_sparse_categorical_accuracy: 0.9234 - val_loss: 7.1449 - val_pred_loss: 7.1449 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.4917 - lr: 1.0000e-04\n",
            "Epoch 218/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.4711 - pred_loss: 0.2082 - tf.where_13_loss: 0.0053 - pred_sparse_categorical_accuracy: 0.9172 - val_loss: 4.9497 - val_pred_loss: 4.9497 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.5091 - lr: 1.0000e-04\n",
            "Epoch 219/500\n",
            "113/113 [==============================] - 2s 22ms/step - loss: 0.4653 - pred_loss: 0.1967 - tf.where_13_loss: 0.0054 - pred_sparse_categorical_accuracy: 0.9231 - val_loss: 1.6184 - val_pred_loss: 1.6184 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6538 - lr: 1.0000e-04\n",
            "Epoch 220/500\n",
            "113/113 [==============================] - 2s 19ms/step - loss: 0.4722 - pred_loss: 0.2127 - tf.where_13_loss: 0.0052 - pred_sparse_categorical_accuracy: 0.9181 - val_loss: 3.1519 - val_pred_loss: 3.1519 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.5750 - lr: 1.0000e-04\n",
            "Epoch 221/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.4536 - pred_loss: 0.1999 - tf.where_13_loss: 0.0051 - pred_sparse_categorical_accuracy: 0.9256 - val_loss: 1.0451 - val_pred_loss: 1.0451 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6917 - lr: 1.0000e-04\n",
            "Epoch 222/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.4678 - pred_loss: 0.2080 - tf.where_13_loss: 0.0052 - pred_sparse_categorical_accuracy: 0.9156 - val_loss: 2.7003 - val_pred_loss: 2.7003 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.5795 - lr: 1.0000e-04\n",
            "Epoch 223/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.4639 - pred_loss: 0.2024 - tf.where_13_loss: 0.0052 - pred_sparse_categorical_accuracy: 0.9192 - val_loss: 2.6854 - val_pred_loss: 2.6854 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.5939 - lr: 1.0000e-04\n",
            "Epoch 224/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.4553 - pred_loss: 0.2016 - tf.where_13_loss: 0.0051 - pred_sparse_categorical_accuracy: 0.9242 - val_loss: 2.0782 - val_pred_loss: 2.0782 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6167 - lr: 1.0000e-04\n",
            "Epoch 225/500\n",
            "113/113 [==============================] - 2s 19ms/step - loss: 0.4502 - pred_loss: 0.1963 - tf.where_13_loss: 0.0051 - pred_sparse_categorical_accuracy: 0.9250 - val_loss: 3.9013 - val_pred_loss: 3.9013 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.5530 - lr: 1.0000e-04\n",
            "Epoch 226/500\n",
            "113/113 [==============================] - 2s 21ms/step - loss: 0.4745 - pred_loss: 0.2029 - tf.where_13_loss: 0.0054 - pred_sparse_categorical_accuracy: 0.9217 - val_loss: 1.9431 - val_pred_loss: 1.9431 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6227 - lr: 1.0000e-04\n",
            "Epoch 227/500\n",
            "113/113 [==============================] - 2s 19ms/step - loss: 0.4646 - pred_loss: 0.2085 - tf.where_13_loss: 0.0051 - pred_sparse_categorical_accuracy: 0.9220 - val_loss: 1.4443 - val_pred_loss: 1.4443 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6689 - lr: 1.0000e-04\n",
            "Epoch 228/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.4566 - pred_loss: 0.2052 - tf.where_13_loss: 0.0050 - pred_sparse_categorical_accuracy: 0.9206 - val_loss: 3.4320 - val_pred_loss: 3.4320 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.5614 - lr: 1.0000e-04\n",
            "Epoch 229/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.4622 - pred_loss: 0.2050 - tf.where_13_loss: 0.0051 - pred_sparse_categorical_accuracy: 0.9222 - val_loss: 2.1815 - val_pred_loss: 2.1815 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6152 - lr: 1.0000e-04\n",
            "Epoch 230/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.4484 - pred_loss: 0.1944 - tf.where_13_loss: 0.0051 - pred_sparse_categorical_accuracy: 0.9284 - val_loss: 5.5387 - val_pred_loss: 5.5387 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.5091 - lr: 1.0000e-04\n",
            "Epoch 231/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.4687 - pred_loss: 0.2033 - tf.where_13_loss: 0.0053 - pred_sparse_categorical_accuracy: 0.9200 - val_loss: 0.4295 - val_pred_loss: 0.4295 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8144 - lr: 1.0000e-04\n",
            "Epoch 232/500\n",
            "113/113 [==============================] - 2s 20ms/step - loss: 0.4542 - pred_loss: 0.1974 - tf.where_13_loss: 0.0051 - pred_sparse_categorical_accuracy: 0.9253 - val_loss: 0.3737 - val_pred_loss: 0.3737 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8333 - lr: 1.0000e-04\n",
            "Epoch 233/500\n",
            "113/113 [==============================] - 2s 21ms/step - loss: 0.4595 - pred_loss: 0.1937 - tf.where_13_loss: 0.0053 - pred_sparse_categorical_accuracy: 0.9272 - val_loss: 1.2832 - val_pred_loss: 1.2832 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6856 - lr: 1.0000e-04\n",
            "Epoch 234/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.4655 - pred_loss: 0.2044 - tf.where_13_loss: 0.0052 - pred_sparse_categorical_accuracy: 0.9175 - val_loss: 1.5695 - val_pred_loss: 1.5695 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6583 - lr: 1.0000e-04\n",
            "Epoch 235/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.4599 - pred_loss: 0.1989 - tf.where_13_loss: 0.0052 - pred_sparse_categorical_accuracy: 0.9242 - val_loss: 5.7217 - val_pred_loss: 5.7217 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.5015 - lr: 1.0000e-04\n",
            "Epoch 236/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.4645 - pred_loss: 0.2083 - tf.where_13_loss: 0.0051 - pred_sparse_categorical_accuracy: 0.9125 - val_loss: 0.9960 - val_pred_loss: 0.9960 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6917 - lr: 1.0000e-04\n",
            "Epoch 237/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.4535 - pred_loss: 0.1910 - tf.where_13_loss: 0.0053 - pred_sparse_categorical_accuracy: 0.9284 - val_loss: 1.3403 - val_pred_loss: 1.3403 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6750 - lr: 1.0000e-04\n",
            "Epoch 238/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.4581 - pred_loss: 0.1949 - tf.where_13_loss: 0.0053 - pred_sparse_categorical_accuracy: 0.9256 - val_loss: 3.3773 - val_pred_loss: 3.3773 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.5636 - lr: 1.0000e-04\n",
            "Epoch 239/500\n",
            "113/113 [==============================] - 2s 20ms/step - loss: 0.4543 - pred_loss: 0.1977 - tf.where_13_loss: 0.0051 - pred_sparse_categorical_accuracy: 0.9256 - val_loss: 0.9256 - val_pred_loss: 0.9256 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7023 - lr: 1.0000e-04\n",
            "Epoch 240/500\n",
            "113/113 [==============================] - 3s 22ms/step - loss: 0.4662 - pred_loss: 0.1970 - tf.where_13_loss: 0.0054 - pred_sparse_categorical_accuracy: 0.9239 - val_loss: 1.9321 - val_pred_loss: 1.9321 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6318 - lr: 1.0000e-04\n",
            "Epoch 241/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.4530 - pred_loss: 0.1941 - tf.where_13_loss: 0.0052 - pred_sparse_categorical_accuracy: 0.9217 - val_loss: 3.8531 - val_pred_loss: 3.8531 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.5447 - lr: 1.0000e-04\n",
            "Epoch 242/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.4544 - pred_loss: 0.1897 - tf.where_13_loss: 0.0053 - pred_sparse_categorical_accuracy: 0.9284 - val_loss: 2.4629 - val_pred_loss: 2.4629 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6068 - lr: 1.0000e-04\n",
            "Epoch 243/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.4406 - pred_loss: 0.1915 - tf.where_13_loss: 0.0050 - pred_sparse_categorical_accuracy: 0.9278 - val_loss: 0.3428 - val_pred_loss: 0.3428 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8470 - lr: 1.0000e-04\n",
            "Epoch 244/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.4466 - pred_loss: 0.1933 - tf.where_13_loss: 0.0051 - pred_sparse_categorical_accuracy: 0.9261 - val_loss: 1.5041 - val_pred_loss: 1.5041 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6492 - lr: 1.0000e-04\n",
            "Epoch 245/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.4463 - pred_loss: 0.1876 - tf.where_13_loss: 0.0052 - pred_sparse_categorical_accuracy: 0.9250 - val_loss: 3.3275 - val_pred_loss: 3.3275 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.5780 - lr: 1.0000e-04\n",
            "Epoch 246/500\n",
            "113/113 [==============================] - 2s 21ms/step - loss: 0.4545 - pred_loss: 0.1973 - tf.where_13_loss: 0.0051 - pred_sparse_categorical_accuracy: 0.9206 - val_loss: 0.7514 - val_pred_loss: 0.7514 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7295 - lr: 1.0000e-04\n",
            "Epoch 247/500\n",
            "113/113 [==============================] - 2s 20ms/step - loss: 0.4327 - pred_loss: 0.1813 - tf.where_13_loss: 0.0050 - pred_sparse_categorical_accuracy: 0.9314 - val_loss: 0.9063 - val_pred_loss: 0.9063 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7068 - lr: 1.0000e-04\n",
            "Epoch 248/500\n",
            "113/113 [==============================] - 2s 19ms/step - loss: 0.4682 - pred_loss: 0.2095 - tf.where_13_loss: 0.0052 - pred_sparse_categorical_accuracy: 0.9192 - val_loss: 0.5746 - val_pred_loss: 0.5746 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7652 - lr: 1.0000e-04\n",
            "Epoch 249/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.4460 - pred_loss: 0.1898 - tf.where_13_loss: 0.0051 - pred_sparse_categorical_accuracy: 0.9239 - val_loss: 1.1624 - val_pred_loss: 1.1624 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6826 - lr: 1.0000e-04\n",
            "Epoch 250/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.4691 - pred_loss: 0.2044 - tf.where_13_loss: 0.0053 - pred_sparse_categorical_accuracy: 0.9220 - val_loss: 0.5277 - val_pred_loss: 0.5277 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7727 - lr: 1.0000e-04\n",
            "Epoch 251/500\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 0.4658 - pred_loss: 0.2060 - tf.where_13_loss: 0.0052 - pred_sparse_categorical_accuracy: 0.9225 - val_loss: 0.8918 - val_pred_loss: 0.8918 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7030 - lr: 1.0000e-04\n",
            "Epoch 252/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.4335 - pred_loss: 0.1841 - tf.where_13_loss: 0.0050 - pred_sparse_categorical_accuracy: 0.9322 - val_loss: 0.4885 - val_pred_loss: 0.4885 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7886 - lr: 1.0000e-04\n",
            "Epoch 253/500\n",
            "113/113 [==============================] - 2s 21ms/step - loss: 0.4387 - pred_loss: 0.1878 - tf.where_13_loss: 0.0050 - pred_sparse_categorical_accuracy: 0.9275 - val_loss: 1.0934 - val_pred_loss: 1.0934 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6909 - lr: 1.0000e-04\n",
            "Epoch 254/500\n",
            "113/113 [==============================] - 2s 19ms/step - loss: 0.4429 - pred_loss: 0.1889 - tf.where_13_loss: 0.0051 - pred_sparse_categorical_accuracy: 0.9284 - val_loss: 3.3008 - val_pred_loss: 3.3008 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.5705 - lr: 1.0000e-04\n",
            "Epoch 255/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.4446 - pred_loss: 0.1907 - tf.where_13_loss: 0.0051 - pred_sparse_categorical_accuracy: 0.9259 - val_loss: 1.5985 - val_pred_loss: 1.5985 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6621 - lr: 1.0000e-04\n",
            "Epoch 256/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.4612 - pred_loss: 0.1965 - tf.where_13_loss: 0.0053 - pred_sparse_categorical_accuracy: 0.9245 - val_loss: 0.6600 - val_pred_loss: 0.6600 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7538 - lr: 1.0000e-04\n",
            "Epoch 257/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.4584 - pred_loss: 0.2000 - tf.where_13_loss: 0.0052 - pred_sparse_categorical_accuracy: 0.9278 - val_loss: 1.5663 - val_pred_loss: 1.5663 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6523 - lr: 1.0000e-04\n",
            "Epoch 258/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.4434 - pred_loss: 0.1853 - tf.where_13_loss: 0.0052 - pred_sparse_categorical_accuracy: 0.9309 - val_loss: 1.2979 - val_pred_loss: 1.2979 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6795 - lr: 1.0000e-04\n",
            "Epoch 259/500\n",
            "113/113 [==============================] - 2s 19ms/step - loss: 0.4352 - pred_loss: 0.1821 - tf.where_13_loss: 0.0051 - pred_sparse_categorical_accuracy: 0.9336 - val_loss: 4.1474 - val_pred_loss: 4.1474 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.5394 - lr: 1.0000e-04\n",
            "Epoch 260/500\n",
            "113/113 [==============================] - 2s 20ms/step - loss: 0.4488 - pred_loss: 0.1920 - tf.where_13_loss: 0.0051 - pred_sparse_categorical_accuracy: 0.9242 - val_loss: 1.5545 - val_pred_loss: 1.5545 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6689 - lr: 1.0000e-04\n",
            "Epoch 261/500\n",
            "113/113 [==============================] - 2s 19ms/step - loss: 0.4628 - pred_loss: 0.1970 - tf.where_13_loss: 0.0053 - pred_sparse_categorical_accuracy: 0.9245 - val_loss: 0.4593 - val_pred_loss: 0.4593 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8045 - lr: 1.0000e-04\n",
            "Epoch 262/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.4423 - pred_loss: 0.1832 - tf.where_13_loss: 0.0052 - pred_sparse_categorical_accuracy: 0.9306 - val_loss: 2.6068 - val_pred_loss: 2.6068 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6008 - lr: 1.0000e-04\n",
            "Epoch 263/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.4384 - pred_loss: 0.1867 - tf.where_13_loss: 0.0050 - pred_sparse_categorical_accuracy: 0.9264 - val_loss: 3.0480 - val_pred_loss: 3.0480 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.5992 - lr: 1.0000e-04\n",
            "Epoch 264/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.4437 - pred_loss: 0.1899 - tf.where_13_loss: 0.0051 - pred_sparse_categorical_accuracy: 0.9303 - val_loss: 10.7369 - val_pred_loss: 10.7369 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.4856 - lr: 1.0000e-04\n",
            "Epoch 265/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.4523 - pred_loss: 0.1945 - tf.where_13_loss: 0.0052 - pred_sparse_categorical_accuracy: 0.9259 - val_loss: 1.6246 - val_pred_loss: 1.6246 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6606 - lr: 1.0000e-04\n",
            "Epoch 266/500\n",
            "113/113 [==============================] - 2s 19ms/step - loss: 0.4396 - pred_loss: 0.1805 - tf.where_13_loss: 0.0052 - pred_sparse_categorical_accuracy: 0.9309 - val_loss: 4.6004 - val_pred_loss: 4.6004 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.5333 - lr: 1.0000e-04\n",
            "Epoch 267/500\n",
            "113/113 [==============================] - 2s 21ms/step - loss: 0.4474 - pred_loss: 0.1890 - tf.where_13_loss: 0.0052 - pred_sparse_categorical_accuracy: 0.9253 - val_loss: 4.5041 - val_pred_loss: 4.5041 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.5333 - lr: 1.0000e-04\n",
            "Epoch 268/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.4396 - pred_loss: 0.1865 - tf.where_13_loss: 0.0051 - pred_sparse_categorical_accuracy: 0.9281 - val_loss: 0.4087 - val_pred_loss: 0.4087 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8235 - lr: 1.0000e-04\n",
            "Epoch 269/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.4449 - pred_loss: 0.1951 - tf.where_13_loss: 0.0050 - pred_sparse_categorical_accuracy: 0.9209 - val_loss: 0.4770 - val_pred_loss: 0.4770 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8015 - lr: 1.0000e-04\n",
            "Epoch 270/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.4422 - pred_loss: 0.1833 - tf.where_13_loss: 0.0052 - pred_sparse_categorical_accuracy: 0.9303 - val_loss: 2.2639 - val_pred_loss: 2.2639 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6379 - lr: 1.0000e-04\n",
            "Epoch 271/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.4309 - pred_loss: 0.1819 - tf.where_13_loss: 0.0050 - pred_sparse_categorical_accuracy: 0.9289 - val_loss: 0.3362 - val_pred_loss: 0.3362 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8470 - lr: 1.0000e-04\n",
            "Epoch 272/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.4329 - pred_loss: 0.1727 - tf.where_13_loss: 0.0052 - pred_sparse_categorical_accuracy: 0.9367 - val_loss: 0.3412 - val_pred_loss: 0.3412 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8538 - lr: 1.0000e-04\n",
            "Epoch 273/500\n",
            "113/113 [==============================] - 2s 21ms/step - loss: 0.4456 - pred_loss: 0.1907 - tf.where_13_loss: 0.0051 - pred_sparse_categorical_accuracy: 0.9250 - val_loss: 3.5767 - val_pred_loss: 3.5767 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.5629 - lr: 1.0000e-04\n",
            "Epoch 274/500\n",
            "113/113 [==============================] - 2s 21ms/step - loss: 0.4303 - pred_loss: 0.1776 - tf.where_13_loss: 0.0051 - pred_sparse_categorical_accuracy: 0.9297 - val_loss: 2.3419 - val_pred_loss: 2.3419 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6288 - lr: 1.0000e-04\n",
            "Epoch 275/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.4328 - pred_loss: 0.1809 - tf.where_13_loss: 0.0050 - pred_sparse_categorical_accuracy: 0.9342 - val_loss: 0.9011 - val_pred_loss: 0.9011 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7045 - lr: 1.0000e-04\n",
            "Epoch 276/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.4251 - pred_loss: 0.1803 - tf.where_13_loss: 0.0049 - pred_sparse_categorical_accuracy: 0.9309 - val_loss: 1.5684 - val_pred_loss: 1.5684 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6697 - lr: 1.0000e-04\n",
            "Epoch 277/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.4284 - pred_loss: 0.1792 - tf.where_13_loss: 0.0050 - pred_sparse_categorical_accuracy: 0.9300 - val_loss: 0.7695 - val_pred_loss: 0.7695 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7303 - lr: 1.0000e-04\n",
            "Epoch 278/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.4296 - pred_loss: 0.1787 - tf.where_13_loss: 0.0050 - pred_sparse_categorical_accuracy: 0.9328 - val_loss: 1.6751 - val_pred_loss: 1.6751 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6462 - lr: 1.0000e-04\n",
            "Epoch 279/500\n",
            "113/113 [==============================] - 2s 19ms/step - loss: 0.4358 - pred_loss: 0.1820 - tf.where_13_loss: 0.0051 - pred_sparse_categorical_accuracy: 0.9331 - val_loss: 0.6080 - val_pred_loss: 0.6080 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7689 - lr: 1.0000e-04\n",
            "Epoch 280/500\n",
            "113/113 [==============================] - 2s 21ms/step - loss: 0.4214 - pred_loss: 0.1744 - tf.where_13_loss: 0.0049 - pred_sparse_categorical_accuracy: 0.9353 - val_loss: 1.0608 - val_pred_loss: 1.0608 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6992 - lr: 1.0000e-04\n",
            "Epoch 281/500\n",
            "113/113 [==============================] - 2s 19ms/step - loss: 0.4474 - pred_loss: 0.1885 - tf.where_13_loss: 0.0052 - pred_sparse_categorical_accuracy: 0.9242 - val_loss: 4.5016 - val_pred_loss: 4.5016 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.5235 - lr: 1.0000e-04\n",
            "Epoch 282/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.4342 - pred_loss: 0.1757 - tf.where_13_loss: 0.0052 - pred_sparse_categorical_accuracy: 0.9320 - val_loss: 3.2321 - val_pred_loss: 3.2321 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.5788 - lr: 1.0000e-04\n",
            "Epoch 283/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.4354 - pred_loss: 0.1782 - tf.where_13_loss: 0.0051 - pred_sparse_categorical_accuracy: 0.9350 - val_loss: 0.4908 - val_pred_loss: 0.4908 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7939 - lr: 1.0000e-04\n",
            "Epoch 284/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.4450 - pred_loss: 0.1907 - tf.where_13_loss: 0.0051 - pred_sparse_categorical_accuracy: 0.9256 - val_loss: 0.5351 - val_pred_loss: 0.5351 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7841 - lr: 1.0000e-04\n",
            "Epoch 285/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.4266 - pred_loss: 0.1709 - tf.where_13_loss: 0.0051 - pred_sparse_categorical_accuracy: 0.9386 - val_loss: 1.1320 - val_pred_loss: 1.1320 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6939 - lr: 1.0000e-04\n",
            "Epoch 286/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.4281 - pred_loss: 0.1729 - tf.where_13_loss: 0.0051 - pred_sparse_categorical_accuracy: 0.9367 - val_loss: 2.3123 - val_pred_loss: 2.3123 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6295 - lr: 1.0000e-04\n",
            "Epoch 287/500\n",
            "113/113 [==============================] - 2s 21ms/step - loss: 0.4302 - pred_loss: 0.1770 - tf.where_13_loss: 0.0051 - pred_sparse_categorical_accuracy: 0.9356 - val_loss: 1.6376 - val_pred_loss: 1.6376 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6712 - lr: 1.0000e-04\n",
            "Epoch 288/500\n",
            "113/113 [==============================] - 2s 19ms/step - loss: 0.4235 - pred_loss: 0.1749 - tf.where_13_loss: 0.0050 - pred_sparse_categorical_accuracy: 0.9389 - val_loss: 2.5094 - val_pred_loss: 2.5094 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6030 - lr: 1.0000e-04\n",
            "Epoch 289/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.4273 - pred_loss: 0.1743 - tf.where_13_loss: 0.0051 - pred_sparse_categorical_accuracy: 0.9339 - val_loss: 2.2200 - val_pred_loss: 2.2200 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6348 - lr: 1.0000e-04\n",
            "Epoch 290/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.4262 - pred_loss: 0.1758 - tf.where_13_loss: 0.0050 - pred_sparse_categorical_accuracy: 0.9356 - val_loss: 2.1310 - val_pred_loss: 2.1310 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6379 - lr: 1.0000e-04\n",
            "Epoch 291/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.4318 - pred_loss: 0.1778 - tf.where_13_loss: 0.0051 - pred_sparse_categorical_accuracy: 0.9331 - val_loss: 3.3875 - val_pred_loss: 3.3875 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.5652 - lr: 1.0000e-04\n",
            "Epoch 292/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.4147 - pred_loss: 0.1616 - tf.where_13_loss: 0.0051 - pred_sparse_categorical_accuracy: 0.9414 - val_loss: 4.2555 - val_pred_loss: 4.2555 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.5424 - lr: 1.0000e-04\n",
            "Epoch 293/500\n",
            "113/113 [==============================] - 2s 20ms/step - loss: 0.4237 - pred_loss: 0.1737 - tf.where_13_loss: 0.0050 - pred_sparse_categorical_accuracy: 0.9325 - val_loss: 2.2294 - val_pred_loss: 2.2294 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6333 - lr: 1.0000e-04\n",
            "Epoch 294/500\n",
            "113/113 [==============================] - 2s 21ms/step - loss: 0.4227 - pred_loss: 0.1747 - tf.where_13_loss: 0.0050 - pred_sparse_categorical_accuracy: 0.9334 - val_loss: 2.4681 - val_pred_loss: 2.4681 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6220 - lr: 1.0000e-04\n",
            "Epoch 295/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.4257 - pred_loss: 0.1759 - tf.where_13_loss: 0.0050 - pred_sparse_categorical_accuracy: 0.9328 - val_loss: 2.3568 - val_pred_loss: 2.3568 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6379 - lr: 1.0000e-04\n",
            "Epoch 296/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.4330 - pred_loss: 0.1835 - tf.where_13_loss: 0.0050 - pred_sparse_categorical_accuracy: 0.9261 - val_loss: 1.3203 - val_pred_loss: 1.3203 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6674 - lr: 1.0000e-04\n",
            "Epoch 297/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.4098 - pred_loss: 0.1630 - tf.where_13_loss: 0.0049 - pred_sparse_categorical_accuracy: 0.9372 - val_loss: 1.1469 - val_pred_loss: 1.1469 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 298/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.4317 - pred_loss: 0.1798 - tf.where_13_loss: 0.0050 - pred_sparse_categorical_accuracy: 0.9303 - val_loss: 0.4698 - val_pred_loss: 0.4698 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8129 - lr: 1.0000e-04\n",
            "Epoch 299/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.4361 - pred_loss: 0.1767 - tf.where_13_loss: 0.0052 - pred_sparse_categorical_accuracy: 0.9320 - val_loss: 3.7114 - val_pred_loss: 3.7114 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.5462 - lr: 1.0000e-04\n",
            "Epoch 300/500\n",
            "113/113 [==============================] - 2s 21ms/step - loss: 0.4146 - pred_loss: 0.1693 - tf.where_13_loss: 0.0049 - pred_sparse_categorical_accuracy: 0.9336 - val_loss: 1.3358 - val_pred_loss: 1.3358 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6712 - lr: 1.0000e-04\n",
            "Epoch 301/500\n",
            "113/113 [==============================] - 2s 20ms/step - loss: 0.4385 - pred_loss: 0.1855 - tf.where_13_loss: 0.0051 - pred_sparse_categorical_accuracy: 0.9303 - val_loss: 2.0593 - val_pred_loss: 2.0593 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6273 - lr: 1.0000e-04\n",
            "Epoch 302/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.4111 - pred_loss: 0.1634 - tf.where_13_loss: 0.0050 - pred_sparse_categorical_accuracy: 0.9375 - val_loss: 2.0993 - val_pred_loss: 2.0993 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6167 - lr: 1.0000e-04\n",
            "Epoch 303/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.4289 - pred_loss: 0.1794 - tf.where_13_loss: 0.0050 - pred_sparse_categorical_accuracy: 0.9297 - val_loss: 0.8855 - val_pred_loss: 0.8855 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7174 - lr: 1.0000e-04\n",
            "Epoch 304/500\n",
            "113/113 [==============================] - 2s 19ms/step - loss: 0.4203 - pred_loss: 0.1723 - tf.where_13_loss: 0.0050 - pred_sparse_categorical_accuracy: 0.9375 - val_loss: 0.4357 - val_pred_loss: 0.4357 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8242 - lr: 1.0000e-04\n",
            "Epoch 305/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.4049 - pred_loss: 0.1552 - tf.where_13_loss: 0.0050 - pred_sparse_categorical_accuracy: 0.9417 - val_loss: 5.6568 - val_pred_loss: 5.6568 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.5159 - lr: 1.0000e-04\n",
            "Epoch 306/500\n",
            "113/113 [==============================] - 2s 19ms/step - loss: 0.4114 - pred_loss: 0.1595 - tf.where_13_loss: 0.0050 - pred_sparse_categorical_accuracy: 0.9378 - val_loss: 0.4773 - val_pred_loss: 0.4773 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8030 - lr: 1.0000e-04\n",
            "Epoch 307/500\n",
            "113/113 [==============================] - 2s 22ms/step - loss: 0.4386 - pred_loss: 0.1803 - tf.where_13_loss: 0.0052 - pred_sparse_categorical_accuracy: 0.9325 - val_loss: 1.1601 - val_pred_loss: 1.1601 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6879 - lr: 1.0000e-04\n",
            "Epoch 308/500\n",
            "113/113 [==============================] - 2s 20ms/step - loss: 0.4244 - pred_loss: 0.1637 - tf.where_13_loss: 0.0052 - pred_sparse_categorical_accuracy: 0.9417 - val_loss: 0.4453 - val_pred_loss: 0.4453 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8152 - lr: 1.0000e-04\n",
            "Epoch 309/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.4069 - pred_loss: 0.1622 - tf.where_13_loss: 0.0049 - pred_sparse_categorical_accuracy: 0.9400 - val_loss: 1.7240 - val_pred_loss: 1.7240 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6583 - lr: 1.0000e-04\n",
            "Epoch 310/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.4411 - pred_loss: 0.1775 - tf.where_13_loss: 0.0053 - pred_sparse_categorical_accuracy: 0.9267 - val_loss: 0.9072 - val_pred_loss: 0.9072 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7167 - lr: 1.0000e-04\n",
            "Epoch 311/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.4236 - pred_loss: 0.1697 - tf.where_13_loss: 0.0051 - pred_sparse_categorical_accuracy: 0.9325 - val_loss: 6.9348 - val_pred_loss: 6.9348 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.4977 - lr: 1.0000e-04\n",
            "Epoch 312/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.4056 - pred_loss: 0.1610 - tf.where_13_loss: 0.0049 - pred_sparse_categorical_accuracy: 0.9420 - val_loss: 6.4176 - val_pred_loss: 6.4176 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.5015 - lr: 1.0000e-04\n",
            "Epoch 313/500\n",
            "113/113 [==============================] - 2s 20ms/step - loss: 0.4358 - pred_loss: 0.1722 - tf.where_13_loss: 0.0053 - pred_sparse_categorical_accuracy: 0.9311 - val_loss: 1.3972 - val_pred_loss: 1.3972 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6773 - lr: 1.0000e-04\n",
            "Epoch 314/500\n",
            "113/113 [==============================] - 2s 20ms/step - loss: 0.4212 - pred_loss: 0.1642 - tf.where_13_loss: 0.0051 - pred_sparse_categorical_accuracy: 0.9386 - val_loss: 0.9398 - val_pred_loss: 0.9398 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7061 - lr: 1.0000e-04\n",
            "Epoch 315/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.4201 - pred_loss: 0.1655 - tf.where_13_loss: 0.0051 - pred_sparse_categorical_accuracy: 0.9384 - val_loss: 2.2703 - val_pred_loss: 2.2703 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6182 - lr: 1.0000e-04\n",
            "Epoch 316/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.4044 - pred_loss: 0.1588 - tf.where_13_loss: 0.0049 - pred_sparse_categorical_accuracy: 0.9431 - val_loss: 5.8494 - val_pred_loss: 5.8494 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.5106 - lr: 1.0000e-04\n",
            "Epoch 317/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.4232 - pred_loss: 0.1667 - tf.where_13_loss: 0.0051 - pred_sparse_categorical_accuracy: 0.9384 - val_loss: 0.3707 - val_pred_loss: 0.3707 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8364 - lr: 1.0000e-04\n",
            "Epoch 318/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.4105 - pred_loss: 0.1607 - tf.where_13_loss: 0.0050 - pred_sparse_categorical_accuracy: 0.9411 - val_loss: 3.8491 - val_pred_loss: 3.8491 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.5735 - lr: 1.0000e-04\n",
            "Epoch 319/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.4128 - pred_loss: 0.1598 - tf.where_13_loss: 0.0051 - pred_sparse_categorical_accuracy: 0.9378 - val_loss: 6.3531 - val_pred_loss: 6.3531 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.5045 - lr: 1.0000e-04\n",
            "Epoch 320/500\n",
            "113/113 [==============================] - 2s 21ms/step - loss: 0.4062 - pred_loss: 0.1596 - tf.where_13_loss: 0.0049 - pred_sparse_categorical_accuracy: 0.9439 - val_loss: 1.5655 - val_pred_loss: 1.5655 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6674 - lr: 1.0000e-04\n",
            "Epoch 321/500\n",
            "113/113 [==============================] - 2s 22ms/step - loss: 0.4108 - pred_loss: 0.1590 - tf.where_13_loss: 0.0050 - pred_sparse_categorical_accuracy: 0.9447 - val_loss: 0.8374 - val_pred_loss: 0.8374 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7341 - lr: 1.0000e-04\n",
            "Epoch 322/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.4196 - pred_loss: 0.1646 - tf.where_13_loss: 0.0051 - pred_sparse_categorical_accuracy: 0.9361 - val_loss: 4.2137 - val_pred_loss: 4.2137 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.5492 - lr: 1.0000e-04\n",
            "Epoch 323/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.4003 - pred_loss: 0.1516 - tf.where_13_loss: 0.0050 - pred_sparse_categorical_accuracy: 0.9467 - val_loss: 1.5873 - val_pred_loss: 1.5873 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6545 - lr: 1.0000e-04\n",
            "Epoch 324/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.4175 - pred_loss: 0.1647 - tf.where_13_loss: 0.0051 - pred_sparse_categorical_accuracy: 0.9411 - val_loss: 10.0335 - val_pred_loss: 10.0335 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.4879 - lr: 1.0000e-04\n",
            "Epoch 325/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.4141 - pred_loss: 0.1603 - tf.where_13_loss: 0.0051 - pred_sparse_categorical_accuracy: 0.9372 - val_loss: 5.4272 - val_pred_loss: 5.4272 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.5197 - lr: 1.0000e-04\n",
            "Epoch 326/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.4221 - pred_loss: 0.1618 - tf.where_13_loss: 0.0052 - pred_sparse_categorical_accuracy: 0.9350 - val_loss: 0.6198 - val_pred_loss: 0.6198 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7682 - lr: 1.0000e-04\n",
            "Epoch 327/500\n",
            "113/113 [==============================] - 2s 21ms/step - loss: 0.3872 - pred_loss: 0.1472 - tf.where_13_loss: 0.0048 - pred_sparse_categorical_accuracy: 0.9472 - val_loss: 1.6450 - val_pred_loss: 1.6450 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6659 - lr: 1.0000e-04\n",
            "Epoch 328/500\n",
            "113/113 [==============================] - 2s 20ms/step - loss: 0.4127 - pred_loss: 0.1593 - tf.where_13_loss: 0.0051 - pred_sparse_categorical_accuracy: 0.9375 - val_loss: 10.7279 - val_pred_loss: 10.7279 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.4886 - lr: 1.0000e-04\n",
            "Epoch 329/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.4034 - pred_loss: 0.1525 - tf.where_13_loss: 0.0050 - pred_sparse_categorical_accuracy: 0.9470 - val_loss: 1.6061 - val_pred_loss: 1.6061 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6697 - lr: 1.0000e-04\n",
            "Epoch 330/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.4053 - pred_loss: 0.1581 - tf.where_13_loss: 0.0049 - pred_sparse_categorical_accuracy: 0.9364 - val_loss: 1.2409 - val_pred_loss: 1.2409 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6917 - lr: 1.0000e-04\n",
            "Epoch 331/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.4173 - pred_loss: 0.1623 - tf.where_13_loss: 0.0051 - pred_sparse_categorical_accuracy: 0.9400 - val_loss: 6.4069 - val_pred_loss: 6.4069 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.5015 - lr: 1.0000e-04\n",
            "Epoch 332/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.4259 - pred_loss: 0.1618 - tf.where_13_loss: 0.0053 - pred_sparse_categorical_accuracy: 0.9411 - val_loss: 1.8694 - val_pred_loss: 1.8694 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6561 - lr: 1.0000e-04\n",
            "Epoch 333/500\n",
            "113/113 [==============================] - 2s 19ms/step - loss: 0.4034 - pred_loss: 0.1546 - tf.where_13_loss: 0.0050 - pred_sparse_categorical_accuracy: 0.9486 - val_loss: 2.8581 - val_pred_loss: 2.8581 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.5886 - lr: 1.0000e-04\n",
            "Epoch 334/500\n",
            "113/113 [==============================] - 2s 21ms/step - loss: 0.4155 - pred_loss: 0.1557 - tf.where_13_loss: 0.0052 - pred_sparse_categorical_accuracy: 0.9411 - val_loss: 0.3826 - val_pred_loss: 0.3826 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8439 - lr: 1.0000e-04\n",
            "Epoch 335/500\n",
            "113/113 [==============================] - 2s 20ms/step - loss: 0.4096 - pred_loss: 0.1618 - tf.where_13_loss: 0.0050 - pred_sparse_categorical_accuracy: 0.9397 - val_loss: 5.0696 - val_pred_loss: 5.0696 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.5258 - lr: 1.0000e-04\n",
            "Epoch 336/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.4006 - pred_loss: 0.1516 - tf.where_13_loss: 0.0050 - pred_sparse_categorical_accuracy: 0.9428 - val_loss: 0.3726 - val_pred_loss: 0.3726 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8409 - lr: 1.0000e-04\n",
            "Epoch 337/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.4161 - pred_loss: 0.1598 - tf.where_13_loss: 0.0051 - pred_sparse_categorical_accuracy: 0.9417 - val_loss: 2.3505 - val_pred_loss: 2.3505 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6242 - lr: 1.0000e-04\n",
            "Epoch 338/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.4002 - pred_loss: 0.1547 - tf.where_13_loss: 0.0049 - pred_sparse_categorical_accuracy: 0.9406 - val_loss: 5.5157 - val_pred_loss: 5.5157 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.5076 - lr: 1.0000e-04\n",
            "Epoch 339/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.4020 - pred_loss: 0.1560 - tf.where_13_loss: 0.0049 - pred_sparse_categorical_accuracy: 0.9470 - val_loss: 0.3574 - val_pred_loss: 0.3574 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8485 - lr: 1.0000e-04\n",
            "Epoch 340/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.4142 - pred_loss: 0.1605 - tf.where_13_loss: 0.0051 - pred_sparse_categorical_accuracy: 0.9422 - val_loss: 4.3357 - val_pred_loss: 4.3357 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.5409 - lr: 1.0000e-04\n",
            "Epoch 341/500\n",
            "113/113 [==============================] - 2s 20ms/step - loss: 0.3940 - pred_loss: 0.1480 - tf.where_13_loss: 0.0049 - pred_sparse_categorical_accuracy: 0.9506 - val_loss: 2.2589 - val_pred_loss: 2.2589 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6326 - lr: 1.0000e-04\n",
            "Epoch 342/500\n",
            "113/113 [==============================] - 2s 20ms/step - loss: 0.3925 - pred_loss: 0.1446 - tf.where_13_loss: 0.0050 - pred_sparse_categorical_accuracy: 0.9453 - val_loss: 2.1236 - val_pred_loss: 2.1236 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6288 - lr: 1.0000e-04\n",
            "Epoch 343/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.4138 - pred_loss: 0.1599 - tf.where_13_loss: 0.0051 - pred_sparse_categorical_accuracy: 0.9397 - val_loss: 1.6141 - val_pred_loss: 1.6141 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6568 - lr: 1.0000e-04\n",
            "Epoch 344/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.4247 - pred_loss: 0.1657 - tf.where_13_loss: 0.0052 - pred_sparse_categorical_accuracy: 0.9364 - val_loss: 3.1460 - val_pred_loss: 3.1460 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.5644 - lr: 1.0000e-04\n",
            "Epoch 345/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.4056 - pred_loss: 0.1573 - tf.where_13_loss: 0.0050 - pred_sparse_categorical_accuracy: 0.9425 - val_loss: 5.3287 - val_pred_loss: 5.3287 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.5250 - lr: 1.0000e-04\n",
            "Epoch 346/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.4198 - pred_loss: 0.1681 - tf.where_13_loss: 0.0050 - pred_sparse_categorical_accuracy: 0.9370 - val_loss: 0.4270 - val_pred_loss: 0.4270 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8295 - lr: 1.0000e-04\n",
            "Epoch 347/500\n",
            "113/113 [==============================] - 2s 20ms/step - loss: 0.4070 - pred_loss: 0.1550 - tf.where_13_loss: 0.0050 - pred_sparse_categorical_accuracy: 0.9406 - val_loss: 0.3701 - val_pred_loss: 0.3701 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8424 - lr: 1.0000e-04\n",
            "Epoch 348/500\n",
            "113/113 [==============================] - 2s 22ms/step - loss: 0.4096 - pred_loss: 0.1592 - tf.where_13_loss: 0.0050 - pred_sparse_categorical_accuracy: 0.9439 - val_loss: 0.3738 - val_pred_loss: 0.3738 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8424 - lr: 1.0000e-04\n",
            "Epoch 349/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.4078 - pred_loss: 0.1587 - tf.where_13_loss: 0.0050 - pred_sparse_categorical_accuracy: 0.9403 - val_loss: 2.1882 - val_pred_loss: 2.1882 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6295 - lr: 1.0000e-04\n",
            "Epoch 350/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.4258 - pred_loss: 0.1703 - tf.where_13_loss: 0.0051 - pred_sparse_categorical_accuracy: 0.9359 - val_loss: 2.8087 - val_pred_loss: 2.8087 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.5977 - lr: 1.0000e-04\n",
            "Epoch 351/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.4100 - pred_loss: 0.1593 - tf.where_13_loss: 0.0050 - pred_sparse_categorical_accuracy: 0.9392 - val_loss: 2.3084 - val_pred_loss: 2.3084 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6030 - lr: 1.0000e-04\n",
            "Epoch 352/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.4013 - pred_loss: 0.1509 - tf.where_13_loss: 0.0050 - pred_sparse_categorical_accuracy: 0.9447 - val_loss: 2.7875 - val_pred_loss: 2.7875 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6098 - lr: 1.0000e-04\n",
            "Epoch 353/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.3938 - pred_loss: 0.1470 - tf.where_13_loss: 0.0049 - pred_sparse_categorical_accuracy: 0.9458 - val_loss: 2.0513 - val_pred_loss: 2.0513 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6477 - lr: 1.0000e-04\n",
            "Epoch 354/500\n",
            "113/113 [==============================] - 2s 20ms/step - loss: 0.3997 - pred_loss: 0.1524 - tf.where_13_loss: 0.0049 - pred_sparse_categorical_accuracy: 0.9445 - val_loss: 2.3141 - val_pred_loss: 2.3141 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6114 - lr: 1.0000e-04\n",
            "Epoch 355/500\n",
            "113/113 [==============================] - 2s 21ms/step - loss: 0.3853 - pred_loss: 0.1431 - tf.where_13_loss: 0.0048 - pred_sparse_categorical_accuracy: 0.9475 - val_loss: 7.4917 - val_pred_loss: 7.4917 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.4955 - lr: 1.0000e-04\n",
            "Epoch 356/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.4062 - pred_loss: 0.1610 - tf.where_13_loss: 0.0049 - pred_sparse_categorical_accuracy: 0.9408 - val_loss: 4.1502 - val_pred_loss: 4.1502 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.5515 - lr: 1.0000e-04\n",
            "Epoch 357/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.3984 - pred_loss: 0.1497 - tf.where_13_loss: 0.0050 - pred_sparse_categorical_accuracy: 0.9445 - val_loss: 6.0795 - val_pred_loss: 6.0795 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.5250 - lr: 1.0000e-04\n",
            "Epoch 358/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.4040 - pred_loss: 0.1505 - tf.where_13_loss: 0.0051 - pred_sparse_categorical_accuracy: 0.9470 - val_loss: 1.9602 - val_pred_loss: 1.9602 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6311 - lr: 1.0000e-04\n",
            "Epoch 359/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.3926 - pred_loss: 0.1445 - tf.where_13_loss: 0.0050 - pred_sparse_categorical_accuracy: 0.9495 - val_loss: 0.9065 - val_pred_loss: 0.9065 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7182 - lr: 1.0000e-04\n",
            "Epoch 360/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.3934 - pred_loss: 0.1436 - tf.where_13_loss: 0.0050 - pred_sparse_categorical_accuracy: 0.9464 - val_loss: 1.4969 - val_pred_loss: 1.4969 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6803 - lr: 1.0000e-04\n",
            "Epoch 361/500\n",
            "113/113 [==============================] - 2s 21ms/step - loss: 0.3930 - pred_loss: 0.1522 - tf.where_13_loss: 0.0048 - pred_sparse_categorical_accuracy: 0.9453 - val_loss: 0.9064 - val_pred_loss: 0.9064 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7167 - lr: 1.0000e-04\n",
            "Epoch 362/500\n",
            "113/113 [==============================] - 2s 21ms/step - loss: 0.3962 - pred_loss: 0.1486 - tf.where_13_loss: 0.0050 - pred_sparse_categorical_accuracy: 0.9442 - val_loss: 3.6367 - val_pred_loss: 3.6367 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.5848 - lr: 1.0000e-04\n",
            "Epoch 363/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.3853 - pred_loss: 0.1419 - tf.where_13_loss: 0.0049 - pred_sparse_categorical_accuracy: 0.9461 - val_loss: 5.3110 - val_pred_loss: 5.3110 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.5341 - lr: 1.0000e-04\n",
            "Epoch 364/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.3969 - pred_loss: 0.1587 - tf.where_13_loss: 0.0048 - pred_sparse_categorical_accuracy: 0.9384 - val_loss: 3.5261 - val_pred_loss: 3.5261 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.5591 - lr: 1.0000e-04\n",
            "Epoch 365/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.3886 - pred_loss: 0.1457 - tf.where_13_loss: 0.0049 - pred_sparse_categorical_accuracy: 0.9481 - val_loss: 3.0064 - val_pred_loss: 3.0064 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.5985 - lr: 1.0000e-04\n",
            "Epoch 366/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.3935 - pred_loss: 0.1486 - tf.where_13_loss: 0.0049 - pred_sparse_categorical_accuracy: 0.9420 - val_loss: 6.3260 - val_pred_loss: 6.3260 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.5068 - lr: 1.0000e-04\n",
            "Epoch 367/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.4040 - pred_loss: 0.1516 - tf.where_13_loss: 0.0050 - pred_sparse_categorical_accuracy: 0.9436 - val_loss: 0.3683 - val_pred_loss: 0.3683 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8439 - lr: 1.0000e-04\n",
            "Epoch 368/500\n",
            "113/113 [==============================] - 2s 21ms/step - loss: 0.3925 - pred_loss: 0.1477 - tf.where_13_loss: 0.0049 - pred_sparse_categorical_accuracy: 0.9456 - val_loss: 4.1231 - val_pred_loss: 4.1231 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.5477 - lr: 1.0000e-04\n",
            "Epoch 369/500\n",
            "113/113 [==============================] - 2s 21ms/step - loss: 0.4131 - pred_loss: 0.1594 - tf.where_13_loss: 0.0051 - pred_sparse_categorical_accuracy: 0.9411 - val_loss: 1.8367 - val_pred_loss: 1.8367 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6462 - lr: 1.0000e-04\n",
            "Epoch 370/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.4035 - pred_loss: 0.1451 - tf.where_13_loss: 0.0052 - pred_sparse_categorical_accuracy: 0.9506 - val_loss: 3.6209 - val_pred_loss: 3.6209 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.5674 - lr: 1.0000e-04\n",
            "Epoch 371/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.3833 - pred_loss: 0.1405 - tf.where_13_loss: 0.0049 - pred_sparse_categorical_accuracy: 0.9520 - val_loss: 2.3349 - val_pred_loss: 2.3349 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6303 - lr: 1.0000e-04\n",
            "Epoch 372/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.3937 - pred_loss: 0.1481 - tf.where_13_loss: 0.0049 - pred_sparse_categorical_accuracy: 0.9458 - val_loss: 0.4569 - val_pred_loss: 0.4569 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8121 - lr: 1.0000e-04\n",
            "Epoch 373/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.4006 - pred_loss: 0.1421 - tf.where_13_loss: 0.0052 - pred_sparse_categorical_accuracy: 0.9467 - val_loss: 1.5087 - val_pred_loss: 1.5087 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6667 - lr: 1.0000e-04\n",
            "Epoch 374/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.3927 - pred_loss: 0.1450 - tf.where_13_loss: 0.0050 - pred_sparse_categorical_accuracy: 0.9511 - val_loss: 0.8260 - val_pred_loss: 0.8260 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7235 - lr: 1.0000e-04\n",
            "Epoch 375/500\n",
            "113/113 [==============================] - 2s 21ms/step - loss: 0.3903 - pred_loss: 0.1423 - tf.where_13_loss: 0.0050 - pred_sparse_categorical_accuracy: 0.9472 - val_loss: 0.6138 - val_pred_loss: 0.6138 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7773 - lr: 1.0000e-04\n",
            "Epoch 376/500\n",
            "113/113 [==============================] - 2s 20ms/step - loss: 0.3975 - pred_loss: 0.1472 - tf.where_13_loss: 0.0050 - pred_sparse_categorical_accuracy: 0.9467 - val_loss: 0.6121 - val_pred_loss: 0.6121 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7803 - lr: 1.0000e-04\n",
            "Epoch 377/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.4096 - pred_loss: 0.1532 - tf.where_13_loss: 0.0051 - pred_sparse_categorical_accuracy: 0.9445 - val_loss: 0.7426 - val_pred_loss: 0.7426 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7561 - lr: 1.0000e-04\n",
            "Epoch 378/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.3981 - pred_loss: 0.1415 - tf.where_13_loss: 0.0051 - pred_sparse_categorical_accuracy: 0.9453 - val_loss: 5.4419 - val_pred_loss: 5.4419 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.5152 - lr: 1.0000e-04\n",
            "Epoch 379/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.4016 - pred_loss: 0.1454 - tf.where_13_loss: 0.0051 - pred_sparse_categorical_accuracy: 0.9456 - val_loss: 1.8718 - val_pred_loss: 1.8718 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6621 - lr: 1.0000e-04\n",
            "Epoch 380/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.3867 - pred_loss: 0.1428 - tf.where_13_loss: 0.0049 - pred_sparse_categorical_accuracy: 0.9492 - val_loss: 6.9918 - val_pred_loss: 6.9918 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.4970 - lr: 1.0000e-04\n",
            "Epoch 381/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.3794 - pred_loss: 0.1343 - tf.where_13_loss: 0.0049 - pred_sparse_categorical_accuracy: 0.9517 - val_loss: 3.2410 - val_pred_loss: 3.2410 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.5962 - lr: 1.0000e-04\n",
            "Epoch 382/500\n",
            "113/113 [==============================] - 2s 20ms/step - loss: 0.3933 - pred_loss: 0.1475 - tf.where_13_loss: 0.0049 - pred_sparse_categorical_accuracy: 0.9414 - val_loss: 0.9437 - val_pred_loss: 0.9437 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7227 - lr: 1.0000e-04\n",
            "Epoch 383/500\n",
            "113/113 [==============================] - 2s 20ms/step - loss: 0.3863 - pred_loss: 0.1394 - tf.where_13_loss: 0.0049 - pred_sparse_categorical_accuracy: 0.9481 - val_loss: 1.9068 - val_pred_loss: 1.9068 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6364 - lr: 1.0000e-04\n",
            "Epoch 384/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.3971 - pred_loss: 0.1536 - tf.where_13_loss: 0.0049 - pred_sparse_categorical_accuracy: 0.9361 - val_loss: 1.4656 - val_pred_loss: 1.4656 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6689 - lr: 1.0000e-04\n",
            "Epoch 385/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.3735 - pred_loss: 0.1356 - tf.where_13_loss: 0.0048 - pred_sparse_categorical_accuracy: 0.9495 - val_loss: 0.3672 - val_pred_loss: 0.3672 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8447 - lr: 1.0000e-04\n",
            "Epoch 386/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.3868 - pred_loss: 0.1377 - tf.where_13_loss: 0.0050 - pred_sparse_categorical_accuracy: 0.9514 - val_loss: 12.4786 - val_pred_loss: 12.4786 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.4856 - lr: 1.0000e-04\n",
            "Epoch 387/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.4058 - pred_loss: 0.1507 - tf.where_13_loss: 0.0051 - pred_sparse_categorical_accuracy: 0.9414 - val_loss: 2.6335 - val_pred_loss: 2.6335 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6250 - lr: 1.0000e-04\n",
            "Epoch 388/500\n",
            "113/113 [==============================] - 2s 20ms/step - loss: 0.4028 - pred_loss: 0.1521 - tf.where_13_loss: 0.0050 - pred_sparse_categorical_accuracy: 0.9436 - val_loss: 1.2649 - val_pred_loss: 1.2649 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6962 - lr: 1.0000e-04\n",
            "Epoch 389/500\n",
            "113/113 [==============================] - 3s 22ms/step - loss: 0.3875 - pred_loss: 0.1391 - tf.where_13_loss: 0.0050 - pred_sparse_categorical_accuracy: 0.9478 - val_loss: 0.4382 - val_pred_loss: 0.4382 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8227 - lr: 1.0000e-04\n",
            "Epoch 390/500\n",
            "113/113 [==============================] - 2s 20ms/step - loss: 0.3885 - pred_loss: 0.1456 - tf.where_13_loss: 0.0049 - pred_sparse_categorical_accuracy: 0.9481 - val_loss: 5.7782 - val_pred_loss: 5.7782 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.5121 - lr: 1.0000e-04\n",
            "Epoch 391/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.3929 - pred_loss: 0.1501 - tf.where_13_loss: 0.0049 - pred_sparse_categorical_accuracy: 0.9425 - val_loss: 2.9705 - val_pred_loss: 2.9705 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6030 - lr: 1.0000e-04\n",
            "Epoch 392/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.3759 - pred_loss: 0.1339 - tf.where_13_loss: 0.0048 - pred_sparse_categorical_accuracy: 0.9511 - val_loss: 3.2516 - val_pred_loss: 3.2516 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.5841 - lr: 1.0000e-04\n",
            "Epoch 393/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.3937 - pred_loss: 0.1436 - tf.where_13_loss: 0.0050 - pred_sparse_categorical_accuracy: 0.9511 - val_loss: 6.0751 - val_pred_loss: 6.0751 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.5061 - lr: 1.0000e-04\n",
            "Epoch 394/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.3895 - pred_loss: 0.1403 - tf.where_13_loss: 0.0050 - pred_sparse_categorical_accuracy: 0.9508 - val_loss: 2.6453 - val_pred_loss: 2.6453 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6129 - lr: 1.0000e-04\n",
            "Epoch 395/500\n",
            "113/113 [==============================] - 2s 20ms/step - loss: 0.3753 - pred_loss: 0.1318 - tf.where_13_loss: 0.0049 - pred_sparse_categorical_accuracy: 0.9533 - val_loss: 1.8836 - val_pred_loss: 1.8836 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6455 - lr: 1.0000e-04\n",
            "Epoch 396/500\n",
            "113/113 [==============================] - 2s 21ms/step - loss: 0.3889 - pred_loss: 0.1409 - tf.where_13_loss: 0.0050 - pred_sparse_categorical_accuracy: 0.9464 - val_loss: 3.3769 - val_pred_loss: 3.3769 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.5742 - lr: 1.0000e-04\n",
            "Epoch 397/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.3885 - pred_loss: 0.1376 - tf.where_13_loss: 0.0050 - pred_sparse_categorical_accuracy: 0.9456 - val_loss: 4.1449 - val_pred_loss: 4.1449 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.5538 - lr: 1.0000e-04\n",
            "Epoch 398/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.3963 - pred_loss: 0.1401 - tf.where_13_loss: 0.0051 - pred_sparse_categorical_accuracy: 0.9467 - val_loss: 4.2158 - val_pred_loss: 4.2158 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.5523 - lr: 1.0000e-04\n",
            "Epoch 399/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.3875 - pred_loss: 0.1408 - tf.where_13_loss: 0.0049 - pred_sparse_categorical_accuracy: 0.9511 - val_loss: 3.7780 - val_pred_loss: 3.7780 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.5545 - lr: 1.0000e-04\n",
            "Epoch 400/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.3952 - pred_loss: 0.1441 - tf.where_13_loss: 0.0050 - pred_sparse_categorical_accuracy: 0.9489 - val_loss: 1.9708 - val_pred_loss: 1.9708 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6598 - lr: 1.0000e-04\n",
            "Epoch 401/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.3760 - pred_loss: 0.1329 - tf.where_13_loss: 0.0049 - pred_sparse_categorical_accuracy: 0.9492 - val_loss: 1.4365 - val_pred_loss: 1.4365 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6818 - lr: 1.0000e-04\n",
            "Epoch 402/500\n",
            "113/113 [==============================] - 2s 21ms/step - loss: 0.3666 - pred_loss: 0.1280 - tf.where_13_loss: 0.0048 - pred_sparse_categorical_accuracy: 0.9564 - val_loss: 2.0667 - val_pred_loss: 2.0667 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6598 - lr: 1.0000e-04\n",
            "Epoch 403/500\n",
            "113/113 [==============================] - 2s 20ms/step - loss: 0.3816 - pred_loss: 0.1406 - tf.where_13_loss: 0.0048 - pred_sparse_categorical_accuracy: 0.9472 - val_loss: 2.9458 - val_pred_loss: 2.9458 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6015 - lr: 1.0000e-04\n",
            "Epoch 404/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.3777 - pred_loss: 0.1332 - tf.where_13_loss: 0.0049 - pred_sparse_categorical_accuracy: 0.9517 - val_loss: 2.9525 - val_pred_loss: 2.9525 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.5856 - lr: 1.0000e-04\n",
            "Epoch 405/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.3882 - pred_loss: 0.1460 - tf.where_13_loss: 0.0048 - pred_sparse_categorical_accuracy: 0.9478 - val_loss: 4.4611 - val_pred_loss: 4.4611 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.5424 - lr: 1.0000e-04\n",
            "Epoch 406/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.3726 - pred_loss: 0.1315 - tf.where_13_loss: 0.0048 - pred_sparse_categorical_accuracy: 0.9550 - val_loss: 0.6075 - val_pred_loss: 0.6075 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7803 - lr: 1.0000e-04\n",
            "Epoch 407/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.3878 - pred_loss: 0.1388 - tf.where_13_loss: 0.0050 - pred_sparse_categorical_accuracy: 0.9486 - val_loss: 2.5868 - val_pred_loss: 2.5868 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6083 - lr: 1.0000e-04\n",
            "Epoch 408/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.3800 - pred_loss: 0.1318 - tf.where_13_loss: 0.0050 - pred_sparse_categorical_accuracy: 0.9553 - val_loss: 1.7590 - val_pred_loss: 1.7590 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6561 - lr: 1.0000e-04\n",
            "Epoch 409/500\n",
            "113/113 [==============================] - 2s 20ms/step - loss: 0.3759 - pred_loss: 0.1354 - tf.where_13_loss: 0.0048 - pred_sparse_categorical_accuracy: 0.9506 - val_loss: 1.7452 - val_pred_loss: 1.7452 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6674 - lr: 1.0000e-04\n",
            "Epoch 410/500\n",
            "113/113 [==============================] - 2s 21ms/step - loss: 0.4121 - pred_loss: 0.1593 - tf.where_13_loss: 0.0051 - pred_sparse_categorical_accuracy: 0.9384 - val_loss: 5.3488 - val_pred_loss: 5.3488 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.5258 - lr: 1.0000e-04\n",
            "Epoch 411/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.3824 - pred_loss: 0.1422 - tf.where_13_loss: 0.0048 - pred_sparse_categorical_accuracy: 0.9470 - val_loss: 1.9349 - val_pred_loss: 1.9349 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6326 - lr: 1.0000e-04\n",
            "Epoch 412/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.3874 - pred_loss: 0.1402 - tf.where_13_loss: 0.0049 - pred_sparse_categorical_accuracy: 0.9447 - val_loss: 4.1707 - val_pred_loss: 4.1707 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.5477 - lr: 1.0000e-04\n",
            "Epoch 413/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.3787 - pred_loss: 0.1363 - tf.where_13_loss: 0.0048 - pred_sparse_categorical_accuracy: 0.9489 - val_loss: 1.9780 - val_pred_loss: 1.9780 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6371 - lr: 1.0000e-04\n",
            "Epoch 414/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.3797 - pred_loss: 0.1298 - tf.where_13_loss: 0.0050 - pred_sparse_categorical_accuracy: 0.9508 - val_loss: 0.4240 - val_pred_loss: 0.4240 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8333 - lr: 1.0000e-04\n",
            "Epoch 415/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.3829 - pred_loss: 0.1355 - tf.where_13_loss: 0.0049 - pred_sparse_categorical_accuracy: 0.9483 - val_loss: 4.9852 - val_pred_loss: 4.9852 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.5311 - lr: 1.0000e-04\n",
            "Epoch 416/500\n",
            "113/113 [==============================] - 2s 22ms/step - loss: 0.3630 - pred_loss: 0.1225 - tf.where_13_loss: 0.0048 - pred_sparse_categorical_accuracy: 0.9561 - val_loss: 3.2948 - val_pred_loss: 3.2948 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.5735 - lr: 1.0000e-04\n",
            "Epoch 417/500\n",
            "113/113 [==============================] - 2s 21ms/step - loss: 0.3867 - pred_loss: 0.1375 - tf.where_13_loss: 0.0050 - pred_sparse_categorical_accuracy: 0.9506 - val_loss: 1.2321 - val_pred_loss: 1.2321 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6932 - lr: 1.0000e-04\n",
            "Epoch 418/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.4029 - pred_loss: 0.1503 - tf.where_13_loss: 0.0051 - pred_sparse_categorical_accuracy: 0.9456 - val_loss: 0.4187 - val_pred_loss: 0.4187 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8280 - lr: 1.0000e-04\n",
            "Epoch 419/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.3695 - pred_loss: 0.1282 - tf.where_13_loss: 0.0048 - pred_sparse_categorical_accuracy: 0.9561 - val_loss: 1.5004 - val_pred_loss: 1.5004 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6758 - lr: 1.0000e-04\n",
            "Epoch 420/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.3836 - pred_loss: 0.1379 - tf.where_13_loss: 0.0049 - pred_sparse_categorical_accuracy: 0.9470 - val_loss: 0.4348 - val_pred_loss: 0.4348 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8356 - lr: 1.0000e-04\n",
            "Epoch 421/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.3906 - pred_loss: 0.1366 - tf.where_13_loss: 0.0051 - pred_sparse_categorical_accuracy: 0.9481 - val_loss: 0.3969 - val_pred_loss: 0.3969 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8386 - lr: 1.0000e-04\n",
            "Epoch 422/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.3882 - pred_loss: 0.1409 - tf.where_13_loss: 0.0049 - pred_sparse_categorical_accuracy: 0.9461 - val_loss: 1.9110 - val_pred_loss: 1.9110 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6614 - lr: 1.0000e-04\n",
            "Epoch 423/500\n",
            "113/113 [==============================] - 2s 21ms/step - loss: 0.3777 - pred_loss: 0.1305 - tf.where_13_loss: 0.0049 - pred_sparse_categorical_accuracy: 0.9536 - val_loss: 3.0416 - val_pred_loss: 3.0416 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.5727 - lr: 1.0000e-04\n",
            "Epoch 424/500\n",
            "113/113 [==============================] - 2s 22ms/step - loss: 0.3785 - pred_loss: 0.1315 - tf.where_13_loss: 0.0049 - pred_sparse_categorical_accuracy: 0.9517 - val_loss: 5.6777 - val_pred_loss: 5.6777 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.5295 - lr: 1.0000e-04\n",
            "Epoch 425/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.3757 - pred_loss: 0.1352 - tf.where_13_loss: 0.0048 - pred_sparse_categorical_accuracy: 0.9517 - val_loss: 10.3183 - val_pred_loss: 10.3183 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.4886 - lr: 1.0000e-04\n",
            "Epoch 426/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.3831 - pred_loss: 0.1326 - tf.where_13_loss: 0.0050 - pred_sparse_categorical_accuracy: 0.9511 - val_loss: 0.7700 - val_pred_loss: 0.7700 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7553 - lr: 1.0000e-04\n",
            "Epoch 427/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.3765 - pred_loss: 0.1322 - tf.where_13_loss: 0.0049 - pred_sparse_categorical_accuracy: 0.9497 - val_loss: 4.1925 - val_pred_loss: 4.1925 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.5477 - lr: 1.0000e-04\n",
            "Epoch 428/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.3717 - pred_loss: 0.1311 - tf.where_13_loss: 0.0048 - pred_sparse_categorical_accuracy: 0.9542 - val_loss: 3.8614 - val_pred_loss: 3.8614 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.5470 - lr: 1.0000e-04\n",
            "Epoch 429/500\n",
            "113/113 [==============================] - 2s 19ms/step - loss: 0.3856 - pred_loss: 0.1423 - tf.where_13_loss: 0.0049 - pred_sparse_categorical_accuracy: 0.9475 - val_loss: 0.8917 - val_pred_loss: 0.8917 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7326 - lr: 1.0000e-04\n",
            "Epoch 430/500\n",
            "113/113 [==============================] - 2s 20ms/step - loss: 0.3574 - pred_loss: 0.1152 - tf.where_13_loss: 0.0048 - pred_sparse_categorical_accuracy: 0.9581 - val_loss: 1.8737 - val_pred_loss: 1.8737 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6538 - lr: 1.0000e-04\n",
            "Epoch 431/500\n",
            "113/113 [==============================] - 2s 20ms/step - loss: 0.3763 - pred_loss: 0.1341 - tf.where_13_loss: 0.0048 - pred_sparse_categorical_accuracy: 0.9481 - val_loss: 2.6603 - val_pred_loss: 2.6603 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.5985 - lr: 1.0000e-04\n",
            "Epoch 432/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.3728 - pred_loss: 0.1310 - tf.where_13_loss: 0.0048 - pred_sparse_categorical_accuracy: 0.9528 - val_loss: 2.8958 - val_pred_loss: 2.8958 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6083 - lr: 1.0000e-04\n",
            "Epoch 433/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.3774 - pred_loss: 0.1364 - tf.where_13_loss: 0.0048 - pred_sparse_categorical_accuracy: 0.9522 - val_loss: 2.2154 - val_pred_loss: 2.2154 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6273 - lr: 1.0000e-04\n",
            "Epoch 434/500\n",
            "113/113 [==============================] - 2s 19ms/step - loss: 0.3789 - pred_loss: 0.1339 - tf.where_13_loss: 0.0049 - pred_sparse_categorical_accuracy: 0.9511 - val_loss: 5.8471 - val_pred_loss: 5.8471 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.5182 - lr: 1.0000e-04\n",
            "Epoch 435/500\n",
            "113/113 [==============================] - 2s 19ms/step - loss: 0.3685 - pred_loss: 0.1246 - tf.where_13_loss: 0.0049 - pred_sparse_categorical_accuracy: 0.9539 - val_loss: 2.4057 - val_pred_loss: 2.4057 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6273 - lr: 1.0000e-04\n",
            "Epoch 436/500\n",
            "113/113 [==============================] - 2s 20ms/step - loss: 0.3793 - pred_loss: 0.1364 - tf.where_13_loss: 0.0049 - pred_sparse_categorical_accuracy: 0.9522 - val_loss: 1.5515 - val_pred_loss: 1.5515 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6727 - lr: 1.0000e-04\n",
            "Epoch 437/500\n",
            "113/113 [==============================] - 2s 21ms/step - loss: 0.3675 - pred_loss: 0.1303 - tf.where_13_loss: 0.0047 - pred_sparse_categorical_accuracy: 0.9528 - val_loss: 5.0441 - val_pred_loss: 5.0441 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.5455 - lr: 1.0000e-04\n",
            "Epoch 438/500\n",
            "113/113 [==============================] - 2s 20ms/step - loss: 0.3860 - pred_loss: 0.1378 - tf.where_13_loss: 0.0050 - pred_sparse_categorical_accuracy: 0.9433 - val_loss: 3.8842 - val_pred_loss: 3.8842 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.5667 - lr: 1.0000e-04\n",
            "Epoch 439/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.3700 - pred_loss: 0.1312 - tf.where_13_loss: 0.0048 - pred_sparse_categorical_accuracy: 0.9506 - val_loss: 3.5202 - val_pred_loss: 3.5202 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.5886 - lr: 1.0000e-04\n",
            "Epoch 440/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.3732 - pred_loss: 0.1243 - tf.where_13_loss: 0.0050 - pred_sparse_categorical_accuracy: 0.9572 - val_loss: 1.5959 - val_pred_loss: 1.5959 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6674 - lr: 1.0000e-04\n",
            "Epoch 441/500\n",
            "113/113 [==============================] - 2s 19ms/step - loss: 0.3805 - pred_loss: 0.1377 - tf.where_13_loss: 0.0049 - pred_sparse_categorical_accuracy: 0.9489 - val_loss: 16.6372 - val_pred_loss: 16.6372 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.4841 - lr: 1.0000e-04\n",
            "Epoch 442/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.3691 - pred_loss: 0.1289 - tf.where_13_loss: 0.0048 - pred_sparse_categorical_accuracy: 0.9508 - val_loss: 2.5185 - val_pred_loss: 2.5185 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6152 - lr: 1.0000e-04\n",
            "Epoch 443/500\n",
            "113/113 [==============================] - 2s 21ms/step - loss: 0.3926 - pred_loss: 0.1390 - tf.where_13_loss: 0.0051 - pred_sparse_categorical_accuracy: 0.9456 - val_loss: 4.2880 - val_pred_loss: 4.2880 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.5432 - lr: 1.0000e-04\n",
            "Epoch 444/500\n",
            "113/113 [==============================] - 3s 22ms/step - loss: 0.3593 - pred_loss: 0.1191 - tf.where_13_loss: 0.0048 - pred_sparse_categorical_accuracy: 0.9595 - val_loss: 4.1344 - val_pred_loss: 4.1344 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.5470 - lr: 1.0000e-04\n",
            "Epoch 445/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.3753 - pred_loss: 0.1256 - tf.where_13_loss: 0.0050 - pred_sparse_categorical_accuracy: 0.9567 - val_loss: 3.6488 - val_pred_loss: 3.6488 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.5742 - lr: 1.0000e-04\n",
            "Epoch 446/500\n",
            "113/113 [==============================] - 2s 19ms/step - loss: 0.3716 - pred_loss: 0.1319 - tf.where_13_loss: 0.0048 - pred_sparse_categorical_accuracy: 0.9514 - val_loss: 1.1795 - val_pred_loss: 1.1795 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6947 - lr: 1.0000e-04\n",
            "Epoch 447/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.3825 - pred_loss: 0.1391 - tf.where_13_loss: 0.0049 - pred_sparse_categorical_accuracy: 0.9478 - val_loss: 7.6603 - val_pred_loss: 7.6603 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.4955 - lr: 1.0000e-04\n",
            "Epoch 448/500\n",
            "113/113 [==============================] - 2s 20ms/step - loss: 0.3743 - pred_loss: 0.1304 - tf.where_13_loss: 0.0049 - pred_sparse_categorical_accuracy: 0.9514 - val_loss: 1.0780 - val_pred_loss: 1.0780 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7121 - lr: 1.0000e-04\n",
            "Epoch 449/500\n",
            "113/113 [==============================] - 2s 19ms/step - loss: 0.3822 - pred_loss: 0.1374 - tf.where_13_loss: 0.0049 - pred_sparse_categorical_accuracy: 0.9495 - val_loss: 4.0751 - val_pred_loss: 4.0751 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.5492 - lr: 1.0000e-04\n",
            "Epoch 450/500\n",
            "113/113 [==============================] - 2s 22ms/step - loss: 0.3679 - pred_loss: 0.1254 - tf.where_13_loss: 0.0048 - pred_sparse_categorical_accuracy: 0.9511 - val_loss: 1.9171 - val_pred_loss: 1.9171 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6576 - lr: 1.0000e-04\n",
            "Epoch 451/500\n",
            "113/113 [==============================] - 2s 21ms/step - loss: 0.3844 - pred_loss: 0.1352 - tf.where_13_loss: 0.0050 - pred_sparse_categorical_accuracy: 0.9528 - val_loss: 2.4502 - val_pred_loss: 2.4502 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6356 - lr: 1.0000e-04\n",
            "Epoch 452/500\n",
            "113/113 [==============================] - 2s 19ms/step - loss: 0.3850 - pred_loss: 0.1403 - tf.where_13_loss: 0.0049 - pred_sparse_categorical_accuracy: 0.9503 - val_loss: 2.4849 - val_pred_loss: 2.4849 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6333 - lr: 1.0000e-04\n",
            "Epoch 453/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.4023 - pred_loss: 0.1439 - tf.where_13_loss: 0.0052 - pred_sparse_categorical_accuracy: 0.9431 - val_loss: 3.8518 - val_pred_loss: 3.8518 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.5629 - lr: 1.0000e-04\n",
            "Epoch 454/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.3669 - pred_loss: 0.1253 - tf.where_13_loss: 0.0048 - pred_sparse_categorical_accuracy: 0.9561 - val_loss: 0.7209 - val_pred_loss: 0.7209 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7621 - lr: 1.0000e-04\n",
            "Epoch 455/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.3688 - pred_loss: 0.1273 - tf.where_13_loss: 0.0048 - pred_sparse_categorical_accuracy: 0.9511 - val_loss: 1.7186 - val_pred_loss: 1.7186 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6621 - lr: 1.0000e-04\n",
            "Epoch 456/500\n",
            "113/113 [==============================] - 2s 20ms/step - loss: 0.3740 - pred_loss: 0.1274 - tf.where_13_loss: 0.0049 - pred_sparse_categorical_accuracy: 0.9495 - val_loss: 1.0996 - val_pred_loss: 1.0996 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7068 - lr: 1.0000e-04\n",
            "Epoch 457/500\n",
            "113/113 [==============================] - 2s 22ms/step - loss: 0.3693 - pred_loss: 0.1256 - tf.where_13_loss: 0.0049 - pred_sparse_categorical_accuracy: 0.9553 - val_loss: 2.7247 - val_pred_loss: 2.7247 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6258 - lr: 1.0000e-04\n",
            "Epoch 458/500\n",
            "113/113 [==============================] - 2s 21ms/step - loss: 0.3629 - pred_loss: 0.1224 - tf.where_13_loss: 0.0048 - pred_sparse_categorical_accuracy: 0.9564 - val_loss: 1.2763 - val_pred_loss: 1.2763 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6985 - lr: 1.0000e-04\n",
            "Epoch 459/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.3647 - pred_loss: 0.1244 - tf.where_13_loss: 0.0048 - pred_sparse_categorical_accuracy: 0.9522 - val_loss: 1.2447 - val_pred_loss: 1.2447 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6894 - lr: 1.0000e-04\n",
            "Epoch 460/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.3581 - pred_loss: 0.1235 - tf.where_13_loss: 0.0047 - pred_sparse_categorical_accuracy: 0.9522 - val_loss: 1.9625 - val_pred_loss: 1.9625 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6470 - lr: 1.0000e-04\n",
            "Epoch 461/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.3653 - pred_loss: 0.1189 - tf.where_13_loss: 0.0049 - pred_sparse_categorical_accuracy: 0.9581 - val_loss: 4.6857 - val_pred_loss: 4.6857 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.5432 - lr: 1.0000e-04\n",
            "Epoch 462/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.3631 - pred_loss: 0.1204 - tf.where_13_loss: 0.0049 - pred_sparse_categorical_accuracy: 0.9570 - val_loss: 7.1093 - val_pred_loss: 7.1093 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.5061 - lr: 1.0000e-04\n",
            "Epoch 463/500\n",
            "113/113 [==============================] - 2s 21ms/step - loss: 0.3533 - pred_loss: 0.1160 - tf.where_13_loss: 0.0047 - pred_sparse_categorical_accuracy: 0.9620 - val_loss: 2.6339 - val_pred_loss: 2.6339 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6144 - lr: 1.0000e-04\n",
            "Epoch 464/500\n",
            "113/113 [==============================] - 3s 24ms/step - loss: 0.3753 - pred_loss: 0.1283 - tf.where_13_loss: 0.0049 - pred_sparse_categorical_accuracy: 0.9492 - val_loss: 5.6558 - val_pred_loss: 5.6558 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.5242 - lr: 1.0000e-04\n",
            "Epoch 465/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.3568 - pred_loss: 0.1213 - tf.where_13_loss: 0.0047 - pred_sparse_categorical_accuracy: 0.9545 - val_loss: 1.0516 - val_pred_loss: 1.0516 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7174 - lr: 1.0000e-04\n",
            "Epoch 466/500\n",
            "113/113 [==============================] - 2s 19ms/step - loss: 0.3495 - pred_loss: 0.1115 - tf.where_13_loss: 0.0048 - pred_sparse_categorical_accuracy: 0.9611 - val_loss: 2.2178 - val_pred_loss: 2.2178 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6424 - lr: 1.0000e-04\n",
            "Epoch 467/500\n",
            "113/113 [==============================] - 2s 19ms/step - loss: 0.3547 - pred_loss: 0.1198 - tf.where_13_loss: 0.0047 - pred_sparse_categorical_accuracy: 0.9567 - val_loss: 6.1954 - val_pred_loss: 6.1954 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.5129 - lr: 1.0000e-04\n",
            "Epoch 468/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.3813 - pred_loss: 0.1316 - tf.where_13_loss: 0.0050 - pred_sparse_categorical_accuracy: 0.9522 - val_loss: 3.7286 - val_pred_loss: 3.7286 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.5758 - lr: 1.0000e-04\n",
            "Epoch 469/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.3774 - pred_loss: 0.1305 - tf.where_13_loss: 0.0049 - pred_sparse_categorical_accuracy: 0.9514 - val_loss: 1.0790 - val_pred_loss: 1.0790 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7159 - lr: 1.0000e-04\n",
            "Epoch 470/500\n",
            "113/113 [==============================] - 2s 22ms/step - loss: 0.3629 - pred_loss: 0.1204 - tf.where_13_loss: 0.0048 - pred_sparse_categorical_accuracy: 0.9522 - val_loss: 5.3806 - val_pred_loss: 5.3806 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.5197 - lr: 1.0000e-04\n",
            "Epoch 471/500\n",
            "113/113 [==============================] - 2s 21ms/step - loss: 0.3777 - pred_loss: 0.1313 - tf.where_13_loss: 0.0049 - pred_sparse_categorical_accuracy: 0.9495 - val_loss: 1.9228 - val_pred_loss: 1.9228 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6538 - lr: 1.0000e-04\n",
            "Epoch 472/500\n",
            "113/113 [==============================] - 2s 19ms/step - loss: 0.3463 - pred_loss: 0.1110 - tf.where_13_loss: 0.0047 - pred_sparse_categorical_accuracy: 0.9617 - val_loss: 4.9784 - val_pred_loss: 4.9784 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.5364 - lr: 1.0000e-04\n",
            "Epoch 473/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.3525 - pred_loss: 0.1183 - tf.where_13_loss: 0.0047 - pred_sparse_categorical_accuracy: 0.9561 - val_loss: 5.6366 - val_pred_loss: 5.6366 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.5205 - lr: 1.0000e-04\n",
            "Epoch 474/500\n",
            "113/113 [==============================] - 2s 19ms/step - loss: 0.3543 - pred_loss: 0.1130 - tf.where_13_loss: 0.0048 - pred_sparse_categorical_accuracy: 0.9625 - val_loss: 5.1520 - val_pred_loss: 5.1520 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.5379 - lr: 1.0000e-04\n",
            "Epoch 475/500\n",
            "113/113 [==============================] - 2s 19ms/step - loss: 0.3643 - pred_loss: 0.1257 - tf.where_13_loss: 0.0048 - pred_sparse_categorical_accuracy: 0.9531 - val_loss: 2.8821 - val_pred_loss: 2.8821 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.5856 - lr: 1.0000e-04\n",
            "Epoch 476/500\n",
            "113/113 [==============================] - 2s 19ms/step - loss: 0.3695 - pred_loss: 0.1245 - tf.where_13_loss: 0.0049 - pred_sparse_categorical_accuracy: 0.9517 - val_loss: 5.1111 - val_pred_loss: 5.1111 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.5220 - lr: 1.0000e-04\n",
            "Epoch 477/500\n",
            "113/113 [==============================] - 3s 23ms/step - loss: 0.3604 - pred_loss: 0.1195 - tf.where_13_loss: 0.0048 - pred_sparse_categorical_accuracy: 0.9547 - val_loss: 0.8732 - val_pred_loss: 0.8732 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7379 - lr: 1.0000e-04\n",
            "Epoch 478/500\n",
            "113/113 [==============================] - 2s 19ms/step - loss: 0.3658 - pred_loss: 0.1196 - tf.where_13_loss: 0.0049 - pred_sparse_categorical_accuracy: 0.9603 - val_loss: 1.0426 - val_pred_loss: 1.0426 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7212 - lr: 1.0000e-04\n",
            "Epoch 479/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.3537 - pred_loss: 0.1154 - tf.where_13_loss: 0.0048 - pred_sparse_categorical_accuracy: 0.9622 - val_loss: 3.0865 - val_pred_loss: 3.0865 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6098 - lr: 1.0000e-04\n",
            "Epoch 480/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.3570 - pred_loss: 0.1199 - tf.where_13_loss: 0.0047 - pred_sparse_categorical_accuracy: 0.9564 - val_loss: 1.3166 - val_pred_loss: 1.3166 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6985 - lr: 1.0000e-04\n",
            "Epoch 481/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.3941 - pred_loss: 0.1443 - tf.where_13_loss: 0.0050 - pred_sparse_categorical_accuracy: 0.9400 - val_loss: 0.9128 - val_pred_loss: 0.9128 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7250 - lr: 1.0000e-04\n",
            "Epoch 482/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.3692 - pred_loss: 0.1269 - tf.where_13_loss: 0.0048 - pred_sparse_categorical_accuracy: 0.9481 - val_loss: 0.4770 - val_pred_loss: 0.4770 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8182 - lr: 1.0000e-04\n",
            "Epoch 483/500\n",
            "113/113 [==============================] - 2s 20ms/step - loss: 0.3605 - pred_loss: 0.1193 - tf.where_13_loss: 0.0048 - pred_sparse_categorical_accuracy: 0.9625 - val_loss: 1.1381 - val_pred_loss: 1.1381 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6992 - lr: 1.0000e-04\n",
            "Epoch 484/500\n",
            "113/113 [==============================] - 2s 22ms/step - loss: 0.3660 - pred_loss: 0.1187 - tf.where_13_loss: 0.0049 - pred_sparse_categorical_accuracy: 0.9567 - val_loss: 0.4362 - val_pred_loss: 0.4362 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8295 - lr: 1.0000e-04\n",
            "Epoch 485/500\n",
            "113/113 [==============================] - 2s 19ms/step - loss: 0.3420 - pred_loss: 0.1097 - tf.where_13_loss: 0.0046 - pred_sparse_categorical_accuracy: 0.9645 - val_loss: 4.4260 - val_pred_loss: 4.4260 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.5394 - lr: 1.0000e-04\n",
            "Epoch 486/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.3497 - pred_loss: 0.1144 - tf.where_13_loss: 0.0047 - pred_sparse_categorical_accuracy: 0.9625 - val_loss: 2.5259 - val_pred_loss: 2.5259 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6220 - lr: 1.0000e-04\n",
            "Epoch 487/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.3494 - pred_loss: 0.1137 - tf.where_13_loss: 0.0047 - pred_sparse_categorical_accuracy: 0.9561 - val_loss: 1.3613 - val_pred_loss: 1.3613 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6795 - lr: 1.0000e-04\n",
            "Epoch 488/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.3708 - pred_loss: 0.1295 - tf.where_13_loss: 0.0048 - pred_sparse_categorical_accuracy: 0.9547 - val_loss: 4.2162 - val_pred_loss: 4.2162 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.5667 - lr: 1.0000e-04\n",
            "Epoch 489/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.3620 - pred_loss: 0.1227 - tf.where_13_loss: 0.0048 - pred_sparse_categorical_accuracy: 0.9558 - val_loss: 0.4354 - val_pred_loss: 0.4354 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.8394 - lr: 1.0000e-04\n",
            "Epoch 490/500\n",
            "113/113 [==============================] - 2s 20ms/step - loss: 0.3526 - pred_loss: 0.1144 - tf.where_13_loss: 0.0048 - pred_sparse_categorical_accuracy: 0.9595 - val_loss: 6.0546 - val_pred_loss: 6.0546 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.5121 - lr: 1.0000e-04\n",
            "Epoch 491/500\n",
            "113/113 [==============================] - 2s 21ms/step - loss: 0.3623 - pred_loss: 0.1207 - tf.where_13_loss: 0.0048 - pred_sparse_categorical_accuracy: 0.9572 - val_loss: 0.5159 - val_pred_loss: 0.5159 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.7992 - lr: 1.0000e-04\n",
            "Epoch 492/500\n",
            "113/113 [==============================] - 2s 19ms/step - loss: 0.3774 - pred_loss: 0.1313 - tf.where_13_loss: 0.0049 - pred_sparse_categorical_accuracy: 0.9495 - val_loss: 1.8143 - val_pred_loss: 1.8143 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6508 - lr: 1.0000e-04\n",
            "Epoch 493/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.3615 - pred_loss: 0.1191 - tf.where_13_loss: 0.0048 - pred_sparse_categorical_accuracy: 0.9564 - val_loss: 2.6279 - val_pred_loss: 2.6279 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6114 - lr: 1.0000e-04\n",
            "Epoch 494/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.3553 - pred_loss: 0.1173 - tf.where_13_loss: 0.0048 - pred_sparse_categorical_accuracy: 0.9583 - val_loss: 5.3755 - val_pred_loss: 5.3755 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.5356 - lr: 1.0000e-04\n",
            "Epoch 495/500\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.3560 - pred_loss: 0.1147 - tf.where_13_loss: 0.0048 - pred_sparse_categorical_accuracy: 0.9575 - val_loss: 5.5765 - val_pred_loss: 5.5765 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.5159 - lr: 1.0000e-04\n",
            "Epoch 496/500\n",
            "113/113 [==============================] - 2s 19ms/step - loss: 0.3640 - pred_loss: 0.1230 - tf.where_13_loss: 0.0048 - pred_sparse_categorical_accuracy: 0.9547 - val_loss: 6.5245 - val_pred_loss: 6.5245 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.5076 - lr: 1.0000e-04\n",
            "Epoch 497/500\n",
            "113/113 [==============================] - 2s 20ms/step - loss: 0.3572 - pred_loss: 0.1167 - tf.where_13_loss: 0.0048 - pred_sparse_categorical_accuracy: 0.9550 - val_loss: 5.6118 - val_pred_loss: 5.6118 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.5174 - lr: 1.0000e-04\n",
            "Epoch 498/500\n",
            "113/113 [==============================] - 2s 21ms/step - loss: 0.3571 - pred_loss: 0.1208 - tf.where_13_loss: 0.0047 - pred_sparse_categorical_accuracy: 0.9531 - val_loss: 10.0132 - val_pred_loss: 10.0132 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.4879 - lr: 1.0000e-04\n",
            "Epoch 499/500\n",
            "113/113 [==============================] - 2s 20ms/step - loss: 0.3353 - pred_loss: 0.1002 - tf.where_13_loss: 0.0047 - pred_sparse_categorical_accuracy: 0.9664 - val_loss: 2.6289 - val_pred_loss: 2.6289 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6114 - lr: 1.0000e-04\n",
            "Epoch 500/500\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.3536 - pred_loss: 0.1180 - tf.where_13_loss: 0.0047 - pred_sparse_categorical_accuracy: 0.9600 - val_loss: 3.2158 - val_pred_loss: 3.2158 - val_tf.where_13_loss: 0.0000e+00 - val_pred_sparse_categorical_accuracy: 0.6030 - lr: 1.0000e-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "_rkkgOxmrvx_"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7n6VaPAoiT76"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}