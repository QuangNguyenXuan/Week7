{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"fJKCmDq2cKxJ","executionInfo":{"status":"ok","timestamp":1662277215003,"user_tz":-420,"elapsed":449,"user":{"displayName":"Khoa Nguyen KT","userId":"08245901144578708381"}}},"outputs":[],"source":["import cv2\n","import numpy as np\n","\n","def capture_template():\n","    # To capture video from webcam. \n","    cap = cv2.VideoCapture(0)\n","\n","    # select region\n","    while True:\n","        # Read the frame and Convert to grayscale\n","        _, img = cap.read()\n","        img = cv2.flip(img, 1)\n","        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n","        \n","        # draw rectangle area\n","        top_left = (200,300)\n","        bottom_right = (400,400)\n","        cv2.rectangle(img, top_left, bottom_right, (0, 255, 0), 2)\n","\n","        # Display\n","        cv2.imshow('img', img)\n","\n","        # press the 'c' key\n","        if cv2.waitKey(33) == ord('c'):  \n","            break\n","\n","    # create a template\n","    template = gray[300:400, 200:400]\n","    \n","    cv2.imshow('template', template)\n","    cv2.waitKey(0) # press any keys\n","    \n","    return cap, template\n","\n","def track_object(cap, template):\n","    # tracking\n","    while True:\n","        # Read the frame and Convert to grayscale\n","        _, img = cap.read()\n","        img = cv2.flip(img, 1)\n","        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n","\n","        corr_map = cv2.matchTemplate(gray, template, cv2.TM_CCOEFF_NORMED)\n","        min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(corr_map) \n","\n","        # take minimum\n","        top_left = max_loc\n","        h, w = template.shape\n","        bottom_right = (top_left[0] + w, top_left[1] + h)\n","\n","        # draw \n","        cv2.rectangle(img, top_left, bottom_right, (0, 255, 0), 2)\n","\n","\n","        # Display\n","        cv2.imshow('img', img)\n","\n","        # press the 'e' key\n","        if cv2.waitKey(33) == ord('e'):  \n","            break\n","    \n","    return cap\n","\n","def release(cap):\n","    # Release the VideoCapture object\n","    cap.release()\n","    cv2.destroyAllWindows()"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":324},"id":"QQ5JMbSccKxL","executionInfo":{"status":"error","timestamp":1662277215581,"user_tz":-420,"elapsed":581,"user":{"displayName":"Khoa Nguyen KT","userId":"08245901144578708381"}},"outputId":"89017907-7de0-4bdd-8bac-5cf99c0b34e6"},"outputs":[{"output_type":"error","ename":"error","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-4abf1f483313>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemplate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcapture_template\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mcap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrack_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemplate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcap\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-1-11bff587d5c2>\u001b[0m in \u001b[0;36mcapture_template\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m####### YOURE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mgray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m# draw rectangle area\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31merror\u001b[0m: OpenCV(4.6.0) /io/opencv/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n"]}],"source":["cap, template = capture_template()\n","cap = track_object(cap, template)\n","release(cap)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mkmRkvFncKxL"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2Mfn6Kd4cKxM"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Mlji5wu1cKxR"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.0"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":false},"colab":{"provenance":[],"collapsed_sections":[]}},"nbformat":4,"nbformat_minor":0}